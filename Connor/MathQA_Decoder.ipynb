{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03a5bb58",
   "metadata": {},
   "source": [
    "# MathQA Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3806a42d",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Figure out how to get true labels\n",
    "- Write custom loss function\n",
    "- test 1 full pass of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a10e4a1",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fffb4413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import os\n",
    "import anytree\n",
    "from anytree import RenderTree\n",
    "from anytree.importer import DictImporter\n",
    "import pandas as pd\n",
    "from itertools import permutations\n",
    "import seaborn as sns\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer, AutoModel, TrainingArguments, Trainer, AutoModelForMaskedLM, DataCollatorForLanguageModeling\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftModel\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import re\n",
    "import pickle\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f9991e",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d428a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 6\n",
    "MAX_LAYERS = 8\n",
    "MAX_TOKENS = 392\n",
    "EMBEDDING_SIZE = 768\n",
    "\n",
    "DATA_PATH = './dataset/'\n",
    "SET_NAMES = ['train', 'validation', 'test']\n",
    "ENCODER_MODEL = 'distilroberta-base' # A more optimized version of roberta obtaining 95% of its performance\n",
    "DEVICE = 'cuda:0'\n",
    "NUM_MASK = '<num>'\n",
    "WORKING_DIR = 'TEMP/'\n",
    "\n",
    "OBJ_DIR = 'pickle/'\n",
    "\n",
    "\n",
    "class Op(Enum):\n",
    "    ADD = '+'\n",
    "    SUB = '-'\n",
    "    MULT = '*'\n",
    "    DIV = '/'\n",
    "    POW = '^'\n",
    "    \n",
    "class Const(Enum):\n",
    "    CONST_NEG_1 = 'const_neg_1' # I added this\n",
    "    CONST_0_25 = 'const_0_25'\n",
    "    CONST_0_2778 = 'const_0_2778'\n",
    "    CONST_0_33 = 'const_0_33'\n",
    "    CONST_0_3937 = 'const_0_3937'\n",
    "    CONST_1 = 'const_1'\n",
    "    CONST_1_6 = 'const_1_6'\n",
    "    CONST_2 = 'const_2'\n",
    "    CONST_3 = 'const_3'\n",
    "    CONST_PI = 'const_pi'\n",
    "    CONST_3_6 = 'const_3_6'\n",
    "    CONST_4 = 'const_4'\n",
    "    CONST_5 = 'const_5'\n",
    "    CONST_6 = 'const_6'\n",
    "    CONST_10 = 'const_10'\n",
    "    CONST_12 = 'const_12'\n",
    "    CONST_26 = 'const_26'\n",
    "    CONST_52 = 'const_52'\n",
    "    CONST_60 = 'const_60'\n",
    "    CONST_100 = 'const_100'\n",
    "    CONST_180 = 'const_180'\n",
    "    CONST_360 = 'const_360'\n",
    "    CONST_1000 = 'const_1000'\n",
    "    CONST_3600 = 'const_3600'\n",
    "\n",
    "values = [-1, 0.25, 0.2778, 0.33, 0.3937, 1, 1.6, 2, 3, math.pi, 3.6, 4, 5, 6, 10, 12, 26, 52, 60, 100, 180, 360, 1000, 3600]\n",
    "const2val = {k:v for k,v in zip(Const._value2member_map_.keys(), values)}    \n",
    "\n",
    "op2id = {k:v for k,v in zip(Op._value2member_map_.keys(), range(len(Op._value2member_map_)))}\n",
    "op2id['None'] = 5\n",
    "const2id = {k:v for k,v in zip(Const._value2member_map_.keys(), range(len(Const._value2member_map_)))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda851b7",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d5bd5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {name:pd.read_csv(f'{DATA_PATH}{name}.csv') for name in SET_NAMES}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ad07be",
   "metadata": {},
   "source": [
    "## Embedding Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a415f6",
   "metadata": {},
   "source": [
    "Converting number embeddings to masked tensors (to ensure they are all homogeneous) and adding in constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7736e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_masked_embeddings(name):\n",
    "#     num_embed = embeddings[name]['num']\n",
    "#     const_embed = embeddings[name]['num']\n",
    "#     mapping, nums = embeddings[name]['num_mapping']\n",
    "#     const = [[num for num in eval(x) if num in const2val] for x in data[name]['nums']]\n",
    "#     max_nums = (np.bincount(mapping)+np.array(list(map(len, const)))).max()\n",
    "\n",
    "#     result = () \n",
    "#     for idx in range(len(const)):\n",
    "#         # Getting number embeddings\n",
    "#         nums = num_embed[mapping==idx]\n",
    "\n",
    "#         # Adding constant embeddings\n",
    "#         c = tuple([const_embed[const2id[x]] for x in const[idx]])\n",
    "#         if len(c) > 0:\n",
    "#             c = torch.stack(c)\n",
    "#             nums = torch.cat((nums, c), dim=0)\n",
    "        \n",
    "#           # non masked code\n",
    "# #         if result is None:\n",
    "# #             result = nums\n",
    "# #         else:\n",
    "# #             result = torch.cat((result, nums), dim=0)\n",
    "        \n",
    "#         # Padding and creating mask\n",
    "#         dim1, dim2 = nums.shape\n",
    "#         mask = torch.full((dim1,dim2), True)\n",
    "#         nums = F.pad(nums, (0,0,0,max_nums-dim1), 'constant', 0)\n",
    "#         mask = F.pad(mask, (0,0,0,max_nums-dim1), 'constant', False)\n",
    "        \n",
    "#         # Creating masked tensor object\n",
    "#         mt = torch.masked.masked_tensor(nums, mask)[None,:,:]\n",
    "#         result = result + (mt,)\n",
    "        \n",
    "#     return torch.cat(result, dim=0)\n",
    "# masked_num_embed = {name:create_masked_embeddings(name) for name in SET_NAMES}\n",
    "# masked_num_embed['train'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081437d6",
   "metadata": {},
   "source": [
    "## Constructing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c533b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerDecoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size, num_tokens, max_layers, K, device):\n",
    "        super(MultiLayerDecoder, self).__init__()\n",
    "        self.device = torch.device(device)\n",
    "        \n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_tokens = num_tokens\n",
    "        self.max_layers = max_layers\n",
    "        self.K = K\n",
    "        self.decoder_layer = MathQADecoder(embedding_size, num_tokens, K, device)\n",
    "    \n",
    "    # Repeatedly get new sets of equations until a maximum depth is reached or there are no more valid equations (all ops are None)\n",
    "    def forward(self, x, embeddings):\n",
    "        \n",
    "        x = x.to(self.device)\n",
    "        nums = embeddings['nums'].to(self.device)\n",
    "        num_idx = embeddings['num_idx'].to(self.device)\n",
    "        ops = embeddings['ops'].to(self.device)\n",
    "        problems = embeddings['problem'].to(self.device)\n",
    "        \n",
    "        # variables to keep track of what equations have been encountered so far\n",
    "        init_dict = lambda x: {i:i for i in range(x)}\n",
    "        eq2id = np.array(list(map(init_dict, num_idx.bincount())))\n",
    "        id2eq = np.array(list(map(init_dict, num_idx.bincount())))\n",
    "\n",
    "        # while less than max layers and the input has more elements\n",
    "        idx = 0\n",
    "        temp = [] # REMOVE THIS\n",
    "        while idx < self.max_layers and x.numel():\n",
    "            batch_size = x.shape[0]\n",
    "            prev_idx = num_idx\n",
    "            prev_nums = nums\n",
    "            \n",
    "            # --------------------------------------------------\n",
    "            # Step 1 - Encoding to embedding size if not already\n",
    "            # --------------------------------------------------\n",
    "            if x.shape[-1] == self.embedding_size*4:\n",
    "                x = self.decoder_layer.exp_encoder(x) #3 [batch_size, K, 3072] -> [batch_size, K, 768]\n",
    "\n",
    "            assert x.shape == torch.Size([batch_size, self.K, self.embedding_size])\n",
    "\n",
    "            # -----------------------\n",
    "            # Step 2 - The main model\n",
    "            # -----------------------\n",
    "            prev_sizes = num_idx.bincount()\n",
    "            x, op, num1, num2, nums, num_idx, problems, eq2id, id2eq = self.decoder_layer(x, nums, num_idx, ops, \n",
    "                                                                                          problems, eq2id, id2eq)\n",
    "            new_sizes = num_idx.bincount()\n",
    "            \n",
    "            # ---------------------------------------------------------------------------------------------------------------------------------\n",
    "            # Step 3 - Removing examples with no valid expressions (If the num nums for a problem is unchanged, it had no valid expressions)\n",
    "            # ---------------------------------------------------------------------------------------------------------------------------------\n",
    "            changed = prev_sizes!=new_sizes # [batch_size] (not_finished True, finished False)\n",
    "            assert len(changed) == batch_size\n",
    "            not_finished = changed.sum()\n",
    "            assert not_finished <= batch_size\n",
    "            nums = nums[changed[num_idx]]  # [num_nums_not_finished, 768]\n",
    "            assert nums.shape[0] <= len(num_idx) and nums.shape[1] == self.embedding_size\n",
    "            prev = num_idx\n",
    "            num_idx = num_idx[changed[num_idx]] # [num_nums_not_finished]\n",
    "            num_idx = torch.unique(num_idx,return_inverse=True)[1]\n",
    "            assert len(num_idx) <= len(prev)\n",
    "            problems = problems[changed] # [not_finished, num_tokens, 768]\n",
    "            assert problems.shape == torch.Size([not_finished, self.num_tokens, self.embedding_size])\n",
    "            eq2id = eq2id[changed] # [not_finished,]\n",
    "            id2eq = id2eq[changed] # [not_finished,]\n",
    "            assert len(eq2id) == not_finished and len(id2eq) == not_finished\n",
    "            x = x[changed] # [not_finished, K, 768]\n",
    "            assert x.shape == torch.Size([not_finished, self.K, self.embedding_size])\n",
    "\n",
    "            idx += 1\n",
    "            temp.append((op,num1,num2,prev_idx,prev_nums,eq2id,id2eq))\n",
    "\n",
    "        return temp\n",
    "\n",
    "        #return op, num1, num2, prev_idx\n",
    "        \n",
    "\n",
    "class MathQADecoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size, num_tokens, K, device): \n",
    "        super(MathQADecoder, self).__init__()\n",
    "        self.device = torch.device(device)\n",
    "        \n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_tokens = num_tokens\n",
    "        self.K = K\n",
    "        \n",
    "        # decreasing dimensionality to match embedding size: <op, num, num, num*num> = 3072 -> 768\n",
    "        self.exp_encoder = torch.nn.Linear(embedding_size*4, embedding_size)\n",
    "        \n",
    "        # converting back into new <op, num, num> for loss calculation\n",
    "        self.exp_decoder = torch.nn.Linear(embedding_size, embedding_size*3)\n",
    "        \n",
    "        # Mixing in expression information to the problem encoding\n",
    "        self.prob_encoder = torch.nn.Linear(num_tokens+K, num_tokens)\n",
    "        \n",
    "        # standard transformer decoder\n",
    "        # we choose K heads for K generated expressions \n",
    "        # (with the hope that each head will get different information for each K expression)\n",
    "        self.transformer_decoder = torch.nn.TransformerDecoderLayer(embedding_size, nhead=K, batch_first=True)\n",
    "        \n",
    "        # softmax for the operations\n",
    "        self.op_softmax = torch.nn.Softmax(dim=2)\n",
    "        \n",
    "        # softmax for the numbers\n",
    "        self.num_softmax = torch.nn.Softmax(dim=0)\n",
    "        \n",
    "    def __apply_to_nums(self, f, nums, num_idx, batch_size):\n",
    "        new_nums = torch.empty(nums.shape)\n",
    "        for x in range(batch_size):\n",
    "            new_nums[num_idx==x] = f(nums[num_idx==x])\n",
    "        return new_nums\n",
    "    \n",
    "    def __update_labels(self, eq2id, id2eq, mask, problem_idx, num1_ids, num2_ids, batch_size, num_idx):\n",
    "        num_valid = len(problem_idx)\n",
    "        valid1 = num1_ids[mask] # [num_valid,]\n",
    "        valid2 = num2_ids[mask] # [num_valid,]\n",
    "        assert len(valid1) == num_valid and len(valid2) == num_valid\n",
    "        for p in range(batch_size):\n",
    "            assert max(id2eq[p].keys()) == (num_idx==p).sum().item()-1\n",
    "            for idx, e in zip(np.where(mask[p])[0], zip(valid1[problem_idx==p], valid2[problem_idx==p])):\n",
    "                assert e[0].item() in id2eq[p] and e[1].item() in id2eq[p]\n",
    "                e = (id2eq[p][e[0].item()],id2eq[p][e[1].item()])\n",
    "                    \n",
    "                if e not in eq2id[p]:\n",
    "                    next_idx = len(eq2id[p])\n",
    "                    eq2id[p][e] = next_idx\n",
    "                    id2eq[p][next_idx] = e\n",
    "                else: # duplicate eq\n",
    "                    mask[p,idx] = False\n",
    "        return eq2id, id2eq, mask\n",
    "      \n",
    "    # x: [batch_size, K, 768]\n",
    "    # nums: [num_nums, 768]\n",
    "    # num_idx: [num_nums,]\n",
    "    # ops: [num_ops, 768]\n",
    "    # problems: [batch_size, num_tokens, 768]\n",
    "    def forward(self, x, nums, num_idx, ops, problems, eq2id, id2eq):    \n",
    "        batch_size = x.shape[0]\n",
    "        num_ops = ops.shape[0]\n",
    "        num_nums = nums.shape[0]\n",
    "\n",
    "        # ----------------------------\n",
    "        # Step 1 - transformer decoder\n",
    "        # ----------------------------\n",
    "        assert problems.shape == torch.Size([batch_size, self.num_tokens, self.embedding_size])\n",
    "        x = self.transformer_decoder(x, problems) # [batch_size, K, 768] -> [batch_size, K, 768] (problems is [batch_size, num_tokens, 768])\n",
    "        assert x.shape == torch.Size([batch_size, self.K, self.embedding_size])\n",
    "        \n",
    "        # -------------------------------------------------------------------------------\n",
    "        # Step 2 - decoding the output into three embeddings of size 768 (op, num1, num2)\n",
    "        # -------------------------------------------------------------------------------\n",
    "        x = self.exp_decoder(x) # [batch_size, K, 768] -> [batch_size, K, 2304]\n",
    "        assert x.shape == torch.Size([batch_size, self.K, self.embedding_size*3])\n",
    "        operation, x1, x2 = torch.split(x, self.embedding_size, dim=2) # [batch_size, K, 2304] -> [batch_size, K, 768] for each\n",
    "        assert operation.shape == torch.Size([batch_size, self.K, self.embedding_size])\n",
    "        assert x1.shape == torch.Size([batch_size, self.K, self.embedding_size])\n",
    "        assert x2.shape == torch.Size([batch_size, self.K, self.embedding_size])\n",
    "\n",
    "        # -----------------------------------------------------------------------------------------------\n",
    "        # Step 3 and 4 - Finding the softmax for the similarity between the predicted and true embeddings\n",
    "        # -----------------------------------------------------------------------------------------------\n",
    "        # making sure params have correct dimension\n",
    "        nums_expanded = nums[:,None,:].expand(-1,self.K,-1) # [number_of_nums, 768] -> [number_of_nums, K, 768]\n",
    "        assert nums_expanded.shape == torch.Size([num_nums, self.K, self.embedding_size])\n",
    "        ops = ops[None,None,:,:].repeat(batch_size,self.K,1,1) # [num_ops, 768] -> [batch_size, K, num_ops, 768]\n",
    "        assert ops.shape == torch.Size([batch_size, self.K, num_ops, self.embedding_size])\n",
    "\n",
    "        # dot product - calculating the similarity between each op/num prediction and its true embedding\n",
    "        num1 = (x1[num_idx]*nums_expanded).sum(dim=2) # [number_of_nums, K]\n",
    "        assert num1.shape == torch.Size([num_nums, self.K])\n",
    "        num2 = (x2[num_idx]*nums_expanded).sum(dim=2) # [number_of_nums, K]        \n",
    "        assert num2.shape == torch.Size([num_nums, self.K])\n",
    "        op = operation[:,:,None,:].expand(-1,-1,num_ops,-1) # [batch_size, K, 768] -> # [batch_size, K, num_ops, 768]\n",
    "        assert op.shape == torch.Size([batch_size, self.K, num_ops, self.embedding_size])\n",
    "        op = (op*ops).sum(dim=3) # [batch_size, K, num_ops, 768] -> [batch_size, K, num_ops]\n",
    "        assert op.shape == torch.Size([batch_size, self.K, num_ops])\n",
    "\n",
    "        # softmax\n",
    "        op = self.op_softmax(op) # [batch_size, K, num_ops] (ie op[1,2] would be the operator prediction probabilities for problem2, query3)\n",
    "        assert op.shape == torch.Size([batch_size, self.K, num_ops])\n",
    "        assert op.sum(dim=2).sum()==batch_size*K\n",
    "        \n",
    "        num1 = self.__apply_to_nums(self.num_softmax, num1, num_idx, batch_size) # [num_nums, K]\n",
    "        assert num1.shape == torch.Size([num_nums, self.K])\n",
    "        assert np.isclose(num1[num_idx==0][:,0].sum().item(),1)\n",
    "        \n",
    "        num2 = self.__apply_to_nums(self.num_softmax, num2, num_idx, batch_size) # [num_nums, K]\n",
    "        assert num2.shape == torch.Size([num_nums, self.K])\n",
    "        assert np.isclose(num2[num_idx==0][:,0].sum().item(),1)\n",
    "        # ----------------------------------------------------\n",
    "        # Step 5 - creating embedding for the found expression  \n",
    "        # ----------------------------------------------------\n",
    "        x = self.exp_encoder(torch.cat((operation,x1,x2,x1*x2), dim=2)) # [batch_size, K, 3072] -> [batch_size, K, 768]  \n",
    "        assert x.shape == torch.Size([batch_size, self.K, self.embedding_size])\n",
    "\n",
    "        # -------------------------------------------------------------------------------------------\n",
    "        # Step 6 - finding valid, adding found expression to problem embeddings and number embeddings\n",
    "        # -------------------------------------------------------------------------------------------\n",
    "        # Getting predicted ops/nums and creating a problem index for what problem they refer to\n",
    "        op_ids = torch.argmax(op, dim=2) # [batch_size, K]\n",
    "        assert op_ids.shape == torch.Size([batch_size, self.K])\n",
    "        assert op_ids.max() < num_ops and op_ids.min() >= 0\n",
    "        mask = op_ids!=op2id['None'] # [batch_size, K]\n",
    "        assert mask.shape == torch.Size([batch_size, self.K])\n",
    "        num1_ids = torch.stack(tuple([num1[num_idx==x].argmax(0) for x in range(batch_size)])) # [batch_size, K]\n",
    "        assert num1_ids.shape == torch.Size([batch_size, self.K])\n",
    "        assert num1_ids.max() < num_idx[num_idx==num1_ids.argmax()//self.K].shape[0] and num1_ids.min() >= 0\n",
    "        num2_ids = torch.stack(tuple([num2[num_idx==x].argmax(0) for x in range(batch_size)])) # [batch_size, K]\n",
    "        assert num2_ids.shape == torch.Size([batch_size, self.K])\n",
    "        assert num2_ids.max() < num_idx[num_idx==num2_ids.argmax()//self.K].shape[0] and num2_ids.min() >= 0\n",
    "        problem_idx = torch.arange(mask.shape[0]).to(self.device).repeat_interleave(K)[mask.flatten()] # [num_valid,]\n",
    "        num_valid = mask.sum()\n",
    "        assert len(problem_idx) == num_valid\n",
    "        \n",
    "        # Figuring out and keeping track of what equations each label corresponds to (to avoid duplicates/for loss calculation)\n",
    "        eq2id, id2eq, mask = self.__update_labels(eq2id, id2eq, mask, problem_idx, num1_ids, num2_ids, batch_size, num_idx)\n",
    "        assert len(eq2id) == batch_size and len(id2eq) == batch_size\n",
    "\n",
    "        # Getting valid embeddings along with an updated problem index\n",
    "        num_valid = mask.sum()\n",
    "        valid = x[mask] # [num_valid, 768]\n",
    "        assert valid.shape == torch.Size([num_valid, 768])\n",
    "        problem_idx = torch.arange(mask.shape[0]).to(self.device).repeat_interleave(K)[mask.flatten()] # [num_valid,]\n",
    "        assert len(problem_idx) == num_valid\n",
    "\n",
    "        # Appending to num_embeddings\n",
    "        nums = torch.cat((nums, valid), dim=0) # [num_nums+num_valid, 768]\n",
    "        assert nums.shape == torch.Size([num_valid+num_nums, self.embedding_size])\n",
    "        num_idx = torch.cat((num_idx, problem_idx), dim=0) # [num_nums+num_valid,]\n",
    "        assert len(num_idx) == num_valid+num_nums\n",
    "\n",
    "        # Updating problem embeddings\n",
    "        temp = torch.clone(x)\n",
    "        temp[~mask] = 0 # [batch_size, K, 768] # CONSIDER CHANGING THIS (rn just setting invalid to zero)\n",
    "        assert temp.shape == torch.Size([batch_size, self.K, 768])\n",
    "        problems = torch.cat((problems,temp),dim=1) # [batch_size, num_tokens+K, 768]\n",
    "        assert problems.shape == torch.Size([batch_size, self.num_tokens+self.K, self.embedding_size])\n",
    "        problems = self.prob_encoder(problems.permute(0,2,1)) # [batch_size, 768, num_tokens]\n",
    "        assert problems.shape == torch.Size([batch_size, self.embedding_size, self.num_tokens])\n",
    "        problems = problems.permute(0,2,1) # [batch_size, num_tokens, 768]\n",
    "        assert problems.shape == torch.Size([batch_size, self.num_tokens, self.embedding_size])\n",
    "        \n",
    "        # -----------------------\n",
    "        # Returning final results\n",
    "        # -----------------------\n",
    "        return x, op, num1, num2, nums, num_idx, problems, eq2id, id2eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea8221de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x: [batch_size, K, 768]\n",
    "# nums: [num_nums, 768]\n",
    "# num_idx: [num_nums,]\n",
    "# ops: [num_ops, 768]\n",
    "# problems: [batch_size, num_tokens, 768]\n",
    "try:\n",
    "    seed = 3\n",
    "    with open(f'{OBJ_DIR}embeddings/train/batch0.pickle', 'rb') as f:\n",
    "        embeddings = pickle.load(f)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    x = torch.rand(8,6,768)\n",
    "    model = MultiLayerDecoder(768, 392, 8, 6, 'cpu')\n",
    "    #model.to('cuda:0')\n",
    "    result = model(x, embeddings)\n",
    "finally:\n",
    "    #del embeddings\n",
    "    del model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119fa863-d541-4152-b0f6-95ad9ebf9321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11664bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "936b279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_exp(name):\n",
    "#     reorder = lambda x: (x[1], x[0], x[2])\n",
    "#     convert_to_arr = lambda d: [[reorder(tuple(x.split())),idx] for idx, arr in enumerate(d.split(' ; ')) for x in eval(arr) if x is not None]\n",
    "#     return data[name]['incremental'].map(convert_to_arr)\n",
    "\n",
    "# exp = get_exp('train')\n",
    "# id2const = {v:k for k, v in const2id.items()}\n",
    "\n",
    "# num_literals = embeddings['num_literals']\n",
    "# num_idx = np.array(embeddings['num_idx'])\n",
    "# layer_idx = []\n",
    "# num1_labels = []\n",
    "# num2_labels = []\n",
    "# op_labels = []\n",
    "# results = []\n",
    "# for p in range(len(exp)):\n",
    "#     for (op, num1, num2), layer in exp[p]:\n",
    "#         try:\n",
    "#             num1_labels.append(process_num(num1, num_literals, num_idx, p, (num1_labels, num2_labels)))\n",
    "#             num2_labels.append(process_num(num2, num_literals, num_idx, p, (num1_labels, num2_labels)))\n",
    "#         except:\n",
    "#             print(num1)\n",
    "#             print(p)\n",
    "#             print(num2)\n",
    "#             raise\n",
    "#         op_labels.append(op2id[op])\n",
    "#         layer_idx.append(layer)\n",
    "#     results.append((op_labels, num1_labels, num2_labels, layer_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48f4f3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([1, 0, 2, 3, 1], [3, 3, (3, 1), ((3, 1), 3), (((3, 1), 3), (3, 0))], [0, 1, 3, (3, 0), 3], [0, 0, 1, 2, 3]), ([3, 2, 0, 2, 4, 2, 1, 1], [0, 1, (0, 8), (1, (0, 8)), ((0, 8), 3), 1, (1, (((0, 8), 3), 2)), ((1, (((0, 8), 3), 2)), 1)], [8, (0, 8), 3, 2, 2, (((0, 8), 3), 2), 1, ((1, (0, 8)), 2)], [0, 1, 1, 2, 2, 3, 4, 5]), ([0, 0, 2], [0, (0, 1), (0, 1)], [1, 1, ((0, 1), 1)], [0, 1, 2]), ([2, 0, 0, 0], [2, (2, 0), ((2, 0), 4), ((2, 0), 4)], [0, 4, 4, (((2, 0), 4), 4)], [0, 1, 2, 3]), ([4, 2, 4, 2, 2, 3], [0, 3, 2, 7, (2, 5), ((2, 5), (3, 7))], [5, 7, 5, (0, 5), (3, 7), (7, (0, 5))], [0, 0, 0, 1, 1, 2]), ([0, 0, 3, 3, 2], [0, 9, (0, 1), (9, 2), ((9, 2), 9)], [1, 2, 4, 9, ((0, 1), 4)], [0, 0, 1, 1, 2]), ([3, 2, 2], [1, (1, 0), ((1, 0), 3)], [0, 3, 2], [0, 1, 2]), ([1, 3, 2, 0, 0], [9, 0, (9, 1), (0, 9), ((0, 9), ((9, 1), 9))], [1, 9, 9, ((9, 1), 9), 6], [0, 0, 1, 2, 3])]\n"
     ]
    }
   ],
   "source": [
    "num_per_batch = 8\n",
    "\n",
    "def get_exp(name):\n",
    "    reorder = lambda x: (x[1], x[0], x[2])\n",
    "    convert_to_arr = lambda d: [[reorder(tuple(x.split())),idx] for idx, arr in enumerate(d.split(' ; ')) for x in eval(arr) if x is not None]\n",
    "    return data[name]['incremental'].map(convert_to_arr)\n",
    "\n",
    "def non_homogeneous_split(arr, num_per_batch):\n",
    "    return [arr[idx:idx+num_per_batch] for idx in range(0,len(arr),num_per_batch)]\n",
    "\n",
    "def process_num(num, literals, idx, prob, prev):\n",
    "    if num in const2val:\n",
    "        return np.where((literals[idx==prob]==num))[0][0]\n",
    "    elif 'x' in num:\n",
    "        eq_idx = int(num[1:])-1\n",
    "        return (prev[0][eq_idx], prev[1][eq_idx])\n",
    "    else:\n",
    "        return np.where((literals[idx==prob]==str(float(num))))[0][0]\n",
    "\n",
    "def process_exp(num_idx, literals, exp, p):\n",
    "    op_labels = []\n",
    "    num1_labels = []\n",
    "    num2_labels = []\n",
    "    layer_idx = []\n",
    "    for (op, num1, num2), layer in exp:\n",
    "        num1_labels.append(process_num(num1, literals, num_idx, p, (num1_labels, num2_labels)))\n",
    "        num2_labels.append(process_num(num2, literals, num_idx, p, (num1_labels, num2_labels)))\n",
    "        op_labels.append(op2id[op])\n",
    "        layer_idx.append(layer)\n",
    "    return op_labels, num1_labels, num2_labels, layer_idx\n",
    "\n",
    "def process_batch(num_idx, literals, expressions):\n",
    "    results = []\n",
    "    for p,exp in enumerate(expressions):\n",
    "        results.append(process_exp(num_idx, literals, exp, p))\n",
    "    return results\n",
    "    \n",
    "name = 'test'\n",
    "exp = exp = non_homogeneous_split(get_exp(name).tolist(), num_per_batch)\n",
    "directory = f'{OBJ_DIR}embeddings/{name}'\n",
    "for batch_num, f in enumerate(os.listdir(f'{OBJ_DIR}embeddings/{name}')):\n",
    "    f = os.path.join(directory, f)\n",
    "    with open(f, 'rb') as f:\n",
    "        embeddings = pickle.load(f)\n",
    "    results = process_batch(embeddings['num_idx'], embeddings['num_literals'], exp[batch_num])\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae1ee082-d1f1-4e89-9e32-c197d2ebd1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 1, 1, 2, 3, 3, 4, 4, 4, 4, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings['num_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec563fda-92de-4399-896f-93cd0d3246e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
