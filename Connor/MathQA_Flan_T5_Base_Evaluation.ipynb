{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14f8b8a5",
   "metadata": {},
   "source": [
    "# Flan T5 Base Version Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848f11f2",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c51c15b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import pickle\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import unittest\n",
    "import torch\n",
    "import evaluate\n",
    "import anytree\n",
    "from anytree.importer import DictImporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a889156",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 6\n",
    "MAX_LAYERS = 8\n",
    "MAX_TOKENS = 392\n",
    "EMBEDDING_SIZE = 768\n",
    "\n",
    "DATA_PATH = './dataset/'\n",
    "SET_NAMES = ['train', 'validation', 'test']\n",
    "MODEL = 'google/flan-t5-base'\n",
    "MODEL_PATH = f'models/{MODEL.split(\"/\")[-1]}-MathQA'\n",
    "DEVICE = 'cuda:0'\n",
    "NUM_MASK = '<num>'\n",
    "WORKING_DIR = 'TEMP/'\n",
    "\n",
    "OBJ_DIR = 'pickle/'\n",
    "\n",
    "\n",
    "class Op(Enum):\n",
    "    ADD = '+'\n",
    "    SUB = '-'\n",
    "    MULT = '*'\n",
    "    DIV = '/'\n",
    "    POW = '^'\n",
    "    \n",
    "class Const(Enum):\n",
    "    CONST_NEG_1 = 'const_neg_1' # I added this\n",
    "    CONST_0_25 = 'const_0_25'\n",
    "    CONST_0_2778 = 'const_0_2778'\n",
    "    CONST_0_33 = 'const_0_33'\n",
    "    CONST_0_3937 = 'const_0_3937'\n",
    "    CONST_1 = 'const_1'\n",
    "    CONST_1_6 = 'const_1_6'\n",
    "    CONST_2 = 'const_2'\n",
    "    CONST_3 = 'const_3'\n",
    "    CONST_PI = 'const_pi'\n",
    "    CONST_3_6 = 'const_3_6'\n",
    "    CONST_4 = 'const_4'\n",
    "    CONST_5 = 'const_5'\n",
    "    CONST_6 = 'const_6'\n",
    "    CONST_10 = 'const_10'\n",
    "    CONST_12 = 'const_12'\n",
    "    CONST_26 = 'const_26'\n",
    "    CONST_52 = 'const_52'\n",
    "    CONST_60 = 'const_60'\n",
    "    CONST_100 = 'const_100'\n",
    "    CONST_180 = 'const_180'\n",
    "    CONST_360 = 'const_360'\n",
    "    CONST_1000 = 'const_1000'\n",
    "    CONST_3600 = 'const_3600'\n",
    "\n",
    "values = [-1, 0.25, 0.2778, 0.33, 0.3937, 1, 1.6, 2, 3, 3.1416, 3.6, 4, 5, 6, 10, 12, 26, 52, 60, 100, 180, 360, 1000, 3600]\n",
    "const2val = {k:v for k,v in zip(Const._value2member_map_.keys(), values)}    \n",
    "\n",
    "op2id = {k:v for k,v in zip(Op._value2member_map_.keys(), range(len(Op._value2member_map_)))}\n",
    "op2id['None'] = 5\n",
    "id2op = np.array(list(op2id.keys()))\n",
    "const2id = {k:v for k,v in zip(Const._value2member_map_.keys(), range(len(Const._value2member_map_)))}\n",
    "id2const = np.array(list(const2id.keys()))\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "class Util():\n",
    "    def load_obj(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            o = pickle.load(f)\n",
    "        return o\n",
    "    \n",
    "    def save_obj(self, path, o):\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(o, f)\n",
    "            \n",
    "    def load_data(self):\n",
    "        return {name:pd.read_csv(f'{DATA_PATH}{name}.csv') for name in SET_NAMES}\n",
    "    \n",
    "    def set_seed(self, seed):\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "util = Util()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28586a1d",
   "metadata": {},
   "source": [
    "## Constructing the Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6ae9c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(arr):\n",
    "    idx = np.concatenate([[i]*len(x) for i,x in enumerate(arr)])\n",
    "    flattened = np.concatenate(arr) \n",
    "    return idx, flattened\n",
    "\n",
    "def get_nums_and_mask(data):\n",
    "    nums = {name:[] for name in SET_NAMES}\n",
    "    problems = {name:[] for name in SET_NAMES}\n",
    "    num_idx = {name:[] for name in SET_NAMES}\n",
    "    for name in SET_NAMES:\n",
    "        for i,problem in enumerate(data[name].problem):\n",
    "            num = re.compile('([+-]?((\\d+(\\.\\d*)?)|(\\.\\d+)))') # normal num\n",
    "            big = re.compile(r'(-?\\d{1,3}(,\\d{3})+(\\.\\d*)?)') # num with comma\n",
    "\n",
    "            big_results = re.finditer(big, problem)\n",
    "            problem = re.sub(big, NUM_MASK, problem)        \n",
    "            num_results = re.finditer(num, problem)\n",
    "            problem = re.sub(num, NUM_MASK, problem)\n",
    "\n",
    "            # Getting the combined numbers in order of occurence\n",
    "            combined = [x for x in num_results]\n",
    "            combined.extend([x for x in big_results])\n",
    "            combined = sorted(combined, key=lambda x: x.start(0))\n",
    "\n",
    "            combined = [float(x.group(0).replace(',','')) for x in combined]\n",
    "\n",
    "            nums[name].append(np.array(combined))\n",
    "            problems[name].append(problem)\n",
    "        num_idx[name], nums[name] = flatten(np.array(nums[name], dtype=object))\n",
    "        problems[name] = np.array(problems[name])\n",
    "    return {name:{'idx':torch.tensor(num_idx[name]), 'literals':nums[name]} for name in SET_NAMES}, problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f620b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = util.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e506d7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "op = util.load_obj(f'{OBJ_DIR}ops.pickle')\n",
    "const = util.load_obj(f'{OBJ_DIR}constants.pickle')\n",
    "subexp = util.load_obj(f'{OBJ_DIR}subexp.pickle')\n",
    "nums,_ = get_nums_and_mask(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b817747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text preprocessing\n",
    "def determine_if_int(num):\n",
    "    if float(num).is_integer():\n",
    "        return int(float(num))\n",
    "    else:\n",
    "        return float(num)\n",
    "\n",
    "def str_numpy(arr, t=None):\n",
    "    if t == 'num':\n",
    "        convert = lambda x: str(determine_if_int(x))\n",
    "    elif t == 'eq':\n",
    "        split = lambda x: x.split()\n",
    "        convert_split = lambda x: f'{x[1]} {process_num(x[0])} {process_num(x[2])}'\n",
    "        convert = lambda x: convert_split(split(x))        \n",
    "    else:\n",
    "        convert = lambda x: str(x)\n",
    "        \n",
    "    output = '{'\n",
    "    if len(arr) > 0:\n",
    "        output += f'{convert(arr[0])}'\n",
    "        for x in arr[1:]:\n",
    "            output += f', {convert(x)}'\n",
    "    output += '}'\n",
    "    return output   \n",
    "\n",
    "def process_num(num):\n",
    "    if num in const2val:\n",
    "        return str(determine_if_int(const2val[num]))\n",
    "    else:\n",
    "        return str(determine_if_int(num))\n",
    "    \n",
    "# label preprocessing\n",
    "importer =  DictImporter()\n",
    "def process_item(item):\n",
    "    if item in id2op:\n",
    "        return str(item)\n",
    "    elif item in const2val:\n",
    "        return str(determine_if_int(const2val[item]))\n",
    "    else:\n",
    "        return str(determine_if_int(item))\n",
    "\n",
    "def convert_to_preorder(name):\n",
    "    labels = []\n",
    "    for tree in data[name]['tree']:\n",
    "        root = importer.import_(eval(tree))\n",
    "        output = ''\n",
    "        for node in anytree.PreOrderIter(root):\n",
    "            output += process_item(node.name) + ' '\n",
    "        labels.append(output[0:-1])\n",
    "    return labels\n",
    "     \n",
    "# main function\n",
    "def prompt_engineering(name):\n",
    "    eq, eq_idx = subexp[name]\n",
    "    eq = np.array(eq)\n",
    "    eq_idx = np.array(eq_idx)\n",
    "    idx = nums[name]['idx']\n",
    "    literals = nums[name]['literals']\n",
    "    engineered = []\n",
    "    \n",
    "    for i in range(len(data[name])):\n",
    "        ops = str_numpy(id2op[0:-1][op['pred'][name][i].astype(bool)])\n",
    "        constants = id2const[const['pred'][name][i].astype(bool)]\n",
    "        constants = str_numpy([const2val[x] for x in constants], t='num')\n",
    "        numbers = str_numpy(literals[idx==i], t='num')\n",
    "        equations = str_numpy(eq[eq_idx==i], t='eq')\n",
    "        problem = data[name]['problem'][i]\n",
    "        prompt = f'Find the mathematical formula given: numbers: {numbers}, constants: {constants}, operations: {ops}, and potential subexpressions: {equations} for problem: \"{problem}\"'\n",
    "        engineered.append(prompt)\n",
    "        \n",
    "    return engineered\n",
    "\n",
    "#labels = {name:data[name]['formula_no_const'].str.replace(r'(\\d)\\.0(\\s|\\))', r'\\1\\2', regex=True).str.replace(' ','') for name in SET_NAMES}\n",
    "engineered = {name:Dataset.from_dict({'text':prompt_engineering(name), 'label':convert_to_preorder(name)}) for name in SET_NAMES}\n",
    "engineered = DatasetDict(engineered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf581614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Find the mathematical formula given: numbers: {3, 10, 36}, constants: {1, 2, 100}, operations: {*, /}, and potential subexpressions: {* 3 10, * 36 100} for problem: \"the banker \\' s gain of a certain sum due 3 years hence at 10 % per annum is rs . 36 . what is the present worth ?\"',\n",
       " 'label': '/ * 100 / * 36 100 * 3 10 * 3 10'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engineered['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8304c627",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dc34cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_PATH)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer)\n",
    "max_source = 512\n",
    "max_target = 186 # The amount needed to emcompass all equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9acf1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18215 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2710 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenization(batch):\n",
    "    tokenized = tokenizer(text = batch['text'], max_length = max_source, truncation = True)\n",
    "    labels = tokenizer(text_target = batch['label'], max_length = max_source, truncation = True)\n",
    "    tokenized['labels'] = labels['input_ids']   \n",
    "    return tokenized\n",
    "\n",
    "tokenized = engineered.map(tokenization, batched=True, remove_columns=['text','label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eb54b5",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f125b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "grad_acc = 4\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    WORKING_DIR,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=1000,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1000,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    learning_rate=5e-5, # learning rates around this worked well for other models trained with this dataset\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=48,\n",
    "    gradient_accumulation_steps=grad_acc,\n",
    "    weight_decay=.01, # to maintain consistency with pytorch AdamW optimizer\n",
    "    save_total_limit=3, # ensures dont run out of disk space\n",
    "    num_train_epochs=5,\n",
    "    predict_with_generate=True, # allows the use of rouge and bleu metrics\n",
    "    load_best_model_at_end=True,\n",
    "    #optim = 'adamw_bnb_8it', # Have to use a quantized optimizer to make it possible to fit within memory\n",
    "    metric_for_best_model=\"exact_match\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85397218",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_metric = evaluate.load('rouge')\n",
    "bleu_metric = evaluate.load('bleu')\n",
    "def compute_metrics(p):\n",
    "    predictions = p[0]\n",
    "    labels = p[1]\n",
    "    pred_decode = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    # the data collator will pad labels with -100 (to signal that they should not be used in loss calculation)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    label_decode = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # rouge (recall)\n",
    "    scores = rouge_metric.compute(predictions=pred_decode, references=label_decode, use_stemmer=False)\n",
    "    \n",
    "    # exact match\n",
    "    exact = (np.array(pred_decode)==np.array(label_decode)).sum()/len(pred_decode)\n",
    "    scores['exact_match'] = exact\n",
    "    \n",
    "    # getting scores\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b2dde4",
   "metadata": {},
   "source": [
    "Setting a seed for consistent results upon rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c0862f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6142769",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized['train'],\n",
    "    eval_dataset=tokenized['validation'],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0be010da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='475' max='380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [380/380 10:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5919688940048218,\n",
       " 'eval_rouge1': 0.8151064393599454,\n",
       " 'eval_rouge2': 0.6542444559862957,\n",
       " 'eval_rougeL': 0.7535839200416939,\n",
       " 'eval_rougeLsum': 0.7535159473532993,\n",
       " 'eval_exact_match': 0.24682953609662367,\n",
       " 'eval_runtime': 500.6983,\n",
       " 'eval_samples_per_second': 36.379,\n",
       " 'eval_steps_per_second': 0.759}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8ce8ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.739315390586853,\n",
       " 'eval_rouge1': 0.7942445016491037,\n",
       " 'eval_rouge2': 0.6106951187204306,\n",
       " 'eval_rougeL': 0.726083327128735,\n",
       " 'eval_rougeLsum': 0.7262423098862572,\n",
       " 'eval_exact_match': 0.23542435424354244,\n",
       " 'eval_runtime': 73.9373,\n",
       " 'eval_samples_per_second': 36.653,\n",
       " 'eval_steps_per_second': 0.771}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a76a41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7559190988540649,\n",
       " 'eval_rouge1': 0.7886660246446813,\n",
       " 'eval_rouge2': 0.5951842411548467,\n",
       " 'eval_rougeL': 0.7216962491502438,\n",
       " 'eval_rougeLsum': 0.7217407298735798,\n",
       " 'eval_exact_match': 0.22469410456062291,\n",
       " 'eval_runtime': 51.2005,\n",
       " 'eval_samples_per_second': 35.117,\n",
       " 'eval_steps_per_second': 0.742}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b826331f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
