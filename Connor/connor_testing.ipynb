{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb9ed0c0",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a550408",
   "metadata": {},
   "source": [
    "* [Preparing the data](#first)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966c08c6",
   "metadata": {},
   "source": [
    "#### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6e3a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, TrainingArguments, Trainer, AutoModelForQuestionAnswering\n",
    "from trl import SFTTrainer\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a514869",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "802e4c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = r'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'\n",
    "#TEST_MODEL = r\"tiiuae/falcon-rw-1b\"\n",
    "TEST_MODEL = r\"bert-base-uncased\"\n",
    "MATHEMATICS_DATASET = r'D:\\jupyter_notebooks\\datasets\\mathematics_dataset\\mathematics_dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d3ff26",
   "metadata": {},
   "source": [
    "## Preparing the data <a class=\"anchor\" id=\"first\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5538a30b",
   "metadata": {},
   "source": [
    "Can get the dataset from https://console.cloud.google.com/storage/browser/mathematics-dataset;tab=objects?prefix=&forceOnObjectsSortingFiltering=false. I use just the arithmetic type problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c2dfa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_mathematics(path=MATHEMATICS_DATASET, subject_list=['arithmetic']):\n",
    "    df = pd.DataFrame()\n",
    "    levels = []\n",
    "    subjects = []\n",
    "    problem_types = []\n",
    "    problems = []\n",
    "    answers = []\n",
    "\n",
    "    for subdir, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if 'train' in subdir:\n",
    "                level = subdir[subdir.rindex('-')+1:] # the problem level is indicated after a - character in the directory name\n",
    "                subject, problem_type = file.split('__') # splitting file name into subject/type\n",
    "                problem_type = problem_type[:-4] # Removing .txt extension\n",
    "\n",
    "                # Only looking at some subjects\n",
    "                if subject in subject_list:\n",
    "                    # Reading the data from the file\n",
    "                    with open(os.path.join(subdir,file), 'r') as f:\n",
    "                        prob = ans = True\n",
    "                        while prob and ans:\n",
    "                            prob = f.readline().strip()\n",
    "                            ans = f.readline().strip()\n",
    "\n",
    "                            # Creating row\n",
    "                            levels.append(level)\n",
    "                            subjects.append(subject)\n",
    "                            problem_types.append(problem_type)\n",
    "                            problems.append(prob)\n",
    "                            answers.append(ans)          \n",
    "                            \n",
    "    # Creating the dataframe\n",
    "    df['level'] = levels\n",
    "    df['subject'] = subjects\n",
    "    df['problem_type'] = problem_types\n",
    "    df['problem'] = problems\n",
    "    df['answer'] = answers\n",
    "    \n",
    "    # Cleaning up the notebook environment\n",
    "    del levels\n",
    "    del subjects\n",
    "    del problem_types\n",
    "    del problems\n",
    "    del answers\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74b468a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_mathematics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bc2c29",
   "metadata": {},
   "source": [
    "#### creating splits (I think its like 400000, 50000, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fee05674",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df[df.level=='easy']\n",
    "temp = temp.drop(columns=['level', 'subject'])\n",
    "temp = temp.rename(columns={'problem':'text', 'answer':'label'})\n",
    "length = len(temp)\n",
    "\n",
    "train = temp.sample(int(length*.04))\n",
    "temp=temp.drop(train.index)\n",
    "train = Dataset.from_pandas(train, preserve_index=False)\n",
    "\n",
    "dev = temp.sample(int(length*.005))\n",
    "temp=temp.drop(dev.index)\n",
    "dev = Dataset.from_pandas(dev, preserve_index=False)\n",
    "\n",
    "test = temp.sample(int(length*.005))\n",
    "test = Dataset.from_pandas(test, preserve_index=False)\n",
    "del temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989f3cbc",
   "metadata": {},
   "source": [
    "#### tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08b91e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa240e603ee4a93b78a3ac44358b2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(TEST_MODEL)\n",
    "def tokenization(items):\n",
    "    tokenized = tokenizer(items['text'], max_length = 64, padding = 'max_length', truncation=True)\n",
    "    return tokenized\n",
    "\n",
    "def tokenization_labels(items):\n",
    "    tokenized = tokenizer(items['text'], max_length = 64, padding = 'max_length', truncation=True)\n",
    "    tokenized['label'] = tokenizer(items['label'], max_length = 64, padding = 'max_length', truncation=True)['input_ids']\n",
    "    return tokenized\n",
    "# train = train.map(tokenization, batched=True)\n",
    "# dev = dev.map(tokenization, batched=True)\n",
    "test = test.map(tokenization_labels, batched=True)\n",
    "# test_labels = test.map(tokenization_labels, batched=True)\n",
    "# test['label'] = test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09b95b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['problem_type', 'text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 30000\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0765b0",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57e5de80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\torch\\Lib\\site-packages\\trl\\trainer\\sft_trainer.py:125: UserWarning: You passed a model_id to the SFTTrainer. This will automatically create an `AutoModelForCausalLM` or a `PeftModel` (if you passed a `peft_config`) for you.\n",
      "  warnings.warn(\n",
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad753795d5d4ffe9238d238836ff728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/240000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d974a4856d0f4bdba08c38ccc6439e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = evaluate.load('f1')\n",
    "def compute_metrics(pred):\n",
    "    output, labels = pred\n",
    "    return metric.compute(predictions=np.argmax(output, axis=-1), references=labels)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(TEST_MODEL)\n",
    "#tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir='./temp',\n",
    "    evaluation_strategy=\"epoch\", # Reports the metric after each epoch\n",
    "    per_device_train_batch_size = 16,\n",
    "    per_device_eval_batch_size = 16,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = TEST_MODEL,\n",
    "    args = args,\n",
    "    train_dataset = train,\n",
    "    eval_dataset = dev,\n",
    "    #compute_metrics = compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=64,\n",
    "    #packing=True,\n",
    "    dataset_text_field='text',\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57e5eda",
   "metadata": {},
   "source": [
    "0 validation loss so theoretically worked perfectly for the basic arithmetic problems, but didnt look at the model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3c7bee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45000' max='45000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45000/45000 1:37:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=45000, training_loss=0.0034019357781870188, metrics={'train_runtime': 5845.2726, 'train_samples_per_second': 123.176, 'train_steps_per_second': 7.699, 'total_flos': 1.47913866661248e+16, 'train_loss': 0.0034019357781870188, 'epoch': 3.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "245fc488",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('bert_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "17e56bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem_type\n",
      "add_or_sub              53680\n",
      "add_or_sub_in_base      53637\n",
      "add_sub_multiple        52947\n",
      "div                     53488\n",
      "mixed                   53404\n",
      "mul                     53307\n",
      "mul_div_multiple        53400\n",
      "nearest_integer_root    53425\n",
      "simplify_surd           52712\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train.groupby('problem_type').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d8a335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5437792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7daf3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83419c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e326cb87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13e1f2de",
   "metadata": {},
   "source": [
    "Random code I was messing with, I was using the commented model in the constants for this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b697b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_amps_problem(path):\n",
    "    problem_ended = False\n",
    "    problem = ''\n",
    "    answer = ''\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line == 'Answer:\\n':\n",
    "                problem_ended = True\n",
    "            elif problem_ended:\n",
    "                answer += line\n",
    "            elif line != 'Problem:\\n':\n",
    "                problem += line\n",
    "    return problem, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3ce796f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Solve the following system of two equations: \\n$-\\\\frac{17 x}{\\\\sqrt{2}}-\\\\frac{y}{\\\\sqrt{2}}-\\\\frac{5}{\\\\sqrt{2}}=0$, $\\\\frac{13 x}{\\\\sqrt{2}}+\\\\frac{21 y}{\\\\sqrt{2}}+\\\\frac{27}{\\\\sqrt{2}}=0$\\n', '$x=-\\\\frac{39}{172}$, $y=-\\\\frac{197}{172}$')\n"
     ]
    }
   ],
   "source": [
    "print(separate_amps_problem(r\"D:\\jupyter_notebooks\\datasets\\amps\\amps\\mathematica\\algebra\\system_of_equations\\30.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58769e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(TEST_MODEL)\n",
    "pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=TEST_MODEL,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "112514ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: Compute the mean of ${9, -4}$.\n",
      "${9,-4} = {0, 2, 3}\n",
      "${9,-2} = {0,-3}\n",
      "${9,-1} = {-1,-3\n"
     ]
    }
   ],
   "source": [
    "sequences = pipeline(\n",
    "    r\"Compute the mean of ${9, -4}$.\",\n",
    "    max_length=50,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4f332f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
