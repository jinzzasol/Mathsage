{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14f8b8a5",
   "metadata": {},
   "source": [
    "# Flan T5 Base Version Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848f11f2",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c51c15b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import pickle\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import unittest\n",
    "import torch\n",
    "import evaluate\n",
    "import anytree\n",
    "from anytree.importer import DictImporter\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a889156",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 6\n",
    "MAX_LAYERS = 8\n",
    "MAX_TOKENS = 392\n",
    "EMBEDDING_SIZE = 768\n",
    "\n",
    "DATA_PATH = './dataset/'\n",
    "SET_NAMES = ['train', 'validation', 'test']\n",
    "MODEL = 'google/flan-t5-large'\n",
    "MODEL_PATH = f'models/{MODEL.split(\"/\")[-1]}-MathQA'\n",
    "DEVICE = 'cuda:0'\n",
    "NUM_MASK = '<num>'\n",
    "WORKING_DIR = 'TEMP/'\n",
    "\n",
    "OBJ_DIR = 'pickle/'\n",
    "\n",
    "\n",
    "class Op(Enum):\n",
    "    ADD = '+'\n",
    "    SUB = '-'\n",
    "    MULT = '*'\n",
    "    DIV = '/'\n",
    "    POW = '^'\n",
    "    \n",
    "class Const(Enum):\n",
    "    CONST_NEG_1 = 'const_neg_1' # I added this\n",
    "    CONST_0_25 = 'const_0_25'\n",
    "    CONST_0_2778 = 'const_0_2778'\n",
    "    CONST_0_33 = 'const_0_33'\n",
    "    CONST_0_3937 = 'const_0_3937'\n",
    "    CONST_1 = 'const_1'\n",
    "    CONST_1_6 = 'const_1_6'\n",
    "    CONST_2 = 'const_2'\n",
    "    CONST_3 = 'const_3'\n",
    "    CONST_PI = 'const_pi'\n",
    "    CONST_3_6 = 'const_3_6'\n",
    "    CONST_4 = 'const_4'\n",
    "    CONST_5 = 'const_5'\n",
    "    CONST_6 = 'const_6'\n",
    "    CONST_10 = 'const_10'\n",
    "    CONST_12 = 'const_12'\n",
    "    CONST_26 = 'const_26'\n",
    "    CONST_52 = 'const_52'\n",
    "    CONST_60 = 'const_60'\n",
    "    CONST_100 = 'const_100'\n",
    "    CONST_180 = 'const_180'\n",
    "    CONST_360 = 'const_360'\n",
    "    CONST_1000 = 'const_1000'\n",
    "    CONST_3600 = 'const_3600'\n",
    "\n",
    "values = [-1, 0.25, 0.2778, 0.33, 0.3937, 1, 1.6, 2, 3, 3.1416, 3.6, 4, 5, 6, 10, 12, 26, 52, 60, 100, 180, 360, 1000, 3600]\n",
    "const2val = {k:v for k,v in zip(Const._value2member_map_.keys(), values)}    \n",
    "\n",
    "op2id = {k:v for k,v in zip(Op._value2member_map_.keys(), range(len(Op._value2member_map_)))}\n",
    "op2id['None'] = 5\n",
    "id2op = np.array(list(op2id.keys()))\n",
    "const2id = {k:v for k,v in zip(Const._value2member_map_.keys(), range(len(Const._value2member_map_)))}\n",
    "id2const = np.array(list(const2id.keys()))\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "class Util():\n",
    "    def load_obj(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            o = pickle.load(f)\n",
    "        return o\n",
    "    \n",
    "    def save_obj(self, path, o):\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(o, f)\n",
    "            \n",
    "    def load_data(self):\n",
    "        return {name:pd.read_csv(f'{DATA_PATH}{name}.csv') for name in SET_NAMES}\n",
    "    \n",
    "    def set_seed(self, seed):\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "util = Util()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28586a1d",
   "metadata": {},
   "source": [
    "## Constructing the Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6ae9c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(arr):\n",
    "    idx = np.concatenate([[i]*len(x) for i,x in enumerate(arr)])\n",
    "    flattened = np.concatenate(arr) \n",
    "    return idx, flattened\n",
    "\n",
    "def get_nums_and_mask(data):\n",
    "    nums = {name:[] for name in SET_NAMES}\n",
    "    problems = {name:[] for name in SET_NAMES}\n",
    "    num_idx = {name:[] for name in SET_NAMES}\n",
    "    for name in SET_NAMES:\n",
    "        for i,problem in enumerate(data[name].problem):\n",
    "            num = re.compile('([+-]?((\\d+(\\.\\d*)?)|(\\.\\d+)))') # normal num\n",
    "            big = re.compile(r'(-?\\d{1,3}(,\\d{3})+(\\.\\d*)?)') # num with comma\n",
    "\n",
    "            big_results = re.finditer(big, problem)\n",
    "            problem = re.sub(big, NUM_MASK, problem)        \n",
    "            num_results = re.finditer(num, problem)\n",
    "            problem = re.sub(num, NUM_MASK, problem)\n",
    "\n",
    "            # Getting the combined numbers in order of occurence\n",
    "            combined = [x for x in num_results]\n",
    "            combined.extend([x for x in big_results])\n",
    "            combined = sorted(combined, key=lambda x: x.start(0))\n",
    "\n",
    "            combined = [float(x.group(0).replace(',','')) for x in combined]\n",
    "\n",
    "            nums[name].append(np.array(combined))\n",
    "            problems[name].append(problem)\n",
    "        num_idx[name], nums[name] = flatten(np.array(nums[name], dtype=object))\n",
    "        problems[name] = np.array(problems[name])\n",
    "    return {name:{'idx':torch.tensor(num_idx[name]), 'literals':nums[name]} for name in SET_NAMES}, problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f620b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = util.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e506d7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "op = util.load_obj(f'{OBJ_DIR}ops.pickle')\n",
    "const = util.load_obj(f'{OBJ_DIR}constants.pickle')\n",
    "subexp = util.load_obj(f'{OBJ_DIR}subexp.pickle')\n",
    "nums,_ = get_nums_and_mask(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b817747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text preprocessing\n",
    "def determine_if_int(num):\n",
    "    if float(num).is_integer():\n",
    "        return int(float(num))\n",
    "    else:\n",
    "        return float(num)\n",
    "\n",
    "def str_numpy(arr, t=None):\n",
    "    if t == 'num':\n",
    "        convert = lambda x: str(determine_if_int(x))\n",
    "    elif t == 'eq':\n",
    "        split = lambda x: x.split()\n",
    "        convert_split = lambda x: f'{x[1]} {process_num(x[0])} {process_num(x[2])}'\n",
    "        convert = lambda x: convert_split(split(x))        \n",
    "    else:\n",
    "        convert = lambda x: str(x)\n",
    "        \n",
    "    output = '{'\n",
    "    if len(arr) > 0:\n",
    "        output += f'{convert(arr[0])}'\n",
    "        for x in arr[1:]:\n",
    "            output += f', {convert(x)}'\n",
    "    output += '}'\n",
    "    return output   \n",
    "\n",
    "def process_num(num):\n",
    "    if num in const2val:\n",
    "        return str(determine_if_int(const2val[num]))\n",
    "    else:\n",
    "        return str(determine_if_int(num))\n",
    "    \n",
    "# label preprocessing\n",
    "importer =  DictImporter()\n",
    "def process_item(item):\n",
    "    if item in id2op:\n",
    "        return str(item)\n",
    "    elif item in const2val:\n",
    "        return str(determine_if_int(const2val[item]))\n",
    "    else:\n",
    "        return str(determine_if_int(item))\n",
    "\n",
    "def convert_to_preorder(name):\n",
    "    labels = []\n",
    "    for tree in data[name]['tree']:\n",
    "        root = importer.import_(eval(tree))\n",
    "        output = ''\n",
    "        for node in anytree.PreOrderIter(root):\n",
    "            output += process_item(node.name) + ' '\n",
    "        labels.append(output[0:-1])\n",
    "    return labels\n",
    "     \n",
    "# main function\n",
    "def prompt_engineering(name):\n",
    "    eq, eq_idx = subexp[name]\n",
    "    eq = np.array(eq)\n",
    "    eq_idx = np.array(eq_idx)\n",
    "    idx = nums[name]['idx']\n",
    "    literals = nums[name]['literals']\n",
    "    engineered = []\n",
    "    \n",
    "    for i in range(len(data[name])):\n",
    "        ops = str_numpy(id2op[0:-1][op['pred'][name][i].astype(bool)])\n",
    "        constants = id2const[const['pred'][name][i].astype(bool)]\n",
    "        constants = str_numpy([const2val[x] for x in constants], t='num')\n",
    "        numbers = str_numpy(literals[idx==i], t='num')\n",
    "        equations = str_numpy(eq[eq_idx==i], t='eq')\n",
    "        problem = data[name]['problem'][i]\n",
    "        prompt = f'Find the mathematical formula given: numbers: {numbers}, constants: {constants}, operations: {ops}, and potential subexpressions: {equations} for problem: \"{problem}\"'\n",
    "        engineered.append(prompt)\n",
    "        \n",
    "    return engineered\n",
    "\n",
    "#labels = {name:data[name]['formula_no_const'].str.replace(r'(\\d)\\.0(\\s|\\))', r'\\1\\2', regex=True).str.replace(' ','') for name in SET_NAMES}\n",
    "engineered = {name:Dataset.from_dict({'text':prompt_engineering(name), 'label':convert_to_preorder(name)}) for name in SET_NAMES}\n",
    "engineered = DatasetDict(engineered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf581614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Find the mathematical formula given: numbers: {3, 10, 36}, constants: {1, 2, 100}, operations: {*, /}, and potential subexpressions: {* 3 10, * 36 100} for problem: \"the banker \\' s gain of a certain sum due 3 years hence at 10 % per annum is rs . 36 . what is the present worth ?\"',\n",
       " 'label': '/ * 100 / * 36 100 * 3 10 * 3 10'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engineered['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8304c627",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dc34cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_PATH)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer)\n",
    "max_source = 512\n",
    "max_target = 186 # The amount needed to emcompass all equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9acf1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18215 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2710 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenization(batch):\n",
    "    tokenized = tokenizer(text = batch['text'], max_length = max_source, truncation = True)\n",
    "    labels = tokenizer(text_target = batch['label'], max_length = max_source, truncation = True)\n",
    "    tokenized['labels'] = labels['input_ids']   \n",
    "    return tokenized\n",
    "\n",
    "tokenized = engineered.map(tokenization, batched=True, remove_columns=['text','label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eb54b5",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f125b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "grad_acc = 4\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    WORKING_DIR,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=1000,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1000,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    learning_rate=5e-5, # learning rates around this worked well for other models trained with this dataset\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=grad_acc,\n",
    "    weight_decay=.01, # to maintain consistency with pytorch AdamW optimizer\n",
    "    save_total_limit=3, # ensures dont run out of disk space\n",
    "    num_train_epochs=5,\n",
    "    predict_with_generate=True, # allows the use of rouge and bleu metrics\n",
    "    load_best_model_at_end=True,\n",
    "    #optim = 'adamw_bnb_8it', # Have to use a quantized optimizer to make it possible to fit within memory\n",
    "    metric_for_best_model=\"exact_match\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85397218",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_metric = evaluate.load('rouge')\n",
    "bleu_metric = evaluate.load('bleu')\n",
    "def compute_metrics(p):\n",
    "    predictions = p[0]\n",
    "    labels = p[1]\n",
    "    pred_decode = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    # the data collator will pad labels with -100 (to signal that they should not be used in loss calculation)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    label_decode = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # rouge (recall)\n",
    "    scores = rouge_metric.compute(predictions=pred_decode, references=label_decode, use_stemmer=False)\n",
    "    \n",
    "    # exact match\n",
    "    exact = (np.array(pred_decode)==np.array(label_decode)).sum()/len(pred_decode)\n",
    "    scores['exact_match'] = exact\n",
    "    \n",
    "    # getting scores\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b2dde4",
   "metadata": {},
   "source": [
    "Setting a seed for consistent results upon rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c0862f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6142769",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized['train'],\n",
    "    eval_dataset=tokenized['validation'],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0be010da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2841' max='2277' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2277/2277 1:02:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.22416742146015167,\n",
       " 'eval_rouge1': 0.8929189520900334,\n",
       " 'eval_rouge2': 0.8182982474780891,\n",
       " 'eval_rougeL': 0.8698482791628894,\n",
       " 'eval_rougeLsum': 0.8697759898913384,\n",
       " 'eval_exact_match': 0.5994510019214933,\n",
       " 'eval_runtime': 2995.3355,\n",
       " 'eval_samples_per_second': 6.081,\n",
       " 'eval_steps_per_second': 0.76}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8ce8ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.45524704456329346,\n",
       " 'eval_rouge1': 0.851220752772899,\n",
       " 'eval_rouge2': 0.7371863917061456,\n",
       " 'eval_rougeL': 0.8182458846701604,\n",
       " 'eval_rougeLsum': 0.8183690287669403,\n",
       " 'eval_exact_match': 0.5243542435424354,\n",
       " 'eval_runtime': 450.4726,\n",
       " 'eval_samples_per_second': 6.016,\n",
       " 'eval_steps_per_second': 0.753}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a76a41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4675537645816803,\n",
       " 'eval_rouge1': 0.8562289607094349,\n",
       " 'eval_rouge2': 0.7378416279901248,\n",
       " 'eval_rougeL': 0.8214545453461344,\n",
       " 'eval_rougeLsum': 0.8214815098924417,\n",
       " 'eval_exact_match': 0.5305895439377085,\n",
       " 'eval_runtime': 310.6798,\n",
       " 'eval_samples_per_second': 5.787,\n",
       " 'eval_steps_per_second': 0.724}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83648b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\torch\\Lib\\site-packages\\transformers\\generation\\utils.py:1254: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "generated = []\n",
    "for x in DataLoader(tokenized['validation'], batch_size=8, collate_fn=data_collator):\n",
    "    ids = model.generate(x['input_ids'].cuda())\n",
    "    pred = tokenizer.batch_decode(ids, skip_special_tokens=True)\n",
    "    generated.append(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7c1f5e",
   "metadata": {},
   "source": [
    "T5 does not recognize '^' as a token and replaces it with \\<unk\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0df0b06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 5 4',\n",
       " '/ * * 2 3 10 * * 2 3 10',\n",
       " '/ 72 * 6 210',\n",
       " '- / * 1 1000 / 48 12 12',\n",
       " '/ * 650 - 100 + + 44 28 10 100',\n",
       " '/ 1 - / 1 3 - / 1 2 / 1 4',\n",
       " '/ - 160 90 160',\n",
       " '/ 800 - 1 / 1 3',\n",
       " '- 10 1',\n",
       " '/  16 / 1 2  25 / 1 2',\n",
       " '*  / * 1348.32 100 2 + 1 / 1 2 100',\n",
       " '/ - 282 * 10 6.2 40',\n",
       " '/ 135 - 1 + / 1 2 * / 1 2 /',\n",
       " '/ 600 - * 54 0.2778 * 36 0.2778',\n",
       " '* 2 * 3.1416 7',\n",
       " '/ / * 32 3.8 1.6 / / * 32 3.8 ',\n",
       " '+ / - * 7 2 * 7 2 3 - * 7 2 * 7',\n",
       " '* 2 / * 20 24 + 24 21',\n",
       " '- * 1200  + 1 / 20 100 6 1200',\n",
       " '/ * * * * * * * * * * * * * * * * *']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for batch in generated for x in batch][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3e721a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_special = []\n",
    "for x in DataLoader(tokenized['validation'], batch_size=8, collate_fn=data_collator):\n",
    "    ids = model.generate(x['input_ids'].cuda())\n",
    "    pred = tokenizer.batch_decode(ids, skip_special_tokens=False)\n",
    "    with_special.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "142dbd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_generated=[x.replace('<pad>','').replace('<unk>','^').replace('</s>','').strip() for batch in with_special for x in batch]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ffd4de",
   "metadata": {},
   "source": [
    "Replacing \\<unk\\> with '^' and seeing if it affects the accuracy. (it doesnt since the \\<unk\\> token is ignored for both true and predicted labels in the metrics function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2de4ab5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5243542435424354"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(real_generated)==np.array(engineered['validation']['label'])).sum()/len(real_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "689a67d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['^ 5 4',\n",
       " '/ * * 2 3 10 * * 2 3 10',\n",
       " '/ 72 * 6 210',\n",
       " '- / * 1 1000 / 48 12 12',\n",
       " '/ * 650 - 100 + + 44 28 10 100',\n",
       " '/ 1 - / 1 3 - / 1 2 / 1 4',\n",
       " '/ - 160 90 160',\n",
       " '/ 800 - 1 / 1 3',\n",
       " '- 10 1',\n",
       " '/ ^ 16 / 1 2 ^ 25 / 1 2',\n",
       " '* ^ / * 1348.32 100 2 + 1 / 1 2 100',\n",
       " '/ - 282 * 10 6.2 40',\n",
       " '/ 135 - 1 + / 1 2 * / 1 2 /',\n",
       " '/ 600 - * 54 0.2778 * 36 0.2778',\n",
       " '* 2 * 3.1416 7',\n",
       " '/ / * 32 3.8 1.6 / / * 32 3.8',\n",
       " '+ / - * 7 2 * 7 2 3 - * 7 2 * 7',\n",
       " '* 2 / * 20 24 + 24 21',\n",
       " '- * 1200 ^ + 1 / 20 100 6 1200',\n",
       " '/ * * * * * * * * * * * * * * * * *']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_generated[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "95752404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['^ 5 4',\n",
       " '- 1 ^ / 1 2 3',\n",
       " '/ 72 * 6 210',\n",
       " '- / * 1 1000 / 48 12 12',\n",
       " '/ * 650 - 100 + + 44 28 10 100',\n",
       " '/ 1 - / 1 3 - / 1 2 / 1 4',\n",
       " '/ - 160 90 160',\n",
       " '/ / 800 - 1 / 1 3 - 1 / 1 3',\n",
       " '* * -1 + 2 3 - 10 + 2 3',\n",
       " '/ ^ 16 / 1 2 ^ 25 / 1 2',\n",
       " '- ^ / * 1348.32 100 / 1200 100 / 1 2 ^ / * 1200 100 / 1200 100 / 1 2',\n",
       " '/ - 282 * 10 6.2 40',\n",
       " '/ 135 - 1 + / 1 2 * / 1 2 / 1 4',\n",
       " '/ 600 - * 54 0.2778 * 36 0.2778',\n",
       " '* 2 * 3.1416 7',\n",
       " '/ * / * 32 3.8 1.6 3.9 5.7',\n",
       " '+ / - * * 7 2 3 * 7 2 2 - * * 7 2 3 * 7 2',\n",
       " '* * / * 20 24 + 24 21 21 2',\n",
       " '- * 1200 ^ + 1 / 20 100 6 1200',\n",
       " '+ + * 8 100 * 1 10 9']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engineered['validation']['label'][0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaa527a",
   "metadata": {},
   "source": [
    "Correct example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4fb42db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Find the mathematical formula given: numbers: {25, 16}, constants: {1, 2, 3, 4, 100}, operations: {-, /, ^}, and potential subexpressions: {/ 1 2} for problem: \"two trains , one from howrah to patna and the other from patna to howrah , start simultaneously . after they meet , the trains reach their destinations after 25 hours and 16 hours respectively . the ratio of their speeds is ?\"'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engineered['validation']['text'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f970f780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: / ^ 16 / 1 2 ^ 25 / 1 2\n",
      "Pred: / ^ 16 / 1 2 ^ 25 / 1 2\n"
     ]
    }
   ],
   "source": [
    "print(f'True: {real_generated[9]}')\n",
    "print(f\"Pred: {engineered['validation']['label'][9]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cfcab3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Find the mathematical formula given: numbers: {7}, constants: {0.2778, 1, 2, 3, 3.1416, 3.6, 4, 10, 60, 100, 1000, 3600}, operations: {+, *, ^}, and potential subexpressions: {* 3.1416 7} for problem: \"calculate the circumference of a circular field whose radius is 7 centimeters .\"'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engineered['validation']['text'][14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f7546709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: * 2 * 3.1416 7\n",
      "Pred: * 2 * 3.1416 7\n"
     ]
    }
   ],
   "source": [
    "print(f'True: {real_generated[14]}')\n",
    "print(f\"Pred: {engineered['validation']['label'][14]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67215431",
   "metadata": {},
   "source": [
    "Incorrect example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b6da0718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Find the mathematical formula given: numbers: {20, 21, 24}, constants: {1, 2, 3, 10}, operations: {+, *, /}, and potential subexpressions: {* 20 24, + 21 24, + 24 21} for problem: \"a woman complete a journey in 20 hours . she travels first half of the journey at the rate of 21 km / hr and second half at the rate of 24 km / hr . find the total journey in km .\"'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engineered['validation']['text'][17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "08de2e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: * 2 / * 20 24 + 24 21\n",
      "Pred: * * / * 20 24 + 24 21 21 2\n"
     ]
    }
   ],
   "source": [
    "print(f'True: {real_generated[17]}')\n",
    "print(f\"Pred: {engineered['validation']['label'][17]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "237e780d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Find the mathematical formula given: numbers: {1, 0, 7, 9, 2, 0, 3, 2, 3, 1, 0, 8, 4, 9, 2, 6, 5, 6, 7, 8}, constants: {1, 2, 3, 4, 10}, operations: {+, -, *, /, ^}, and potential subexpressions: {} for problem: \"you need to unlock a secret code using following clues , can you ? here you have the clues : clue - 1 : 0 7 9 ( one of the numbers is correct and is placed in its correct position ) clue - 2 : 0 3 2 ( nothing is correct ) clue - 3 : 1 0 8 ( two numbers are correct but not placed at its correct position . ) clue - 4 : 9 2 6 ( one number is correct but not placed at its correct position . ) clue - 5 : 6 7 8 ( one number is correct but not placed at its correct position . )\"'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engineered['validation']['text'][19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8474da79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: / * * * * * * * * * * * * * * * * *\n",
      "Pred: + + * 8 100 * 1 10 9\n"
     ]
    }
   ],
   "source": [
    "print(f'True: {real_generated[19]}')\n",
    "print(f\"Pred: {engineered['validation']['label'][19]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d94096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
