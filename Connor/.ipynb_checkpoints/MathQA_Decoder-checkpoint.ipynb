{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03a5bb58",
   "metadata": {},
   "source": [
    "# MathQA Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3806a42d",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- IMPORTANT: FIX PREPROCESSING 2, SO LABELS ALLOW DUPLICATE EQUATIONS ON THE SAME LAYER (THIS IS NECESSARY)\n",
    "- Maybe increase problem embedding by a factor of 3?\n",
    "- Change masked num embeddings function so it usese predicted constants from constants.pickle\n",
    "- Consider doing the same for the operators\n",
    "- Finish forward propogation (test a pass)\n",
    "- Write custom loss function\n",
    "- test 1 full pass of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a10e4a1",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fffb4413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import os\n",
    "import anytree\n",
    "from anytree import RenderTree\n",
    "from anytree.importer import DictImporter\n",
    "import pandas as pd\n",
    "from itertools import permutations\n",
    "import seaborn as sns\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer, AutoModel, TrainingArguments, Trainer, AutoModelForMaskedLM, DataCollatorForLanguageModeling\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftModel\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import re\n",
    "import pickle\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f9991e",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d428a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 6\n",
    "MAX_LAYERS = 8\n",
    "MAX_TOKENS = 392\n",
    "EMBEDDING_SIZE = 768\n",
    "\n",
    "DATA_PATH = './dataset/'\n",
    "SET_NAMES = ['train', 'validation', 'test']\n",
    "ENCODER_MODEL = 'distilroberta-base' # A more optimized version of roberta obtaining 95% of its performance\n",
    "DEVICE = 'cuda:0'\n",
    "NUM_MASK = '<num>'\n",
    "WORKING_DIR = 'TEMP/'\n",
    "\n",
    "OBJ_DIR = 'pickle/'\n",
    "\n",
    "\n",
    "class Op(Enum):\n",
    "    ADD = '+'\n",
    "    SUB = '-'\n",
    "    MULT = '*'\n",
    "    DIV = '/'\n",
    "    POW = '^'\n",
    "    \n",
    "class Const(Enum):\n",
    "    CONST_NEG_1 = 'const_neg_1' # I added this\n",
    "    CONST_0_25 = 'const_0_25'\n",
    "    CONST_0_2778 = 'const_0_2778'\n",
    "    CONST_0_33 = 'const_0_33'\n",
    "    CONST_0_3937 = 'const_0_3937'\n",
    "    CONST_1 = 'const_1'\n",
    "    CONST_1_6 = 'const_1_6'\n",
    "    CONST_2 = 'const_2'\n",
    "    CONST_3 = 'const_3'\n",
    "    CONST_PI = 'const_pi'\n",
    "    CONST_3_6 = 'const_3_6'\n",
    "    CONST_4 = 'const_4'\n",
    "    CONST_5 = 'const_5'\n",
    "    CONST_6 = 'const_6'\n",
    "    CONST_10 = 'const_10'\n",
    "    CONST_12 = 'const_12'\n",
    "    CONST_26 = 'const_26'\n",
    "    CONST_52 = 'const_52'\n",
    "    CONST_60 = 'const_60'\n",
    "    CONST_100 = 'const_100'\n",
    "    CONST_180 = 'const_180'\n",
    "    CONST_360 = 'const_360'\n",
    "    CONST_1000 = 'const_1000'\n",
    "    CONST_3600 = 'const_3600'\n",
    "\n",
    "values = [-1, 0.25, 0.2778, 0.33, 0.3937, 1, 1.6, 2, 3, math.pi, 3.6, 4, 5, 6, 10, 12, 26, 52, 60, 100, 180, 360, 1000, 3600]\n",
    "const2val = {k:v for k,v in zip(Const._value2member_map_.keys(), values)}    \n",
    "\n",
    "op2id = {k:v for k,v in zip(Op._value2member_map_.keys(), range(len(Op._value2member_map_)))}\n",
    "op2id['None'] = 5\n",
    "const2id = {k:v for k,v in zip(Const._value2member_map_.keys(), range(len(Const._value2member_map_)))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda851b7",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d5bd5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {name:pd.read_csv(f'{DATA_PATH}{name}.csv') for name in SET_NAMES}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ad07be",
   "metadata": {},
   "source": [
    "## Embedding Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a415f6",
   "metadata": {},
   "source": [
    "Converting number embeddings to masked tensors (to ensure they are all homogeneous) and adding in constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7736e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_masked_embeddings(name):\n",
    "#     num_embed = embeddings[name]['num']\n",
    "#     const_embed = embeddings[name]['num']\n",
    "#     mapping, nums = embeddings[name]['num_mapping']\n",
    "#     const = [[num for num in eval(x) if num in const2val] for x in data[name]['nums']]\n",
    "#     max_nums = (np.bincount(mapping)+np.array(list(map(len, const)))).max()\n",
    "\n",
    "#     result = () \n",
    "#     for idx in range(len(const)):\n",
    "#         # Getting number embeddings\n",
    "#         nums = num_embed[mapping==idx]\n",
    "\n",
    "#         # Adding constant embeddings\n",
    "#         c = tuple([const_embed[const2id[x]] for x in const[idx]])\n",
    "#         if len(c) > 0:\n",
    "#             c = torch.stack(c)\n",
    "#             nums = torch.cat((nums, c), dim=0)\n",
    "        \n",
    "#           # non masked code\n",
    "# #         if result is None:\n",
    "# #             result = nums\n",
    "# #         else:\n",
    "# #             result = torch.cat((result, nums), dim=0)\n",
    "        \n",
    "#         # Padding and creating mask\n",
    "#         dim1, dim2 = nums.shape\n",
    "#         mask = torch.full((dim1,dim2), True)\n",
    "#         nums = F.pad(nums, (0,0,0,max_nums-dim1), 'constant', 0)\n",
    "#         mask = F.pad(mask, (0,0,0,max_nums-dim1), 'constant', False)\n",
    "        \n",
    "#         # Creating masked tensor object\n",
    "#         mt = torch.masked.masked_tensor(nums, mask)[None,:,:]\n",
    "#         result = result + (mt,)\n",
    "        \n",
    "#     return torch.cat(result, dim=0)\n",
    "# masked_num_embed = {name:create_masked_embeddings(name) for name in SET_NAMES}\n",
    "# masked_num_embed['train'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081437d6",
   "metadata": {},
   "source": [
    "## Constructing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4c533b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerDecoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size, num_tokens, max_layers, K, device):\n",
    "        super(MultiLayerDecoder, self).__init__()\n",
    "        self.device = torch.device(device)\n",
    "        \n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_tokens = num_tokens\n",
    "        self.max_layers = max_layers\n",
    "        self.K = K\n",
    "        self.decoder_layer = MathQADecoder(embedding_size, num_tokens, K, device)\n",
    "    \n",
    "    # Repeatedly get new sets of equations until a maximum depth is reached or there are no more valid equations (all ops are None)\n",
    "    def forward(self, x, embeddings):\n",
    "        \n",
    "        x = x.to(self.device)\n",
    "        nums = embeddings['nums'].to(self.device)\n",
    "        num_idx = embeddings['num_idx'].to(self.device)\n",
    "        ops = embeddings['ops'].to(self.device)\n",
    "        problems = embeddings['problem'].to(self.device)\n",
    "        \n",
    "        # variables to keep track of what equations have been encountered so far\n",
    "        init_dict = lambda x: {i:i for i in range(x)}\n",
    "        eq2id = np.array(list(map(init_dict, num_idx.bincount())))\n",
    "        id2eq = np.array(list(map(init_dict, num_idx.bincount())))\n",
    "\n",
    "        # while less than max layers and the input has more elements\n",
    "        idx = 0\n",
    "        temp = [] # REMOVE THIS\n",
    "        while idx < self.max_layers and x.numel():\n",
    "            batch_size = x.shape[0]\n",
    "            prev_idx = num_idx\n",
    "            prev_nums = nums\n",
    "            \n",
    "            # --------------------------------------------------\n",
    "            # Step 1 - Encoding to embedding size if not already\n",
    "            # --------------------------------------------------\n",
    "            if x.shape[-1] == self.embedding_size*4:\n",
    "                x = self.decoder_layer.exp_encoder(x) #3 [batch_size, K, 3072] -> [batch_size, K, 768]\n",
    "\n",
    "            assert x.shape == torch.Size([batch_size, self.K, self.embedding_size])\n",
    "\n",
    "            # -----------------------\n",
    "            # Step 2 - The main model\n",
    "            # -----------------------\n",
    "            prev_sizes = num_idx.bincount()\n",
    "            x, op, num1, num2, nums, num_idx, problems, eq2id, id2eq = self.decoder_layer(x, nums, num_idx, ops, \n",
    "                                                                                          problems, eq2id, id2eq)\n",
    "            new_sizes = num_idx.bincount()\n",
    "            \n",
    "            # ---------------------------------------------------------------------------------------------------------------------------------\n",
    "            # Step 3 - Removing examples with no valid expressions (If the num nums for a problem is unchanged, it had no valid expressions)\n",
    "            # ---------------------------------------------------------------------------------------------------------------------------------\n",
    "            changed = prev_sizes!=new_sizes # [batch_size] (not_finished True, finished False)\n",
    "            assert len(changed) == batch_size\n",
    "            not_finished = changed.sum()\n",
    "            assert not_finished <= batch_size\n",
    "            nums = nums[changed[num_idx]]  # [num_nums_not_finished, 768]\n",
    "            assert nums.shape[0] <= len(num_idx) and nums.shape[1] == self.embedding_size\n",
    "            prev = num_idx\n",
    "            num_idx = num_idx[changed[num_idx]] # [num_nums_not_finished]\n",
    "            num_idx = torch.unique(num_idx,return_inverse=True)[1]\n",
    "            assert len(num_idx) <= len(prev)\n",
    "            problems = problems[changed] # [not_finished, num_tokens, 768]\n",
    "            assert problems.shape == torch.Size([not_finished, self.num_tokens, self.embedding_size])\n",
    "            eq2id = eq2id[changed] # [not_finished,]\n",
    "            id2eq = id2eq[changed] # [not_finished,]\n",
    "            assert len(eq2id) == not_finished and len(id2eq) == not_finished\n",
    "            x = x[changed] # [not_finished, K, 768]\n",
    "            assert x.shape == torch.Size([not_finished, self.K, self.embedding_size])\n",
    "\n",
    "            idx += 1\n",
    "            temp.append((op,num1,num2,prev_idx,prev_nums,eq2id,id2eq))\n",
    "\n",
    "        return temp\n",
    "\n",
    "        #return op, num1, num2, prev_idx\n",
    "        \n",
    "\n",
    "class MathQADecoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size, num_tokens, K, device): \n",
    "        super(MathQADecoder, self).__init__()\n",
    "        self.device = torch.device(device)\n",
    "        \n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_tokens = num_tokens\n",
    "        self.K = K\n",
    "        \n",
    "        # decreasing dimensionality to match embedding size: <op, num, num, num*num> = 3072 -> 768\n",
    "        self.exp_encoder = torch.nn.Linear(embedding_size*4, embedding_size)\n",
    "        \n",
    "        # converting back into new <op, num, num> for loss calculation\n",
    "        self.exp_decoder = torch.nn.Linear(embedding_size, embedding_size*3)\n",
    "        \n",
    "        # Mixing in expression information to the problem encoding\n",
    "        self.prob_encoder = torch.nn.Linear(num_tokens+K, num_tokens)\n",
    "        \n",
    "        # standard transformer decoder\n",
    "        # we choose K heads for K generated expressions \n",
    "        # (with the hope that each head will get different information for each K expression)\n",
    "        self.transformer_decoder = torch.nn.TransformerDecoderLayer(embedding_size, nhead=K, batch_first=True)\n",
    "        \n",
    "        # softmax for the operations\n",
    "        self.op_softmax = torch.nn.Softmax(dim=2)\n",
    "        \n",
    "        # softmax for the numbers\n",
    "        self.num_softmax = torch.nn.Softmax(dim=0)\n",
    "        \n",
    "    def __apply_to_nums(self, f, nums, num_idx, batch_size):\n",
    "        new_nums = torch.empty(nums.shape)\n",
    "        for x in range(batch_size):\n",
    "            new_nums[num_idx==x] = f(nums[num_idx==x])\n",
    "        return new_nums\n",
    "    \n",
    "    def __update_labels(self, eq2id, id2eq, mask, problem_idx, num1_ids, num2_ids, op_ids, batch_size, num_idx):\n",
    "        num_valid = len(problem_idx)\n",
    "        valid1 = num1_ids[op_ids!=op2id['None']] # [num_valid,]\n",
    "        valid2 = num2_ids[op_ids!=op2id['None']] # [num_valid,]\n",
    "        assert len(valid1) == num_valid and len(valid2) == num_valid\n",
    "        for p in range(batch_size):\n",
    "            print(p)\n",
    "            print(id2eq)\n",
    "            print(id2eq[p])\n",
    "            print(num_idx)\n",
    "            print(max(id2eq[p].keys()))\n",
    "            print((num_idx==p).sum())\n",
    "            assert max(id2eq[p].keys()) == (num_idx==p).sum().item()-1\n",
    "            for idx, e in enumerate(zip(valid1[problem_idx==p], valid2[problem_idx==p])):\n",
    "                try:\n",
    "                    assert e[0].item() in id2eq[p] and e[1].item() in id2eq[p]\n",
    "                except:\n",
    "                    print(num1_ids)\n",
    "                    print(e[0].item())\n",
    "                    print(e[1].item())\n",
    "                    print(id2eq[p])\n",
    "                    print(p)\n",
    "                    print(num_idx)\n",
    "                    print(problem_idx)\n",
    "                    print(batch_size)\n",
    "                    raise\n",
    "                e = (id2eq[p][e[0].item()],id2eq[p][e[1].item()])\n",
    "                    \n",
    "                if e not in eq2id[p]:\n",
    "                    next_idx = len(eq2id[p])\n",
    "                    eq2id[p][e] = next_idx\n",
    "                    id2eq[p][next_idx] = e\n",
    "                else: # duplicate eq\n",
    "                    mask[p,idx] = False\n",
    "        return eq2id, id2eq, mask\n",
    "      \n",
    "    # x: [batch_size, K, 768]\n",
    "    # nums: [num_nums, 768]\n",
    "    # num_idx: [num_nums,]\n",
    "    # ops: [num_ops, 768]\n",
    "    # problems: [batch_size, num_tokens, 768]\n",
    "    def forward(self, x, nums, num_idx, ops, problems, eq2id, id2eq):    \n",
    "        batch_size = x.shape[0]\n",
    "        num_ops = ops.shape[0]\n",
    "        num_nums = nums.shape[0]\n",
    "\n",
    "        # ----------------------------\n",
    "        # Step 1 - transformer decoder\n",
    "        # ----------------------------\n",
    "        assert problems.shape == torch.Size([batch_size, self.num_tokens, self.embedding_size])\n",
    "        x = self.transformer_decoder(x, problems) # [batch_size, K, 768] -> [batch_size, K, 768] (problems is [batch_size, num_tokens, 768])\n",
    "        assert x.shape == torch.Size([batch_size, self.K, self.embedding_size])\n",
    "        \n",
    "        # -------------------------------------------------------------------------------\n",
    "        # Step 2 - decoding the output into three embeddings of size 768 (op, num1, num2)\n",
    "        # -------------------------------------------------------------------------------\n",
    "        x = self.exp_decoder(x) # [batch_size, K, 768] -> [batch_size, K, 2304]\n",
    "        assert x.shape == torch.Size([batch_size, self.K, self.embedding_size*3])\n",
    "        operation, x1, x2 = torch.split(x, self.embedding_size, dim=2) # [batch_size, K, 2304] -> [batch_size, K, 768] for each\n",
    "        assert operation.shape == torch.Size([batch_size, self.K, self.embedding_size])\n",
    "        assert x1.shape == torch.Size([batch_size, self.K, self.embedding_size])\n",
    "        assert x2.shape == torch.Size([batch_size, self.K, self.embedding_size])\n",
    "\n",
    "        # -----------------------------------------------------------------------------------------------\n",
    "        # Step 3 and 4 - Finding the softmax for the similarity between the predicted and true embeddings\n",
    "        # -----------------------------------------------------------------------------------------------\n",
    "        # making sure params have correct dimension\n",
    "        nums_expanded = nums[:,None,:].expand(-1,self.K,-1) # [number_of_nums, 768] -> [number_of_nums, K, 768]\n",
    "        assert nums_expanded.shape == torch.Size([num_nums, self.K, self.embedding_size])\n",
    "        ops = ops[None,None,:,:].repeat(batch_size,self.K,1,1) # [num_ops, 768] -> [batch_size, K, num_ops, 768]\n",
    "        assert ops.shape == torch.Size([batch_size, self.K, num_ops, self.embedding_size])\n",
    "\n",
    "        # dot product - calculating the similarity between each op/num prediction and its true embedding\n",
    "        num1 = (x1[num_idx]*nums_expanded).sum(dim=2) # [number_of_nums, K]\n",
    "        assert num1.shape == torch.Size([num_nums, self.K])\n",
    "        num2 = (x2[num_idx]*nums_expanded).sum(dim=2) # [number_of_nums, K]        \n",
    "        assert num2.shape == torch.Size([num_nums, self.K])\n",
    "        op = operation[:,:,None,:].expand(-1,-1,num_ops,-1) # [batch_size, K, 768] -> # [batch_size, K, num_ops, 768]\n",
    "        assert op.shape == torch.Size([batch_size, self.K, num_ops, self.embedding_size])\n",
    "        op = (op*ops).sum(dim=3) # [batch_size, K, num_ops, 768] -> [batch_size, K, num_ops]\n",
    "        assert op.shape == torch.Size([batch_size, self.K, num_ops])\n",
    "\n",
    "        # softmax\n",
    "        op = self.op_softmax(op) # [batch_size, K, num_ops] (ie op[1,2] would be the operator prediction probabilities for problem2, query3)\n",
    "        assert op.shape == torch.Size([batch_size, self.K, num_ops])\n",
    "        assert op.sum(dim=2).sum()==batch_size*K\n",
    "        \n",
    "        num1 = self.__apply_to_nums(self.num_softmax, num1, num_idx, batch_size) # [num_nums, K]\n",
    "        assert num1.shape == torch.Size([num_nums, self.K])\n",
    "        assert np.isclose(num1[num_idx==0][:,0].sum().item(),1)\n",
    "        \n",
    "        num2 = self.__apply_to_nums(self.num_softmax, num2, num_idx, batch_size) # [num_nums, K]\n",
    "        assert num2.shape == torch.Size([num_nums, self.K])\n",
    "        assert np.isclose(num2[num_idx==0][:,0].sum().item(),1)\n",
    "        # ----------------------------------------------------\n",
    "        # Step 5 - creating embedding for the found expression  \n",
    "        # ----------------------------------------------------\n",
    "        x = self.exp_encoder(torch.cat((operation,x1,x2,x1*x2), dim=2)) # [batch_size, K, 3072] -> [batch_size, K, 768]  \n",
    "        assert x.shape == torch.Size([batch_size, self.K, self.embedding_size])\n",
    "\n",
    "        # -------------------------------------------------------------------------------------------\n",
    "        # Step 6 - finding valid, adding found expression to problem embeddings and number embeddings\n",
    "        # -------------------------------------------------------------------------------------------\n",
    "        # Getting predicted ops/nums and creating a problem index for what problem they refer to\n",
    "        op_ids = torch.argmax(op, dim=2) # [batch_size, K]\n",
    "        assert op_ids.shape == torch.Size([batch_size, self.K])\n",
    "        assert op_ids.max() < num_ops and op_ids.min() >= 0\n",
    "        mask = op_ids!=op2id['None'] # [batch_size, K]\n",
    "        assert mask.shape == torch.Size([batch_size, self.K])\n",
    "        num1_ids = torch.stack(tuple([num1[num_idx==x].argmax(0) for x in range(batch_size)])) # [batch_size, K]\n",
    "        assert num1_ids.shape == torch.Size([batch_size, self.K])\n",
    "        assert num1_ids.max() < num_idx[num_idx==num1_ids.argmax()//self.K].shape[0] and num1_ids.min() >= 0\n",
    "        num2_ids = torch.stack(tuple([num2[num_idx==x].argmax(0) for x in range(batch_size)])) # [batch_size, K]\n",
    "        assert num2_ids.shape == torch.Size([batch_size, self.K])\n",
    "        assert num2_ids.max() < num_idx[num_idx==num2_ids.argmax()//self.K].shape[0] and num2_ids.min() >= 0\n",
    "        problem_idx = torch.arange(mask.shape[0]).to(self.device).repeat_interleave(K)[mask.flatten()] # [num_valid,]\n",
    "        num_valid = mask.sum()\n",
    "        assert len(problem_idx) == num_valid\n",
    "        \n",
    "        # Figuring out and keeping track of what equations each label corresponds to (to avoid duplicates/for loss calculation)\n",
    "        eq2id, id2eq, mask = self.__update_labels(eq2id, id2eq, mask, problem_idx, num1_ids, num2_ids, op_ids, batch_size, num_idx)\n",
    "        assert len(eq2id) == batch_size and len(id2eq) == batch_size\n",
    "\n",
    "        # Getting valid embeddings along with an updated problem index\n",
    "        num_valid = mask.sum()\n",
    "        valid = x[mask] # [num_valid, 768]\n",
    "        assert valid.shape == torch.Size([num_valid, 768])\n",
    "        problem_idx = torch.arange(mask.shape[0]).to(self.device).repeat_interleave(K)[mask.flatten()] # [num_valid,]\n",
    "        assert len(problem_idx) == num_valid\n",
    "\n",
    "        # Appending to num_embeddings\n",
    "        nums = torch.cat((nums, valid), dim=0) # [num_nums+num_valid, 768]\n",
    "        assert nums.shape == torch.Size([num_valid+num_nums, self.embedding_size])\n",
    "        num_idx = torch.cat((num_idx, problem_idx), dim=0) # [num_nums+num_valid,]\n",
    "        assert len(num_idx) == num_valid+num_nums\n",
    "\n",
    "        # Updating problem embeddings\n",
    "        temp = torch.clone(x)\n",
    "        temp[~mask] = 0 # [batch_size, K, 768] # CONSIDER CHANGING THIS (rn just setting invalid to zero)\n",
    "        assert temp.shape == torch.Size([batch_size, self.K, 768])\n",
    "        problems = torch.cat((problems,temp),dim=1) # [batch_size, num_tokens+K, 768]\n",
    "        assert problems.shape == torch.Size([batch_size, self.num_tokens+self.K, self.embedding_size])\n",
    "        problems = self.prob_encoder(problems.permute(0,2,1)) # [batch_size, 768, num_tokens]\n",
    "        assert problems.shape == torch.Size([batch_size, self.embedding_size, self.num_tokens])\n",
    "        problems = problems.permute(0,2,1) # [batch_size, num_tokens, 768]\n",
    "        assert problems.shape == torch.Size([batch_size, self.num_tokens, self.embedding_size])\n",
    "        \n",
    "        # -----------------------\n",
    "        # Returning final results\n",
    "        # -----------------------\n",
    "        return x, op, num1, num2, nums, num_idx, problems, eq2id, id2eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ea8221de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5} {0: 0, 1: 1, 2: 2, 3: 3, 4: 4}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4} {0: 0, 1: 1, 2: 2, 3: 3, 4: 4}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10}]\n",
      "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}\n",
      "tensor([0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 7, 7, 7, 7,\n",
      "        7, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 6,\n",
      "        6, 6, 7, 7, 7, 7, 7, 7])\n",
      "5\n",
      "tensor(6)\n",
      "1\n",
      "[{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: (1, 0)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5} {0: 0, 1: 1, 2: 2, 3: 3, 4: 4}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4} {0: 0, 1: 1, 2: 2, 3: 3, 4: 4}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10}]\n",
      "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}\n",
      "tensor([0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 7, 7, 7, 7,\n",
      "        7, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 6,\n",
      "        6, 6, 7, 7, 7, 7, 7, 7])\n",
      "9\n",
      "tensor(10)\n",
      "2\n",
      "[{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: (1, 0)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: (1, 2), 11: (8, 2)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5} {0: 0, 1: 1, 2: 2, 3: 3, 4: 4}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4} {0: 0, 1: 1, 2: 2, 3: 3, 4: 4}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10}]\n",
      "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}\n",
      "tensor([0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 7, 7, 7, 7,\n",
      "        7, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 6,\n",
      "        6, 6, 7, 7, 7, 7, 7, 7])\n",
      "5\n",
      "tensor(6)\n",
      "3\n",
      "[{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: (1, 0)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: (1, 2), 11: (8, 2)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: (0, 0), 7: (0, 3)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4} {0: 0, 1: 1, 2: 2, 3: 3, 4: 4}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10}]\n",
      "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4}\n",
      "tensor([0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 7, 7, 7, 7,\n",
      "        7, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 6,\n",
      "        6, 6, 7, 7, 7, 7, 7, 7])\n",
      "4\n",
      "tensor(5)\n",
      "4\n",
      "[{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: (1, 0)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: (1, 2), 11: (8, 2)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: (0, 0), 7: (0, 3)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: (2, 0), 6: (3, 0)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4} {0: 0, 1: 1, 2: 2, 3: 3, 4: 4}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10}]\n",
      "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}\n",
      "tensor([0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 7, 7, 7, 7,\n",
      "        7, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 6,\n",
      "        6, 6, 7, 7, 7, 7, 7, 7])\n",
      "7\n",
      "tensor(8)\n",
      "5\n",
      "[{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: (1, 0)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: (1, 2), 11: (8, 2)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: (0, 0), 7: (0, 3)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: (2, 0), 6: (3, 0)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: (2, 3), 9: (1, 3), 10: (5, 3)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4} {0: 0, 1: 1, 2: 2, 3: 3, 4: 4}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10}]\n",
      "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4}\n",
      "tensor([0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 7, 7, 7, 7,\n",
      "        7, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 6,\n",
      "        6, 6, 7, 7, 7, 7, 7, 7])\n",
      "4\n",
      "tensor(5)\n",
      "6\n",
      "[{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: (1, 0)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: (1, 2), 11: (8, 2)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: (0, 0), 7: (0, 3)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: (2, 0), 6: (3, 0)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: (2, 3), 9: (1, 3), 10: (5, 3)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: (0, 2)} {0: 0, 1: 1, 2: 2, 3: 3, 4: 4}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10}]\n",
      "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4}\n",
      "tensor([0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 7, 7, 7, 7,\n",
      "        7, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 6,\n",
      "        6, 6, 7, 7, 7, 7, 7, 7])\n",
      "4\n",
      "tensor(5)\n",
      "7\n",
      "[{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: (1, 0)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: (1, 2), 11: (8, 2)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: (0, 0), 7: (0, 3)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: (2, 0), 6: (3, 0)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: (2, 3), 9: (1, 3), 10: (5, 3)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: (0, 2)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: (1, 0)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10}]\n",
      "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10}\n",
      "tensor([0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 7, 7, 7, 7,\n",
      "        7, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 6,\n",
      "        6, 6, 7, 7, 7, 7, 7, 7])\n",
      "10\n",
      "tensor(11)\n",
      "0\n",
      "[{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: (1, 0)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: (1, 2), 11: (8, 2)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: (0, 0), 7: (0, 3)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: (2, 0), 6: (3, 0)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: (2, 3), 9: (1, 3), 10: (5, 3)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: (0, 2)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: (1, 0)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: (3, 4), 12: (2, 4)}]\n",
      "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: (1, 0)}\n",
      "tensor([0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 7, 7, 7, 7,\n",
      "        7, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 6,\n",
      "        6, 6, 7, 7, 7, 7, 7, 7, 0, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 4, 5, 6, 7, 7,\n",
      "        7])\n",
      "6\n",
      "tensor(7)\n",
      "1\n",
      "[{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: (1, 0), 7: ((1, 0), 1), 8: ((1, 0), (1, 0)), 9: (1, (1, 0))}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: (1, 2), 11: (8, 2)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: (0, 0), 7: (0, 3)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: (2, 0), 6: (3, 0)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: (2, 3), 9: (1, 3), 10: (5, 3)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: (0, 2)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: (1, 0)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: (3, 4), 12: (2, 4)}]\n",
      "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: (1, 2), 11: (8, 2)}\n",
      "tensor([0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 7, 7, 7, 7,\n",
      "        7, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 6,\n",
      "        6, 6, 7, 7, 7, 7, 7, 7, 0, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 4, 5, 6, 7, 7,\n",
      "        7])\n",
      "11\n",
      "tensor(12)\n",
      "2\n",
      "[{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: (1, 0), 7: ((1, 0), 1), 8: ((1, 0), (1, 0)), 9: (1, (1, 0))}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: (1, 2), 11: (8, 2), 12: (0, (1, 2)), 13: ((8, 2), 2), 14: ((8, 2), 0), 15: (0, 0), 16: ((1, 2), (1, 2)), 17: (0, (8, 2))}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: (0, 0), 7: (0, 3)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: (2, 0), 6: (3, 0)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: (2, 3), 9: (1, 3), 10: (5, 3)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: (0, 2)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: (1, 0)}\n",
      " {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: (3, 4), 12: (2, 4)}]\n",
      "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: (0, 0), 7: (0, 3)}\n",
      "tensor([0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 7, 7, 7, 7,\n",
      "        7, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 6,\n",
      "        6, 6, 7, 7, 7, 7, 7, 7, 0, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 4, 5, 6, 7, 7,\n",
      "        7])\n",
      "7\n",
      "tensor(9)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m     model \u001b[38;5;241m=\u001b[39m MultiLayerDecoder(\u001b[38;5;241m768\u001b[39m, \u001b[38;5;241m392\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m#model.to('cuda:0')\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m#del embeddings\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m model\n",
      "File \u001b[0;32m~/nlp/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nlp/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[58], line 47\u001b[0m, in \u001b[0;36mMultiLayerDecoder.forward\u001b[0;34m(self, x, embeddings)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# -----------------------\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Step 2 - The main model\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# -----------------------\u001b[39;00m\n\u001b[1;32m     46\u001b[0m prev_sizes \u001b[38;5;241m=\u001b[39m num_idx\u001b[38;5;241m.\u001b[39mbincount()\n\u001b[0;32m---> 47\u001b[0m x, op, num1, num2, nums, num_idx, problems, eq2id, id2eq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                                                                              \u001b[49m\u001b[43mproblems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meq2id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid2eq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m new_sizes \u001b[38;5;241m=\u001b[39m num_idx\u001b[38;5;241m.\u001b[39mbincount()\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Step 3 - Removing examples with no valid expressions (If the num nums for a problem is unchanged, it had no valid expressions)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------------------------------------------------------------------------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/nlp/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nlp/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[58], line 236\u001b[0m, in \u001b[0;36mMathQADecoder.forward\u001b[0;34m(self, x, nums, num_idx, ops, problems, eq2id, id2eq)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(problem_idx) \u001b[38;5;241m==\u001b[39m num_valid\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Figuring out and keeping track of what equations each label corresponds to (to avoid duplicates/for loss calculation)\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m eq2id, id2eq, mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__update_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43meq2id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid2eq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproblem_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum1_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum2_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(eq2id) \u001b[38;5;241m==\u001b[39m batch_size \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(id2eq) \u001b[38;5;241m==\u001b[39m batch_size\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# Getting valid embeddings along with an updated problem index\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[58], line 128\u001b[0m, in \u001b[0;36mMathQADecoder.__update_labels\u001b[0;34m(self, eq2id, id2eq, mask, problem_idx, num1_ids, num2_ids, op_ids, batch_size, num_idx)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mmax\u001b[39m(id2eq[p]\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mprint\u001b[39m((num_idx\u001b[38;5;241m==\u001b[39mp)\u001b[38;5;241m.\u001b[39msum())\n\u001b[0;32m--> 128\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(id2eq[p]\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m==\u001b[39m (num_idx\u001b[38;5;241m==\u001b[39mp)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(valid1[problem_idx\u001b[38;5;241m==\u001b[39mp], valid2[problem_idx\u001b[38;5;241m==\u001b[39mp])):\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# x: [batch_size, K, 768]\n",
    "# nums: [num_nums, 768]\n",
    "# num_idx: [num_nums,]\n",
    "# ops: [num_ops, 768]\n",
    "# problems: [batch_size, num_tokens, 768]\n",
    "try:\n",
    "    seed = 3\n",
    "    with open(f'{OBJ_DIR}embeddings/train/batch0.pickle', 'rb') as f:\n",
    "        embeddings = pickle.load(f)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    x = torch.rand(8,6,768)\n",
    "    model = MultiLayerDecoder(768, 392, 8, 6, 'cpu')\n",
    "    #model.to('cuda:0')\n",
    "    result = model(x, embeddings)\n",
    "finally:\n",
    "    #del embeddings\n",
    "    del model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c871cc-c818-4bf8-a829-73a2b5b4675f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ad9d1a1-5ef6-4ba4-83e2-60313619ccad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 0, 7, 9, 8, 8])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_idx=embeddings['num_idx']\n",
    "def apply_to_nums(f, nums, num_idx, batch_size):\n",
    "    new_nums = torch.empty(nums.shape)\n",
    "    for x in range(batch_size):\n",
    "        new_nums[num_idx==x] = f(nums[num_idx==x])\n",
    "    return new_nums\n",
    "num1 = torch.rand(len(num_idx),6)\n",
    "num1 = apply_to_nums(torch.nn.Softmax(dim=0), num1, num_idx, batch_size=8)\n",
    "num1[num_idx==1].argmax(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a4db002-d7a8-4fe8-a3cb-9dc365a87d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0826, 0.1288, 0.0583, 0.0908, 0.0855, 0.1103],\n",
       "        [0.0683, 0.0760, 0.0773, 0.1003, 0.0716, 0.1268],\n",
       "        [0.0954, 0.1141, 0.1463, 0.0775, 0.1088, 0.0987],\n",
       "        [0.0819, 0.0779, 0.0932, 0.0762, 0.1173, 0.0623],\n",
       "        [0.0948, 0.0769, 0.1065, 0.1336, 0.0795, 0.1330],\n",
       "        [0.1063, 0.1169, 0.1003, 0.0936, 0.1223, 0.0759],\n",
       "        [0.0920, 0.0962, 0.0746, 0.0720, 0.1202, 0.0974],\n",
       "        [0.1174, 0.1013, 0.1522, 0.0684, 0.1030, 0.0841],\n",
       "        [0.1000, 0.0834, 0.1313, 0.1174, 0.1256, 0.1383],\n",
       "        [0.1612, 0.1286, 0.0600, 0.1702, 0.0662, 0.0732]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num1[num_idx==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3e677eb-c0fc-4b74-b68a-ca1d847a2bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num1[num_idx==0][:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5490379-a2eb-4310-b471-84044a28e19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Softmax(\n",
       "   dim=tensor([[0.2152, 0.1450, 0.2075, 0.1642, 0.1115, 0.0954],\n",
       "           [0.1592, 0.0925, 0.1989, 0.2157, 0.2351, 0.1178],\n",
       "           [0.1309, 0.2244, 0.1301, 0.1772, 0.2098, 0.2380],\n",
       "           [0.1892, 0.2341, 0.1398, 0.1213, 0.0969, 0.2087],\n",
       "           [0.1504, 0.1099, 0.1919, 0.1281, 0.1389, 0.1572],\n",
       "           [0.1551, 0.1941, 0.1319, 0.1935, 0.2079, 0.1830]])\n",
       " ),\n",
       " Softmax(\n",
       "   dim=tensor([[0.0928, 0.1316, 0.0606, 0.1125, 0.0741, 0.0881],\n",
       "           [0.1111, 0.1019, 0.1567, 0.0923, 0.1400, 0.0810],\n",
       "           [0.0793, 0.0734, 0.1168, 0.1036, 0.1100, 0.0896],\n",
       "           [0.0657, 0.0940, 0.0842, 0.1676, 0.1042, 0.1546],\n",
       "           [0.0717, 0.0697, 0.0839, 0.0815, 0.0975, 0.1017],\n",
       "           [0.1347, 0.0870, 0.0597, 0.0742, 0.0590, 0.1273],\n",
       "           [0.1259, 0.1278, 0.1229, 0.0813, 0.0683, 0.0802],\n",
       "           [0.0837, 0.1133, 0.0703, 0.1134, 0.1209, 0.0677],\n",
       "           [0.1065, 0.0737, 0.1176, 0.0930, 0.0746, 0.1020],\n",
       "           [0.1287, 0.1278, 0.1273, 0.0806, 0.1514, 0.1077]])\n",
       " ),\n",
       " Softmax(\n",
       "   dim=tensor([[0.1641, 0.1649, 0.2071, 0.2234, 0.1599, 0.1782],\n",
       "           [0.1072, 0.1879, 0.1709, 0.1566, 0.2738, 0.1736],\n",
       "           [0.1578, 0.1820, 0.2246, 0.1633, 0.1761, 0.1450],\n",
       "           [0.2537, 0.0966, 0.1447, 0.1085, 0.1070, 0.1218],\n",
       "           [0.1471, 0.1543, 0.1568, 0.2340, 0.1691, 0.2544],\n",
       "           [0.1701, 0.2143, 0.0959, 0.1142, 0.1141, 0.1270]])\n",
       " ),\n",
       " Softmax(\n",
       "   dim=tensor([[0.2316, 0.1896, 0.1888, 0.1325, 0.2194, 0.1925],\n",
       "           [0.2564, 0.1110, 0.1328, 0.2387, 0.1860, 0.2168],\n",
       "           [0.1313, 0.2733, 0.2278, 0.1974, 0.1599, 0.1939],\n",
       "           [0.1181, 0.1489, 0.2342, 0.2531, 0.1760, 0.1796],\n",
       "           [0.2627, 0.2773, 0.2165, 0.1784, 0.2587, 0.2173]])\n",
       " ),\n",
       " Softmax(\n",
       "   dim=tensor([[0.0913, 0.1349, 0.1067, 0.0858, 0.0827, 0.1398],\n",
       "           [0.1049, 0.1567, 0.1717, 0.1091, 0.1279, 0.1691],\n",
       "           [0.1043, 0.0644, 0.1264, 0.1010, 0.1349, 0.1211],\n",
       "           [0.1317, 0.1324, 0.1086, 0.0890, 0.2047, 0.1220],\n",
       "           [0.1310, 0.1567, 0.1328, 0.1654, 0.1100, 0.0922],\n",
       "           [0.1227, 0.1361, 0.1109, 0.1837, 0.1551, 0.1111],\n",
       "           [0.1025, 0.0628, 0.1281, 0.1719, 0.0843, 0.1524],\n",
       "           [0.2116, 0.1560, 0.1148, 0.0941, 0.1005, 0.0923]])\n",
       " ),\n",
       " Softmax(\n",
       "   dim=tensor([[0.1747, 0.2319, 0.2166, 0.2944, 0.1553, 0.2804],\n",
       "           [0.1607, 0.2350, 0.2181, 0.1280, 0.1542, 0.1137],\n",
       "           [0.2131, 0.1601, 0.1989, 0.2852, 0.1524, 0.1230],\n",
       "           [0.2506, 0.1611, 0.2069, 0.1535, 0.2236, 0.2323],\n",
       "           [0.2009, 0.2119, 0.1595, 0.1389, 0.3145, 0.2507]])\n",
       " ),\n",
       " Softmax(\n",
       "   dim=tensor([[0.1258, 0.2810, 0.1921, 0.1761, 0.1616, 0.2165],\n",
       "           [0.3200, 0.2695, 0.1633, 0.1134, 0.2192, 0.1923],\n",
       "           [0.2366, 0.1212, 0.1808, 0.2494, 0.2838, 0.2437],\n",
       "           [0.1755, 0.1198, 0.1856, 0.2090, 0.1408, 0.2338],\n",
       "           [0.1422, 0.2085, 0.2783, 0.2520, 0.1946, 0.1137]])\n",
       " ),\n",
       " Softmax(\n",
       "   dim=tensor([[0.0563, 0.0989, 0.0631, 0.0819, 0.0947, 0.0669],\n",
       "           [0.0652, 0.0700, 0.1164, 0.0705, 0.1088, 0.0647],\n",
       "           [0.1022, 0.0569, 0.0931, 0.0677, 0.0796, 0.0619],\n",
       "           [0.0990, 0.0899, 0.1165, 0.0982, 0.0767, 0.1060],\n",
       "           [0.1007, 0.0505, 0.1395, 0.0755, 0.1117, 0.1318],\n",
       "           [0.0873, 0.1053, 0.0727, 0.1116, 0.0844, 0.1107],\n",
       "           [0.0900, 0.0962, 0.0925, 0.0706, 0.0683, 0.1193],\n",
       "           [0.1007, 0.1068, 0.1189, 0.0655, 0.0900, 0.0928],\n",
       "           [0.0978, 0.1121, 0.0557, 0.1139, 0.0855, 0.0805],\n",
       "           [0.0848, 0.1043, 0.0689, 0.1105, 0.1448, 0.0662],\n",
       "           [0.1161, 0.1091, 0.0627, 0.1340, 0.0558, 0.0994]])\n",
       " )]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[torch.nn.Softmax(num1[num_idx==x]) for x in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a82907-f781-42f5-9116-b63f2a4a96fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119fa863-d541-4152-b0f6-95ad9ebf9321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
