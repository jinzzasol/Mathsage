{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b949f5ef",
   "metadata": {},
   "source": [
    "# MathQA Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8417205d",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e92b04d3-cd66-4237-b824-ac18a7debedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import os\n",
    "import anytree\n",
    "import pandas as pd\n",
    "from itertools import permutations\n",
    "import seaborn as sns\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer, AutoModel, TrainingArguments, Trainer, AutoModelForMaskedLM, DataCollatorForLanguageModeling\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftModel\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0d48fc",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f00c0896",
   "metadata": {},
   "outputs": [],
   "source": [
    "K=6\n",
    "DATA_PATH = './dataset/'\n",
    "SET_NAMES = ['train', 'validation', 'test']\n",
    "ENCODER_MODEL = 'distilroberta-base' # A more optimized version of roberta obtaining 95% of its performance\n",
    "MAX_TOKENS = 392\n",
    "DEVICE = 'cuda:0'\n",
    "NUM_MASK = '<num>'\n",
    "WORKING_DIR = 'TEMP/'\n",
    "FINAL_DIR = 'pickle/'\n",
    "MODEL_DIR = 'models/'\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "class Op(Enum):\n",
    "    ADD = '+'\n",
    "    SUB = '-'\n",
    "    MULT = '*'\n",
    "    DIV = '/'\n",
    "    POW = '^'\n",
    "    \n",
    "class Const(Enum):\n",
    "    CONST_NEG_1 = 'const_neg_1' # I added this\n",
    "    CONST_0_25 = 'const_0_25'\n",
    "    CONST_0_2778 = 'const_0_2778'\n",
    "    CONST_0_33 = 'const_0_33'\n",
    "    CONST_0_3937 = 'const_0_3937'\n",
    "    CONST_1 = 'const_1'\n",
    "    CONST_1_6 = 'const_1_6'\n",
    "    CONST_2 = 'const_2'\n",
    "    CONST_3 = 'const_3'\n",
    "    CONST_PI = 'const_pi'\n",
    "    CONST_3_6 = 'const_3_6'\n",
    "    CONST_4 = 'const_4'\n",
    "    CONST_5 = 'const_5'\n",
    "    CONST_6 = 'const_6'\n",
    "    CONST_10 = 'const_10'\n",
    "    CONST_12 = 'const_12'\n",
    "    CONST_26 = 'const_26'\n",
    "    CONST_52 = 'const_52'\n",
    "    CONST_60 = 'const_60'\n",
    "    CONST_100 = 'const_100'\n",
    "    CONST_180 = 'const_180'\n",
    "    CONST_360 = 'const_360'\n",
    "    CONST_1000 = 'const_1000'\n",
    "    CONST_3600 = 'const_3600'\n",
    "\n",
    "values = [-1, 0.25, 0.2778, 0.33, 0.3937, 1, 1.6, 2, 3, math.pi, 3.6, 4, 5, 6, 10, 12, 26, 52, 60, 100, 180, 360, 1000, 3600]\n",
    "const2val = {k:v for k,v in zip(Const._value2member_map_.keys(), values)}    \n",
    "\n",
    "op2id = {k:v for k,v in zip(Op._value2member_map_.keys(), range(len(Op._value2member_map_)))}\n",
    "const2id = {k:v for k,v in zip(Const._value2member_map_.keys(), range(len(Const._value2member_map_)))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5120984",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4528e98f",
   "metadata": {},
   "source": [
    "Reading csv into a dictionary of dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a1239b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {name:pd.read_csv(f'{DATA_PATH}{name}.csv') for name in SET_NAMES}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61cfd60",
   "metadata": {},
   "source": [
    "Converts operations for each problem into a multi label onehot encoded setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe3a40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_ops(data):\n",
    "    labels = []\n",
    "    for op_set in data.ops:\n",
    "        op_set = eval(op_set)\n",
    "        idx = [op2id[op] for op in op_set]\n",
    "        onehot = np.zeros(len(op2id))\n",
    "        onehot[idx] = 1\n",
    "        labels.append(onehot)\n",
    "    return np.array(labels)\n",
    "        \n",
    "#onehot_ops(data['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93df24d",
   "metadata": {},
   "source": [
    "Sort nums for each each problem in increasing order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e7d18ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_num(nums):\n",
    "    get_float = lambda x: float(const2val[x]) if x in const2val else float(x)\n",
    "    return max(map(get_float, nums))\n",
    "\n",
    "def remove_const(data):\n",
    "    nums = []\n",
    "    for num_list in data.nums:\n",
    "        nums.append(set([float(x) for x in eval(num_list) if x not in const2val]))\n",
    "    return nums\n",
    "\n",
    "# Gets the numbers listed in a problem\n",
    "# Once found, numbers are masked using a number mask\n",
    "def get_nums_from_problem(data, convert_to_float=False):\n",
    "    nums = []\n",
    "    problems = []\n",
    "    for problem in data.problem:\n",
    "        num = re.compile('([+-]?((\\d+(\\.\\d*)?)|(\\.\\d+)))')\n",
    "        big = re.compile(r'(-?\\d{1,3}(,\\d{3})+(\\.\\d*)?)')\n",
    "        \n",
    "        big_results = re.finditer(big, problem)\n",
    "        problem = re.sub(big, NUM_MASK, problem)        \n",
    "        num_results = re.finditer(num, problem)\n",
    "        problem = re.sub(num, NUM_MASK, problem)\n",
    "        \n",
    "        # Getting the combined numbers in order of occurence\n",
    "        combined = [x for x in num_results]\n",
    "        combined.extend([x for x in big_results])\n",
    "        combined = sorted(combined, key=lambda x: x.start(0))\n",
    "        \n",
    "        if convert_to_float:\n",
    "            combined = [float(x.group(0).replace(',','')) for x in combined]\n",
    "        else:\n",
    "            combined = [x.group(0) for x in combined]\n",
    "        \n",
    "        nums.append(combined)\n",
    "        problems.append(problem)\n",
    "    return nums, problems\n",
    "\n",
    "def sort_nums(data):\n",
    "    nums_sorted = []\n",
    "    nums_no_const_sorted = []\n",
    "    for nums in data.nums_no_const:\n",
    "        nums_no_const_sorted.append(sorted(list(eval(nums)), key=lambda x: float(x)))\n",
    "    for nums in data.nums:\n",
    "        num_list = list(eval(nums))\n",
    "        maximum = max_num(num_list)\n",
    "        get_float = lambda x: float(const2val[x])+maximum if x in const2val else float(x)\n",
    "        nums_sorted.append(sorted(num_list, key=get_float))\n",
    "    return nums_sorted, nums_no_const_sorted\n",
    "\n",
    "#sort_nums(data['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7260430",
   "metadata": {},
   "source": [
    "Here I do some testing to see if the numbers from the equation can be found in the problem description using simple regexes. This actually works extremely well, having no examples where the expected numbers is not a subset of the obtained numbers. This does not include constants. Constants are values which should not occur in the problem description (like pi or the 2 in r^2 for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43603d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = remove_const(data['train'])\n",
    "obtained,_ = get_nums_from_problem(data['train'], convert_to_float=True)\n",
    "obtained = [set(x) for x in obtained]\n",
    "\n",
    "idx = 0\n",
    "for x, y in zip(expected, obtained):\n",
    "    if not (x <= y):\n",
    "        print('------------------')\n",
    "        print(data['train']['problem'][idx])\n",
    "        print(f'Expected: {x}')\n",
    "        print(f'Obtained: {y}')\n",
    "        print('------------------')\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fe01d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "general        7187\n",
       "physics        4885\n",
       "gain           3520\n",
       "geometry       1410\n",
       "other          1069\n",
       "probability     144\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879bc1ac-89a5-4e66-a781-4595950ab9f4",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dfc7b7-7194-4dcd-8423-99080999cd25",
   "metadata": {},
   "source": [
    "In this step, we use Roberta to get contextualized embeddings for each math problem\n",
    "\n",
    "First, the problem texts must be tokenized into input ids. A number mask token is used for each number in the problem, as they should not affect the problem itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61dd08b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at models/distilroberta-base-encoder-mathqa and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_path = f'{MODEL_DIR}{ENCODER_MODEL}-encoder-mathqa'\n",
    "#model = AutoModelForMaskedLM.from_pretrained(ENCODER_MODEL) # Used for fine tuning only\n",
    "model = AutoModel.from_pretrained(model_path, output_hidden_states=True) # Fine tuned model used for getting the contextualized embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dd053ea-161e-44a7-bb13-74e4ca6a0c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 50266. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(ENCODER_MODEL)\n",
    "\n",
    "# Adding a new token to the model, for masking out numbers.\n",
    "tokenizer.add_special_tokens({'additional_special_tokens':[NUM_MASK]})\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "def tokenize_data(data):\n",
    "    tokenization = lambda x: tokenizer(x, padding='max_length', max_length=MAX_TOKENS, truncation=True)\n",
    "    _,problem = get_nums_from_problem(data)\n",
    "    \n",
    "    tokenized = list(map(tokenization, problem))\n",
    "    input_ids = torch.stack([torch.tensor(x['input_ids']) for x in tokenized])\n",
    "    attention_mask = torch.stack([torch.tensor(x['attention_mask']) for x in tokenized])\n",
    "    \n",
    "    return {'input_ids':input_ids.long(), 'attention_mask':attention_mask.int()}\n",
    "\n",
    "tokenized = {name:tokenize_data(data[name]) for name in SET_NAMES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fabc7e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of problems that exceed 392 tokens: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of problems that exceed {MAX_TOKENS} tokens: {np.sum(np.array((tokenized['train']['input_ids'][:,-1]!=1)))}\") # 1 is the padding token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b9a3ee",
   "metadata": {},
   "source": [
    "Next, the encoder model is finetuned on MathQA, using masked language modeling, similar to how bert does its trainined. This allows the model to create better contextualized representations for each math problem. Hyperparameters courtesy of https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/language_modeling.ipynb#scrollTo=QRTpmyCc3l_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b105b7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = TrainingArguments(\n",
    "#     f'{WORKING_DIR}{model_path}',\n",
    "#     evaluation_strategy='epoch',\n",
    "#     learning_rate=2e-5,\n",
    "#     weight_decay=0.01,\n",
    "#     per_device_train_batch_size = 8,\n",
    "#     per_device_eval_batch_size = 8,\n",
    "# )\n",
    "\n",
    "# train = Dataset.from_dict(tokenized['train'])\n",
    "# val = Dataset.from_dict(tokenized['validation'])\n",
    "# train.set_format('torch')\n",
    "# val.set_format('torch')\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=args,\n",
    "#     train_dataset=train,\n",
    "#     eval_dataset=val,\n",
    "#     data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15) # using the masked probability from BERT\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3c8ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2c0a558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.save_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f960b6cd",
   "metadata": {},
   "source": [
    "This function gets the number index for each masked number token in the tokenized problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf5610d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masked_idx(tokenized):\n",
    "    mask_id = tokenizer.encode(NUM_MASK, add_special_tokens=False)[0]\n",
    "    ids = tokenized['input_ids']\n",
    "    \n",
    "    return [np.where(id==mask_id)[0] for id in ids]\n",
    "\n",
    "masked_idx = {name:get_masked_idx(tokenized[name]) for name in data.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f0cbac",
   "metadata": {},
   "source": [
    "This function gets the problem indices that each constant is used in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6a72e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_const_problems(data):\n",
    "    const2idx = {const:[] for const in Const._value2member_map_.keys()}\n",
    "    for idx, num_list in enumerate(data.nums):\n",
    "        for x in eval(num_list):\n",
    "            if x in const2val:\n",
    "                const2idx[x].append(idx)\n",
    "    return {k:np.array(v) for k,v in const2idx.items()}\n",
    "\n",
    "const2idx = {name:get_const_problems(data[name]) for name in SET_NAMES}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ee681b",
   "metadata": {},
   "source": [
    "Here the contextualized embeddings are obtained using the fientuned roberta model for the problem, problem numbers, and constants. The contextualized embeddings are just the sum of the last four hidden layers outputted from bert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9b126ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batches a non homogeneous array given a number of splits\n",
    "def non_homogeneous_split(arr, num_per_batch):\n",
    "    return [arr[idx:idx+num_per_batch] for idx in range(0,len(arr),num_per_batch)]\n",
    "\n",
    "# Batches the const2idx dictionary\n",
    "def batch_const2idx(const2idx, name):\n",
    "    batched_const2idx = [{const:[] for const in Const._value2member_map_.keys()} for x in range(num_splits)]\n",
    "    split_size = math.ceil(len(data[name])/num_splits)\n",
    "    for k,v in const2idx[name].items():\n",
    "        for batch_num, batch_idx in zip(v//96, v%96):\n",
    "            batched_const2idx[batch_num][k].append(batch_idx)\n",
    "    return [{k:np.array(v) for k,v in x.items()} for x in batched_const2idx]\n",
    "\n",
    "# Putting model on gpu\n",
    "model.to(DEVICE)\n",
    "\n",
    "def get_embeddings(name): \n",
    "    # batching ids and masks\n",
    "    num_per_batch = BATCH_SIZE\n",
    "    num_splits = math.ceil(len(tokenized[name]['input_ids'])/num_per_batch)\n",
    "    batched_ids = torch.split(tokenized[name]['input_ids'], num_per_batch)\n",
    "    batched_masks = torch.split(tokenized[name]['attention_mask'], num_per_batch)\n",
    "    batched_idx = non_homogeneous_split(masked_idx[name], num_per_batch)\n",
    "    batched_literals = non_homogeneous_split(get_nums_from_problem(data[name], convert_to_float=True)[0], num_per_batch)\n",
    "    \n",
    "    all_cls = None\n",
    "\n",
    "    for batch_num in range(num_splits):   \n",
    "        embeddings = {}\n",
    "        \n",
    "        # Getting first batch and putting on gpu\n",
    "        ids = batched_ids[batch_num].to(DEVICE)\n",
    "        mask = batched_masks[batch_num].to(DEVICE)\n",
    "        idx = batched_idx[batch_num]\n",
    "        literals = torch.tensor(np.concatenate(batched_literals[batch_num])).to(DEVICE)\n",
    "\n",
    "        # Getting the raw hidden layer output\n",
    "        with torch.no_grad():\n",
    "            output = model(ids, mask)\n",
    "\n",
    "        # [batch_size * tokens * 13 * 768]\n",
    "        output = torch.stack(output[2], dim=0).permute(1,2,0,3)\n",
    "\n",
    "        # Summing the last 4 hidden layers from roberta to be used as the contextualized embeddings\n",
    "        #output = torch.sum(output[:,:,-4:,:], dim=2)\n",
    "        output = output[:,:,-1,:]\n",
    "        \n",
    "        # Getting the num embeddings at the index of each masked number\n",
    "        num_embeddings = ()\n",
    "        num_idx = []\n",
    "        for x in range(len(idx)):\n",
    "            embed = output[x,idx[x]].to('cpu')\n",
    "            num_embeddings += (embed,)\n",
    "            num_idx.extend([x]*embed.shape[0])\n",
    "        num_embeddings = torch.cat(num_embeddings, dim = 0)\n",
    "        \n",
    "        # Adding to dictionary\n",
    "        embeddings['problem'] = output\n",
    "        embeddings['mask'] = mask\n",
    "        embeddings['nums'] = num_embeddings\n",
    "        embeddings['num_idx'] = torch.tensor(num_idx)\n",
    "        embeddings['num_literals'] = literals\n",
    "        \n",
    "        # Getting the embedding of the cls token for sentence level representation (used for constant embedding later)\n",
    "        problem_embeddings = output[:,0,:].to('cpu')\n",
    "        if all_cls is None:\n",
    "            all_cls = problem_embeddings\n",
    "        else:\n",
    "            all_cls = torch.cat((all_cls, problem_embeddings), dim=0)\n",
    "            \n",
    "        # Storing output to disk (too large to all fit in memory)\n",
    "        if not os.path.exists(f'{FINAL_DIR}embeddings/{name}'):\n",
    "            os.makedirs(f'{FINAL_DIR}embeddings/{name}')\n",
    "        with open(f'{FINAL_DIR}embeddings/{name}/batch{batch_num}.pickle', 'wb') as f:\n",
    "            pickle.dump(embeddings, f) \n",
    "        \n",
    "        # Cleaning up for the next batch\n",
    "        del ids\n",
    "        del num_idx\n",
    "        del mask\n",
    "        del num_embeddings\n",
    "        del idx\n",
    "        del embeddings\n",
    "        del output\n",
    "        torch.cuda.empty_cache()\n",
    "    return all_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bf6cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = {name:get_embeddings(name) for name in SET_NAMES}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186fcd5c",
   "metadata": {},
   "source": [
    "To get the constant embeddings, we take the average of all of the problem embeddings that the constant was used in. This should hopefully give the constants some more context during downstream training. The training data is only used for the constant embeddings, as you would not know what constants belong to the problem in the test/validation. For the constants, we use the predicted constants from the constant classifier file (even for training to maintain consistency). Also, adding randomly initialized operation embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13b2247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "op_embeds = torch.nn.init.normal_(torch.empty((len(op2id)+1,768)), mean=0, std=1)\n",
    "query = torch.nn.init.normal_(torch.empty((K,768)), mean=0, std=1)\n",
    "const_embeds = torch.stack(tuple([torch.mean(cls['train'][const2idx['train'][k]], dim=0) for k in const2idx['train'].keys()]))\n",
    "    \n",
    "init = {}\n",
    "init['op'] = op_embeds\n",
    "init['query'] = query\n",
    "init['const'] = const_embeds\n",
    "\n",
    "with open(f'{FINAL_DIR}embeddings/init.pickle', 'wb') as f:\n",
    "    pickle.dump(init, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5995dbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': None, 'validation': None, 'test': None}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = BATCH_SIZE\n",
    "with open(f'{FINAL_DIR}constants.pickle', 'rb') as f:\n",
    "    const_pred = pickle.load(f)\n",
    "id2const = {v:k for k, v in const2id.items()}\n",
    "\n",
    "def get_real_const(name):\n",
    "    arr = []\n",
    "    for nums in data[name]['nums']:\n",
    "        nums = eval(nums)\n",
    "        arr.append(set([const2id[x] for x in nums if x in const2id]))\n",
    "    return np.array(arr)\n",
    "\n",
    "def get_const_embeddings(name):\n",
    "    problem, const_idx = np.where(const_pred['pred'][name]==1)\n",
    "    batch_num = 0\n",
    "    real_const = get_real_const(name)\n",
    "    for idx in range(0,len(data[name]),8):\n",
    "        p_idx = problem[(problem>=idx)&(problem<idx+8)]     \n",
    "        c_idx = const_idx[(problem>=idx)&(problem<idx+8)]\n",
    "        \n",
    "        with open(f'{FINAL_DIR}embeddings/{name}/batch{batch_num}.pickle', 'rb') as f:\n",
    "             embeddings = pickle.load(f)\n",
    "        \n",
    "        num_literals = embeddings['num_literals'].to('cpu')\n",
    "        num_idx = embeddings['num_idx'].to('cpu')\n",
    "        num_embed = embeddings['nums'].to('cpu')\n",
    "        literals = np.concatenate((num_literals, [id2const[int(x)] for x in c_idx]))\n",
    "        idx = np.concatenate((num_idx, p_idx%8))\n",
    "        embed = torch.cat((num_embed, const_embeds[c_idx]),dim=0)\n",
    "        \n",
    "        embeddings['num_literals'] = np.array(literals)\n",
    "        embeddings['num_idx'] = torch.tensor(idx)\n",
    "        embeddings['nums'] = embed\n",
    "        \n",
    "        with open(f'{FINAL_DIR}embeddings/{name}/batch{batch_num}.pickle', 'wb') as f:\n",
    "            pickle.dump(embeddings, f) \n",
    "        \n",
    "        batch_num += 1\n",
    "        \n",
    "{name:get_const_embeddings(name) for name in SET_NAMES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03635459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': None, 'validation': None, 'test': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = BATCH_SIZE\n",
    "op2id['None'] = 5\n",
    "\n",
    "def get_exp(name):\n",
    "    reorder = lambda x: (x[1], x[0], x[2])\n",
    "    convert_to_arr = lambda d: [reorder(tuple(x.split())) for idx, arr in enumerate(d.split(' ; ')) for x in eval(arr) if x is not None and idx == 0]\n",
    "    return data[name]['incremental'].map(convert_to_arr)\n",
    "\n",
    "def non_homogeneous_split(arr, num_per_batch):\n",
    "     return [arr[idx:idx+num_per_batch] for idx in range(0,len(arr),num_per_batch)]\n",
    "\n",
    "def get_true_num(num, i, embeddings):\n",
    "    if num in const2val:\n",
    "        return const_embeds[const2id[num]]\n",
    "    else:\n",
    "        num_embed = embeddings['nums']\n",
    "        literals = embeddings['num_literals']\n",
    "        idx = embeddings['num_idx']\n",
    "        return num_embed[((idx==i)&(literals==str(float(num)))).bool()][0]\n",
    "    \n",
    "def get_true_label(num, i, embeddings):\n",
    "    num_embed = embeddings['nums']\n",
    "    literals = embeddings['num_literals']\n",
    "    idx = embeddings['num_idx']\n",
    "    label = torch.zeros(literals.shape)\n",
    "    if num in const2val:\n",
    "        location = np.where((idx==i)&(literals==num))[0]\n",
    "        if len(location) > 0:\n",
    "            location = location[0]\n",
    "        else: # if not found, the constant was not predicted from the constant predictor and we just return an empty label\n",
    "            return label\n",
    "    else:\n",
    "        location = np.where((idx==i)&(literals==str(float(num))))[0][0]\n",
    "    label[location]=1\n",
    "    return label\n",
    "\n",
    "def get_true(e, i, embeddings):\n",
    "    op, num1, num2 = e\n",
    "    op_embed = op_embeds[op2id[op]]\n",
    "    num1_embed = get_true_num(num1, i, embeddings)\n",
    "    num2_embed = get_true_num(num2, i, embeddings)\n",
    "    op_label = torch.zeros(len(op2id))\n",
    "    op_label[op2id[op]] = 1\n",
    "    num1_label = get_true_label(num1, i, embeddings)\n",
    "    num2_label = get_true_label(num2, i, embeddings)\n",
    "    return op_label, num1_label, num2_label, torch.cat((op_embed,num1_embed,num2_embed,num1_embed*num2_embed))\n",
    "\n",
    "def expand_tensor(curr, new):\n",
    "    if curr is None:\n",
    "        curr = new\n",
    "    else:\n",
    "        curr =  torch.cat((curr,new), dim=0)\n",
    "    return curr\n",
    "\n",
    "def pad_op(op_label):\n",
    "    temp = torch.zeros(op_label.shape[1])\n",
    "    temp[op2id['None']] = 1\n",
    "    return torch.cat((op_label, temp[None,:].repeat(K-op_label.shape[0],1)), dim=0)[None,:,:]\n",
    "\n",
    "def pad_num(num_label):\n",
    "    temp = torch.zeros(num_label.shape[1])\n",
    "    return torch.cat((num_label, temp[None,:].repeat(K-num_label.shape[0],1)), dim=0)[None,:,:]\n",
    "\n",
    "def get_true_batch(exp_batch, embeddings):\n",
    "    idx = []\n",
    "    true_embed = None\n",
    "    true_op_label = None\n",
    "    true_num1_label = None\n",
    "    true_num2_label = None\n",
    "    for i,e in enumerate(exp_batch):\n",
    "        get_true_embed = lambda x: get_true(x, i, embeddings)\n",
    "        op_label, num1_label, num2_label, embed = [torch.stack(item) for item in list(zip(*map(get_true_embed, e)))]\n",
    "        true_embed = expand_tensor(true_embed, embed)\n",
    "        \n",
    "        true_op_label = expand_tensor(true_op_label, pad_op(op_label))\n",
    "        \n",
    "        true_num1_label = expand_tensor(true_num1_label, pad_num(num1_label))\n",
    "        true_num2_label = expand_tensor(true_num2_label, pad_num(num2_label))\n",
    "        \n",
    "        idx.extend([i]*embed.shape[0])\n",
    "    return torch.tensor(idx), true_op_label, true_num1_label, true_num2_label, true_embed\n",
    "\n",
    "def create_masked_nums(embeddings, batch_size):\n",
    "    num_nums, embedding_size = embeddings['nums'].shape\n",
    "    idx = embeddings['num_idx']\n",
    "    masked_nums = None\n",
    "    for i in range(batch_size):\n",
    "        #temp = torch.zeros((num_nums, embedding_size))\n",
    "        temp = torch.full((num_nums, embedding_size), -math.inf)\n",
    "        temp[idx==i] = embeddings['nums'][idx==i]\n",
    "        masked_nums = expand_tensor(masked_nums, temp[None,:,:])\n",
    "    return masked_nums\n",
    "\n",
    "def get_all_true(name):\n",
    "    exp = non_homogeneous_split(get_exp(name).tolist(), batch_size)\n",
    "    directory = f'{FINAL_DIR}embeddings/{name}'\n",
    "    files = os.listdir(directory)\n",
    "    files.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    for batch_num, f in enumerate(files):\n",
    "        fname = os.path.join(directory, f)\n",
    "        with open(fname, 'rb') as f:\n",
    "            embeddings = pickle.load(f)\n",
    "            \n",
    "        idx, true_op_label, true_num1_label, true_num2_label, true_embed = get_true_batch(exp[batch_num], embeddings)\n",
    "        batch_idx = torch.arange(true_op_label.shape[0]).unsqueeze(-1)\n",
    "        perm = torch.stack(tuple([torch.randperm(K) for x in range(true_op_label.shape[0])])) # Ensure model does not just learn that all None operations are at the end\n",
    "        embeddings['true_op'] = true_op_label[batch_idx,perm,:]\n",
    "        embeddings['true_num1'] = true_num1_label[batch_idx,perm,:]\n",
    "        embeddings['true_num2'] = true_num2_label[batch_idx,perm,:]\n",
    "#         embeddings['true_op'] = true_op_label\n",
    "#         embeddings['true_num1'] = true_num1_labeltrue_op = \n",
    "#         embeddings['true_num2'] = true_num2_label\n",
    "        #embeddings['true_idx'] = idx\n",
    "        #embeddings['true_embed'] = true_embed\n",
    "        #embeddings['masked_nums'] = create_masked_nums(embeddings, batch_size)\n",
    "\n",
    "        with open(fname, 'wb') as f:\n",
    "            pickle.dump(embeddings, f)\n",
    "\n",
    "{name:get_all_true(name) for name in SET_NAMES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222d6487",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathQADecoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, config): \n",
    "        super(MathQADecoder, self).__init__()\n",
    "        self.device = config.device\n",
    "        self.embedding_size = config.embedding_size\n",
    "        self.num_tokens = config.num_tokens\n",
    "        self.K = config.K\n",
    "        self.path = config.path\n",
    "        self.query = config.query\n",
    "        self.op = config.op\n",
    "        self.grad_norm_clip = config.grad_norm_clip\n",
    "        \n",
    "        # Getting all the independent expressions\n",
    "        self.decoder_layer = DecoderLayer(config)\n",
    "        \n",
    "        # Optimizer\n",
    "        self.opt = config.opt(self.decoder_layer.parameters(), lr=config.lr)\n",
    "\n",
    "    def __expand_tensor(self, curr, new):\n",
    "        if curr is None:\n",
    "            curr = new\n",
    "        else:\n",
    "            curr =  torch.cat((curr,new), dim=0)\n",
    "        return curr\n",
    "    \n",
    "    def lmatch(self, embeddings, op, num1, num2):\n",
    "        true_ops = torch.clone(embeddings['true_op']).to(self.device)\n",
    "        true_num1 = embeddings['true_num1'].to(self.device)\n",
    "        true_num2 = embeddings['true_num2'].to(self.device)\n",
    "        #true_ops[:,:,op2id['None']] = 0 # setting all none operators to zero so ignored during calculation\n",
    "\n",
    "        # rows: true exp, cols: pred exp (ie 0,1 would be the cost for true exp 0 with pred exp 1)\n",
    "        # [8,K*K]\n",
    "        op_mat = (true_ops.repeat_interleave(K,dim=1)*op.repeat(1,K,1)).sum(dim=-1)\n",
    "        num1_mat = (true_num1.repeat_interleave(K,dim=1)*num1.repeat(1,K,1)).sum(dim=-1)\n",
    "        num2_mat = (true_num2.repeat_interleave(K,dim=1)*num2.repeat(1,K,1)).sum(dim=-1)\n",
    "\n",
    "        return -(op_mat+num1_mat+num2_mat).reshape(op_mat.shape[0],K,K)\n",
    "    \n",
    "    # consider trying to write this in pytorch if have time\n",
    "    def hungarian_algorithm(self, embeddings, op, num1, num2, batch_size):\n",
    "        m = self.lmatch(embeddings, op, num1, num2)\n",
    "        permutations = torch.stack(tuple([torch.tensor(linear_sum_assignment(m.detach().cpu().numpy()[x])[1]) for x in range(batch_size)]))\n",
    "        batch_idx = torch.arange(batch_size).unsqueeze(-1)\n",
    "        return op[batch_idx, permutations], num1[batch_idx, permutations], num2[batch_idx, permutations]\n",
    "    \n",
    "    # expects the optimal permutation from the hungarian algorithm\n",
    "    def final_loss(self, embeddings, op, num1, num2):\n",
    "        true_op = embeddings['true_op'].to(self.device)\n",
    "        true_num1 = embeddings['true_num1'].to(self.device)\n",
    "        true_num2 = embeddings['true_num2'].to(self.device)\n",
    "        \n",
    "        log_op = torch.log((true_op*op).sum(-1))\n",
    "        \n",
    "        log_num1 = ((true_num1*num1).sum(-1))\n",
    "        log_num1[log_num1.nonzero(as_tuple=True)] = torch.log(log_num1[log_num1.nonzero(as_tuple=True)])\n",
    "        \n",
    "        log_num2 = ((true_num2*num2).sum(-1))\n",
    "        log_num2[log_num2.nonzero(as_tuple=True)] = torch.log(log_num2[log_num2.nonzero(as_tuple=True)])\n",
    " \n",
    "        return (-log_op-log_num1-log_num2).sum(-1).mean()\n",
    "\n",
    "    # expects the optimal permutation from the hungarian algorithm\n",
    "    # gets the number of correct examples for a batch\n",
    "    def correct(self, embeddings, op, num1, num2):\n",
    "        true_op = embeddings['true_op'].to(self.device)\n",
    "        true_num1 = embeddings['true_num1'].to(self.device)\n",
    "        true_num2 = embeddings['true_num2'].to(self.device)\n",
    "        invalid = true_op.argmax(-1)==op2id['None']\n",
    "        op_correct = true_op.argmax(-1)==op.argmax(-1)\n",
    "        num1_correct = num1.argmax(-1)==true_num1.argmax(-1)\n",
    "        num2_correct = num2.argmax(-1)==true_num2.argmax(-1)\n",
    "        num1_correct[invalid]=True\n",
    "        num2_correct[invalid]=True\n",
    "        \n",
    "        correct = ((op_correct&num1_correct&num2_correct).sum(1)==self.K).sum()\n",
    "        num_ops = true_op.shape[0]*true_op.shape[1]\n",
    "        op_correct = op_correct.sum()\n",
    "        num_nums = len(num1_correct[~invalid])\n",
    "        num1_correct = num1_correct[~invalid].sum()\n",
    "        num2_correct = num2_correct[~invalid].sum()\n",
    "        return correct, op_correct, num_ops, num1_correct, num2_correct, num_nums\n",
    "    \n",
    "    def loss(self, embeddings, op, num1, num2, batch_size):\n",
    "        op, num1, num2 = self.hungarian_algorithm(embeddings, op, num1, num2, batch_size) # getting optimal permutation\n",
    "        \n",
    "        loss = self.final_loss(embeddings, op, num1, num2)\n",
    "        correct, op_correct, num_ops, num1_correct, num2_correct, num_nums = self.correct(embeddings, op, num1, num2)\n",
    "        \n",
    "        return loss, correct, op_correct, num_ops, num1_correct, num2_correct, num_nums\n",
    "    \n",
    "    def train(self, epoch, subset=None, shuffle=True):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_op_correct = 0\n",
    "        total_num1_correct = 0\n",
    "        total_num2_correct = 0\n",
    "        total_nums = 0\n",
    "        total_ops = 0\n",
    "        total_examples = 0\n",
    "        \n",
    "        directory = f'{self.path}/train'\n",
    "        files = np.array(os.listdir(directory))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(files)\n",
    "        if subset is not None:\n",
    "            files = files[0:subset]\n",
    "        with tqdm(range(len(files))) as bar:\n",
    "            for i in bar:\n",
    "                bar.set_description(f'Epoch {epoch}')\n",
    "                \n",
    "                fname = os.path.join(directory, files[i])\n",
    "                with open(fname, 'rb') as f:\n",
    "                    embeddings = pickle.load(f)\n",
    "\n",
    "                batch_size = embeddings['problem'].shape[0]\n",
    "                total_examples += batch_size\n",
    "\n",
    "                # Forward pass\n",
    "                x = self.query[None,:,:].repeat(batch_size,1,1) # [batch_size, K+1, 768]\n",
    "                x, op, num1, num2 = self.forward(x, embeddings) # x: [batch_size, K, 768]\n",
    "\n",
    "                # Getting the loss\n",
    "                loss, correct, op_correct, num_ops, num1_correct, num2_correct, num_nums = self.loss(embeddings, \n",
    "                                                                                                     op, \n",
    "                                                                                                     num1, \n",
    "                                                                                                     num2,\n",
    "                                                                                                     batch_size)\n",
    "                \n",
    "                # Backpropagating the loss\n",
    "                self.opt.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.decoder_layer.parameters(), self.grad_norm_clip)\n",
    "                self.opt.step()\n",
    "\n",
    "                total_loss += loss.detach().item()\n",
    "                total_correct += correct.detach().item()\n",
    "                total_op_correct += op_correct.detach().item()\n",
    "                total_num1_correct += num1_correct.detach().item()\n",
    "                total_num2_correct += num2_correct.detach().item()\n",
    "                total_ops += num_ops\n",
    "                total_nums += num_nums\n",
    "                \n",
    "                bar.set_postfix(loss=loss.detach().item())\n",
    "                \n",
    "        return total_loss/len(files), total_correct/total_examples, total_op_correct/total_ops, total_num1_correct/total_nums, total_num2_correct/total_nums\n",
    "    \n",
    "    def val(self, subset=1, shuffle=True):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_examples = 0\n",
    "        total_op_correct = 0\n",
    "        total_num1_correct = 0\n",
    "        total_num2_correct = 0\n",
    "        total_nums = 0\n",
    "        total_ops = 0\n",
    "        total_examples = 0\n",
    "        \n",
    "        directory = f'{self.path}/validation'\n",
    "        files = np.array(os.listdir(directory))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(files)\n",
    "        if subset is not None:\n",
    "            files = files[0:subset]\n",
    "        with torch.no_grad():\n",
    "            with tqdm(range(len(files))) as bar:\n",
    "                for i in bar:\n",
    "                    bar.set_description(f'Validation')\n",
    "\n",
    "                    fname = os.path.join(directory, files[i])\n",
    "                    with open(fname, 'rb') as f:\n",
    "                        embeddings = pickle.load(f)\n",
    "\n",
    "                    batch_size = embeddings['problem'].shape[0]\n",
    "                    total_examples += batch_size\n",
    "\n",
    "                    # Forward pass\n",
    "                    x = self.query[None,:,:].repeat(batch_size,1,1) # [batch_size, K, 768]\n",
    "                    x, op, num1, num2 = self.forward(x, embeddings) # x: [batch_size, K, 768]\n",
    "\n",
    "                    # Getting the loss\n",
    "                    loss, correct, op_correct, num_ops, num1_correct, num2_correct, num_nums = self.loss(embeddings, \n",
    "                                                                                                         op, \n",
    "                                                                                                         num1, \n",
    "                                                                                                         num2,\n",
    "                                                                                                         batch_size)\n",
    "                    \n",
    "                    total_loss += loss.item()\n",
    "                    total_correct += correct.item()\n",
    "                    total_op_correct += op_correct.item()\n",
    "                    total_num1_correct += num1_correct.item()\n",
    "                    total_num2_correct += num2_correct.item()\n",
    "                    total_ops += num_ops\n",
    "                    total_nums += num_nums\n",
    "                    \n",
    "        return total_loss/len(files), total_correct/total_examples, total_op_correct/total_ops, total_num1_correct/total_nums, total_num2_correct/total_nums\n",
    "    \n",
    "    def fit(self, epochs, tsubset=None, vsubset=None, shuffle=True):\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_acc, train_op_acc, train_num1_acc, train_num2_acc = self.train(epoch+1, tsubset, shuffle)\n",
    "            val_loss, val_acc, val_op_acc, val_num1_acc, val_num2_acc = self.val(vsubset, shuffle)\n",
    "            \n",
    "            df = pd.DataFrame({'Train':[train_loss, train_acc, train_op_acc, train_num1_acc, train_num2_acc], \n",
    "                               'Validation':[val_loss, val_acc, val_op_acc, val_num1_acc, val_num2_acc]},\n",
    "                       index = ['Loss','Accuracy','Op Accuracy','Num1 Accuracy','Num2 Accuracy'])\n",
    "            \n",
    "            display(df)\n",
    "            \n",
    "    def get_eq(self, embeddings, op, num1, num2):\n",
    "        literals = embeddings['num_literals']\n",
    "        op = op.cpu()\n",
    "        num1 = num1.cpu()\n",
    "        num2 = num2.cpu()\n",
    "        op_lit = np.array([id2op[x.item()] for x in op.argmax(-1).flatten()])\n",
    "        num1_lit = literals[num1.argmax(-1)].flatten()\n",
    "        num2_lit = literals[num2.argmax(-1)].flatten()\n",
    "        return np.array([f'{n1} {o} {n2}' if o!='None' else 'None' for o,n1,n2 in zip(op_lit,num1_lit,num2_lit)]).reshape(8,K)\n",
    "            \n",
    "    def forward(self, x, embeddings):\n",
    "        return self.decoder_layer(x, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79833267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_op2 = torch.tensor([[[.2,.01,.35,.09,.3,.05],\n",
    "#                          [.4,.01,.02,.03,.04,.5],\n",
    "#                          [.02,.08,.2,.25,.05,.4],\n",
    "#                          [.04,.06,.07,.03,.02,.78],\n",
    "#                          [.3,.03,.39,.01,.07,.2],\n",
    "#                          [.03,.04,.02,.01,.06,.84]]])\n",
    "# pred_num12 = torch.tensor([[[.1,.8,.03,.07],\n",
    "#                            [.7,.2,.06,.04],\n",
    "#                            [.2,.1,.65,.05],\n",
    "#                            [.1,.3,.2,.4],\n",
    "#                            [.45,.3,.05,.2],\n",
    "#                            [0.1, 0.5, 0.17, 0.23]]])\n",
    "# pred_num22 = torch.tensor([[[.09,.3,.11,.5],\n",
    "#                            [.3,.4,.25,.05],\n",
    "#                            [.1,.8,.04,.06],\n",
    "#                            [.7,0.01,.19,.1],\n",
    "#                            [.24,.26,.3,.2],\n",
    "#                            [.2,.11,.09,.6]]])\n",
    "# pred_op3 = torch.tensor([[[.2,.01,.35,.09,.3,.05],\n",
    "#                          [.4,.01,.02,.03,.04,.5],\n",
    "#                          [.02,.08,.2,.25,.05,.4],\n",
    "#                          [.04,.06,.07,.03,.02,.78],\n",
    "#                          [.3,.03,.39,.01,.07,.2],\n",
    "#                          [.03,.04,.02,.01,.06,.84]]])\n",
    "# pred_num13 = torch.tensor([[[.1,.8,.03,.07],\n",
    "#                            [.7,.2,.06,.04],\n",
    "#                            [.2,.1,.65,.05],\n",
    "#                            [.1,.3,.2,.4],\n",
    "#                            [.45,.3,.05,.2],\n",
    "#                            [0.1, 0.5, 0.17, 0.23]]])\n",
    "# pred_num23 = torch.tensor([[[.09,.3,.11,.5],\n",
    "#                            [.3,.4,.25,.05],\n",
    "#                            [.1,.8,.04,.06],\n",
    "#                            [.7,0.01,.19,.1],\n",
    "#                            [.24,.26,.3,.2],\n",
    "#                            [.2,.11,.09,.6]]])\n",
    "# pred_op = torch.tensor([[[.4,.01,.02,.03,.04,.5],\n",
    "#                          [.2,.01,.35,.09,.3,.05],\n",
    "#                          [.02,.08,.2,.25,.05,.4],\n",
    "#                          [.04,.06,.07,.03,.02,.78],\n",
    "#                          [.3,.03,.39,.01,.07,.2],\n",
    "#                          [.03,.04,.02,.01,.06,.84]]])\n",
    "# pred_num1 = torch.tensor([[[.7,.2,.06,.04],\n",
    "#                            [.1,.8,.03,.07],\n",
    "#                            [.2,.1,.65,.05],\n",
    "#                            [.1,.3,.2,.4],\n",
    "#                            [.45,.3,.05,.2],\n",
    "#                            [0.1, 0.5, 0.17, 0.23]]])\n",
    "# pred_num2 = torch.tensor([[[.3,.4,.25,.05],\n",
    "#                            [.09,.3,.11,.5],\n",
    "#                            [.1,.8,.04,.06],\n",
    "#                            [.7,0.01,.19,.1],\n",
    "#                            [.24,.26,.3,.2],\n",
    "#                            [.2,.11,.09,.6]]])\n",
    "\n",
    "# true_op = torch.tensor([[[0,0,1,0,0,0],[0,0,1,0,0,0],[0,0,0,0,0,1],[0,0,0,0,0,1],[0,0,0,0,0,1],[0,0,0,0,0,1]]])\n",
    "# true_num1 = torch.tensor([[[0,1,0,0],[1,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0]]])\n",
    "# true_num2 = torch.tensor([[[0,0,0,1],[0,0,1,0],[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0]]])\n",
    "\n",
    "# true_op = torch.cat((true_op,true_op,true_op), dim=0)\n",
    "# true_num1 = torch.cat((true_num1,true_num1,true_num1), dim=0)\n",
    "# true_num2 = torch.cat((true_num2,true_num2,true_num2), dim=0)\n",
    "# pred_op = torch.cat((pred_op,pred_op2,pred_op3), dim=0)\n",
    "# pred_num1 = torch.cat((pred_num1,pred_num12,pred_num13), dim=0)\n",
    "# pred_num2 = torch.cat((pred_num2,pred_num22,pred_num23), dim=0)\n",
    "\n",
    "# def lmatch(true_ops, true_num1, true_num2, op, num1, num2):\n",
    "#     true_ops = torch.clone(true_ops)\n",
    "#     true_ops[:,:,op2id['None']] = 0 # setting all none operators to zero so ignored during calculation\n",
    "\n",
    "#     # rows: true exp, cols: pred exp (ie 0,1 would be the cost for true exp 0 with pred exp 1)\n",
    "#     # [8,K*K]\n",
    "#     op_mat = (true_ops.repeat_interleave(K,dim=1)*op.repeat(1,K,1)).sum(dim=-1)\n",
    "#     num1_mat = (true_num1.repeat_interleave(K,dim=1)*num1.repeat(1,K,1)).sum(dim=-1)\n",
    "#     num2_mat = (true_num2.repeat_interleave(K,dim=1)*num2.repeat(1,K,1)).sum(dim=-1)\n",
    "\n",
    "#     return -(op_mat+num1_mat+num2_mat).reshape(op_mat.shape[0],K,K)\n",
    "\n",
    "# #print(lmatch(true_op, true_num1, true_num2, pred_op, pred_num1, pred_num2)[0])\n",
    "\n",
    "# # consider trying to write this in pytorch if have time\n",
    "# def hungarian_algorithm(true_ops, true_num1, true_num2, op, num1, num2, batch_size):\n",
    "#     m = lmatch(true_ops, true_num1, true_num2, op, num1, num2)\n",
    "#     permutations = torch.stack(tuple([torch.tensor(linear_sum_assignment(m.detach().cpu().numpy()[x])[1]) for x in range(batch_size)]))\n",
    "#     batch_idx = torch.arange(batch_size).unsqueeze(-1)\n",
    "#     return permutations\n",
    "#     #return op[batch_idx, permutations], num1[batch_idx, permutations], num2[batch_idx, permutations]\n",
    "    \n",
    "# hungarian_algorithm(true_op, true_num1, true_num2, pred_op, pred_num1, pred_num2, 3)\n",
    "\n",
    "# # def final_loss(true_op, true_num1, true_num2, op, num1, num2):\n",
    "# #     log_op = torch.log((true_op*op).sum(-1))\n",
    "\n",
    "# #     log_num1 = ((true_num1*num1).sum(-1))\n",
    "# #     log_num1[log_num1.nonzero(as_tuple=True)] = torch.log(log_num1[log_num1.nonzero(as_tuple=True)])\n",
    "\n",
    "# #     log_num2 = ((true_num2*num2).sum(-1))\n",
    "# #     log_num2[log_num2.nonzero(as_tuple=True)] = torch.log(log_num2[log_num2.nonzero(as_tuple=True)])\n",
    "\n",
    "# #     return (-log_op-log_num1-log_num2).sum(-1)\n",
    "\n",
    "# # final_loss(true_op, true_num1, true_num2, pred_op, pred_num1, pred_num2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652b14a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, config): \n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.device = config.device\n",
    "        self.embedding_size = config.embedding_size\n",
    "        self.num_tokens = config.num_tokens\n",
    "        self.K = config.K\n",
    "        self.op = config.op\n",
    "        \n",
    "        # standard transformer decoder\n",
    "        # we choose K heads, K layers for K generated expressions             \n",
    "        # (with the hope that each head/layer will get different information for each K expression)\n",
    "        transformer_decoder_layer = torch.nn.TransformerDecoderLayer(self.embedding_size, nhead=config.nhead, batch_first=True)\n",
    "        self.transformer_decoder = torch.nn.TransformerDecoder(transformer_decoder_layer, num_layers=config.nlayer)\n",
    "        \n",
    "        # softmax for the operations\n",
    "        self.op_softmax = torch.nn.Softmax(dim=2)\n",
    "        \n",
    "        # softmax for the numbers\n",
    "        self.num_softmax = torch.nn.Softmax(dim=0)\n",
    "        \n",
    "        # decreasing dimensionality to match embedding size: <op, num, num, num*num> = 3072 -> 768\n",
    "        self.exp_encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.embedding_size*4, self.embedding_size*2),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(self.embedding_size*2, self.embedding_size*2),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(self.embedding_size*2, self.embedding_size),\n",
    "        )\n",
    "        \n",
    "        # converting back into new <op, num, num> for loss calculation\n",
    "        self.exp_decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.embedding_size, self.embedding_size*2),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(self.embedding_size*2, self.embedding_size*2),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(self.embedding_size*2, self.embedding_size*3),\n",
    "        )\n",
    "        \n",
    "        # Attention Mask\n",
    "        #self.tgt_mask = torch.nn.Transformer().generate_square_subsequent_mask(sz=self.K).to(self.device)\n",
    "      \n",
    "    def __apply_to_nums(self, f, num, embeddings):\n",
    "        batch_size = embeddings['problem'].shape[0]\n",
    "        num_idx = embeddings['num_idx']\n",
    "        new_nums = torch.zeros(embeddings['true_num1'].shape).to(self.device)\n",
    "        for x in range(batch_size):\n",
    "            new_nums[x,:,num_idx==x] = f(num[num_idx==x]).T\n",
    "        return new_nums\n",
    "    \n",
    "    # x: [batch_size, K, 768]\n",
    "    # nums: [batch_size, num_nums, 768]\n",
    "    # ops: [num_ops, 768]\n",
    "    # problems: [batch_size, num_tokens, 768]\n",
    "    def forward(self, x, embeddings):    \n",
    "        nums = embeddings['nums'].to(self.device)\n",
    "        num_idx = embeddings['num_idx'].to(self.device)\n",
    "        ops = self.op\n",
    "        problems = embeddings['problem'].to(self.device)\n",
    "        batch_size = x.shape[0]\n",
    "        num_ops = ops.shape[0]\n",
    "        num_nums = nums.shape[0]\n",
    "\n",
    "        # ----------------------------\n",
    "        # Step 1 - transformer decoder\n",
    "        # ----------------------------\n",
    "        assert problems.shape == torch.Size([batch_size, self.num_tokens, self.embedding_size])\n",
    "        assert x.shape == torch.Size([batch_size, self.K, self.embedding_size])\n",
    "        x = self.transformer_decoder(x, problems) # [batch_size, K, 768] -> [batch_size, K, 768] (problems is [batch_size, num_tokens, 768])\n",
    "        assert x.shape == torch.Size([batch_size, self.K, self.embedding_size])\n",
    "        \n",
    "        # -------------------------------------------------------------------------------\n",
    "        # Step 2 - decoding the output into three embeddings of size 768 (op, num1, num2)\n",
    "        # -------------------------------------------------------------------------------\n",
    "        x = self.exp_decoder(x) # [batch_size, K, 768] -> [batch_size, K, 2304]\n",
    "        assert x.shape == torch.Size([batch_size, self.K, self.embedding_size*3])\n",
    "        operation, x1, x2 = torch.split(x, self.embedding_size, dim=2) # [batch_size, K, 2304] -> [batch_size, K, 768] for each\n",
    "        assert operation.shape == torch.Size([batch_size, self.K, self.embedding_size]) and x1.shape == torch.Size([batch_size, self.K, self.embedding_size]) and x2.shape == torch.Size([batch_size, self.K, self.embedding_size])\n",
    "\n",
    "        # -----------------------------------------------------------------------------------------------\n",
    "        # Step 3 and 4 - Finding the softmax for the similarity between the predicted and true embeddings\n",
    "        # -----------------------------------------------------------------------------------------------\n",
    "        # making sure params have correct dimension\n",
    "        nums_expanded = nums[:,None,:].expand(-1,K,-1) # [number_of_nums, 768] -> [number_of_nums, K, 768]\n",
    "        assert nums_expanded.shape == torch.Size([num_nums, self.K, self.embedding_size])\n",
    "        ops = ops[None,None,:,:].repeat(batch_size,self.K,1,1) # [num_ops, 768] -> [batch_size, K, num_ops, 768]\n",
    "        assert ops.shape == torch.Size([batch_size, self.K, num_ops, self.embedding_size])\n",
    "\n",
    "        # dot product - calculating the similarity between each op/num prediction and stored embeddings\n",
    "        num1 = (x1[num_idx]*nums_expanded).sum(dim=2) # [number_of_nums, K]\n",
    "        assert num1.shape == torch.Size([num_nums, self.K])\n",
    "        num2 = (x2[num_idx]*nums_expanded).sum(dim=2) # [number_of_nums, K]        \n",
    "        assert num2.shape == torch.Size([num_nums, self.K])\n",
    "        op = operation[:,:,None,:].expand(-1,-1,num_ops,-1) # [batch_size, K, 768] -> # [batch_size, K, num_ops, 768]\n",
    "        op = (op*ops).sum(dim=3) # [batch_size, K, num_ops, 768] -> [batch_size, K, num_ops]\n",
    "        assert op.shape == torch.Size([batch_size, self.K, num_ops])\n",
    "        \n",
    "        # softmax\n",
    "        op = self.op_softmax(op) # [batch_size, K, num_ops] (ie op[1,2] would be the operator prediction probabilities for problem2, query3)\n",
    "        assert op.shape == torch.Size([batch_size, self.K, num_ops])\n",
    "        assert op.sum(dim=2).sum()==batch_size*self.K  \n",
    "        \n",
    "        num1 = self.__apply_to_nums(self.num_softmax, num1, embeddings) # [batch_size,K,num_nums]\n",
    "        assert num1.shape == torch.Size([batch_size, self.K, num_nums])\n",
    "        assert np.isclose(num1[0].sum(1).sum().item(),self.K)\n",
    "        \n",
    "        num2 = self.__apply_to_nums(self.num_softmax, num2, embeddings) # [batch_size,K,num_nums]\n",
    "        assert num2.shape == torch.Size([batch_size, self.K, num_nums])\n",
    "        assert np.isclose(num2[0].sum(1).sum().item(),self.K)\n",
    "        \n",
    "        # ----------------------------------------------------\n",
    "        # Step 5 - creating embedding for the found expression  \n",
    "        # ----------------------------------------------------\n",
    "        x = self.exp_encoder(torch.cat((operation,x1,x2,x1*x2), dim=2)) # [batch_size, K, 3072] -> [batch_size, K, 768]  \n",
    "        assert x.shape == torch.Size([batch_size, self.K, self.embedding_size])\n",
    "        \n",
    "        # -----------------------\n",
    "        # Returning final results\n",
    "        # -----------------------\n",
    "        return x, op, num1, num2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584a937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     # Each set of equations starts with an sos token, and is padded with additional None tokens to reach K\n",
    "#     def __get_true_embed(self, embeddings):\n",
    "#         batch_size = embeddings['problem'].shape[0]\n",
    "#         idx = embeddings['true_idx']\n",
    "#         sos = embeddings['sos']\n",
    "#         x = self.exp_encoder(embeddings['true_embed'])\n",
    "#         x = torch.nn.functional.normalize(x, dim=-1)\n",
    "#         pad = self.exp_encoder(torch.cat((self.padding,embeddings['ops'][op2id['None']],self.padding,self.padding)))\n",
    "#         pad = torch.nn.functional.normalize(pad, dim=-1)\n",
    "#         new_x = None\n",
    "#         for batch_num in range(batch_size):\n",
    "#             temp = x[idx==batch_num]\n",
    "#             temp = torch.cat((sos[None,:], temp, pad[None,:].repeat(K-temp.shape[0],1)), dim=0)\n",
    "#             new_x = self.__expand_tensor(new_x, temp[None,:,:])\n",
    "#         return new_x\n",
    "    \n",
    "#     def __get_all_true(self):\n",
    "#         true = {}\n",
    "#         padding = torch.rand(self.embedding_size)\n",
    "#         for name in SET_NAMES:\n",
    "#             directory = f'{self.path}/{name}'\n",
    "#             files = os.listdir(directory)\n",
    "#             files.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "#             for batch_num, f in enumerate(files):\n",
    "#                 fname = os.path.join(directory, f)\n",
    "#                 with open(fname, 'rb') as f:\n",
    "#                     embeddings = pickle.load(f)\n",
    "#                 embeddings['true'] = self.__get_true_embed(embeddings, padding)\n",
    "#                 with open(fname, 'wb') as f:\n",
    "#                     pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a0d467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae36003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TestModel(unittest.TestCase):\n",
    "    \n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         super(TestModel, self).__init__(*args, **kwargs)\n",
    "#         self.data = util.load_data()\n",
    "#         self.config = Config(data, reload=False)\n",
    "    \n",
    "#     def test_config(self):\n",
    "#         # query\n",
    "#         self.assertEqual(self.config.query.shape, torch.Size([self.config.K, self.config.embedding_size]))\n",
    "#         self.assertEqual(self.config.query.unique(dim=0).shape, self.config.query.shape)\n",
    "\n",
    "#         # op\n",
    "#         self.assertEqual(self.config.op.shape, torch.Size([len(op2id), self.config.embedding_size]))\n",
    "#         self.assertEqual(self.config.op.unique(dim=0).shape, self.config.op.shape)\n",
    "#         for name in SET_NAMES:\n",
    "#             # nums\n",
    "#             self.assertEqual(self.config.num[name]['idx'].max(), len(self.data[name])-1)\n",
    "#             self.assertEqual(self.config.num[name]['idx'].shape, self.config.num[name]['literals'].shape)\n",
    "            \n",
    "#             # const\n",
    "#             self.assertEqual(self.config.const[name]['idx'].max(), len(self.data[name])-1)\n",
    "#             self.assertEqual(self.config.const[name]['idx'].shape, self.config.const[name]['literals'].shape)\n",
    "#             self.assertEqual(self.config.const[name]['embed_idx'].shape, self.config.const[name]['idx'].shape)\n",
    "#             self.assertEqual(self.config.const[name]['embed_idx'].max(), len(self.config.const[name]['embed'])-1)\n",
    "#             self.assertEqual(len(self.config.const[name]['embed']), config.const['train']['embed'].unique(dim=1).shape[0])\n",
    "            \n",
    "#             # combined\n",
    "#             self.assertEqual(self.config.combined[name]['idx'].max(), len(self.data[name])-1)\n",
    "#             self.assertEqual(self.config.combined[name]['idx'].shape, self.config.combined[name]['literals'].shape)\n",
    "#             self.assertEqual(self.config.combined[name]['idx'].shape[0], self.config.const[name]['idx'].shape[0]+self.config.num[name]['idx'].shape[0])    \n",
    "            \n",
    "#             # Checking if all equation nums are in the problem\n",
    "#             for i, eq_nums in enumerate([x-set(const2val.keys()) for x in data[name]['nums'].map(eval).tolist()]):\n",
    "#                 eq_nums = set(np.array(list(eq_nums)).astype(float))\n",
    "#                 literals = set(self.config.num[name]['literals'][self.config.num[name]['idx']==i])\n",
    "#                 self.assertTrue(eq_nums<=literals)\n",
    "                \n",
    "#             # Checking if constant correctness is within acceptable threshold\n",
    "#             num_correct = 0\n",
    "#             thresh = .97\n",
    "#             for i, actual in enumerate([x.intersection(set(const2val.keys())) for x in data[name]['nums'].map(eval).tolist()]):\n",
    "#                 predicted = set(id2const[config.const[name]['embed_idx'][config.const[name]['idx']==i]])\n",
    "#                 literals = set(self.config.const[name]['literals'][self.config.const[name]['idx']==i])\n",
    "#                 if actual <= predicted and literals <= predicted:\n",
    "#                     num_correct += 1\n",
    "#             self.assertTrue(num_correct/len(data[name]) >= thresh)\n",
    "            \n",
    "#             # Checking if all equations have same literals within threshold\n",
    "#             num_correct = 0\n",
    "#             thresh = .97\n",
    "#             for i, actual in enumerate(data[name]['nums'].map(eval).tolist()):\n",
    "#                 actual = set([x if x in const2val else str(float(x)) for x in actual])\n",
    "#                 literals = set(self.config.combined[name]['literals'][self.config.combined[name]['idx']==i])\n",
    "#                 if actual <= literals:\n",
    "#                     num_correct += 1\n",
    "#             self.assertTrue(num_correct/len(data[name]) >= thresh)\n",
    "            \n",
    "        \n",
    "# unittest.main(argv=[''], verbosity=2, exit=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eda2a2",
   "metadata": {},
   "source": [
    "## Old prepare labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc9ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labels(self, idx, true_labels, shape):\n",
    "    true_op, true_num1, true_num2 = true_labels\n",
    "    batch_size = true_op.shape[0]\n",
    "\n",
    "    temp = torch.zeros(shape)\n",
    "    unmasked = true_num1!=-1\n",
    "    true_idx = torch.cat([torch.where(idx==x)[0][true_num1[x][true_num1[x]!=-1]] for x in range(batch_size)])\n",
    "    temp[unmasked,true_idx]=1\n",
    "    true_num1 = temp\n",
    "\n",
    "    temp = torch.zeros(shape)\n",
    "    unmasked = true_num2!=-1\n",
    "    true_idx = torch.cat([torch.where(idx==x)[0][true_num2[x][true_num2[x]!=-1]] for x in range(batch_size)])\n",
    "    temp[unmasked,true_idx]=1\n",
    "    true_num2 = temp\n",
    "\n",
    "    # Randomizing equation order\n",
    "    batch_idx = torch.arange(batch_size).unsqueeze(-1)\n",
    "    perm = torch.rand(batch_size,self.K).argsort(dim=1)\n",
    "    true_op = true_op[batch_idx,perm,:]\n",
    "    true_num1 = true_num1[batch_idx,perm,:]\n",
    "    true_num2 = true_num2[batch_idx,perm,:]\n",
    "\n",
    "    return true_op.to(self.device), true_num1.to(self.device), true_num2.to(self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed25eb4",
   "metadata": {},
   "source": [
    "## Old preprocessing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c394948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def __get_init_exp(self, data, name):\n",
    "#         reorder = lambda x: [x[1], x[0], x[2]]\n",
    "#         convert_to_arr = lambda d: [reorder(x.split()) for idx, arr in enumerate(d.split(' ; ')) for x in eval(arr) if x is not None and idx == 0]\n",
    "#         return data[name]['incremental'].map(convert_to_arr)\n",
    "\n",
    "#     def __get_num_label(self, name, num, i):\n",
    "#         idx = self.combined[name]['idx']\n",
    "#         literals = self.combined[name]['literals'][idx==i]\n",
    "#         label = torch.zeros(literals.shape)\n",
    "#         if num in const2val:\n",
    "#             location = np.where(literals==num)[0]\n",
    "#             if len(location) == 0:\n",
    "#                 return torch.tensor(-1)\n",
    "#             else:\n",
    "#                 location = location[0]\n",
    "#         else:\n",
    "#             location = np.where(literals==str(float(num)))[0][0]\n",
    "#         return torch.tensor(location)\n",
    "\n",
    "#     def __pad_op(self, op_label):\n",
    "#         temp = torch.zeros(op_label.shape[1])\n",
    "#         temp[op2id['None']] = 1\n",
    "#         return torch.cat((op_label, temp[None,:].repeat(K-op_label.shape[0],1)), dim=0)[None,:,:]\n",
    "\n",
    "#     def __pad_num(self, num_label):\n",
    "#         return torch.cat((num_label, torch.tensor(-1).repeat(K-num_label.shape[0])), dim=0)\n",
    "\n",
    "#     def __get_true_label(self, name, e, i):\n",
    "#         op, num1, num2 = e\n",
    "#         op_label = torch.zeros(len(op2id))\n",
    "#         op_label[op2id[op]] = 1\n",
    "#         num1_label = self.__get_num_label(name, num1, i)\n",
    "#         num2_label = self.__get_num_label(name, num2, i)\n",
    "#         return op_label, num1_label, num2_label\n",
    "\n",
    "#     def __get_label(self, data, name):\n",
    "#         exp = self.__get_init_exp(data, name)\n",
    "#         idx = []\n",
    "#         true_op_label = None\n",
    "#         true_num1_label = []\n",
    "#         true_num2_label = []\n",
    "#         for i,e in enumerate(exp):\n",
    "#             get_true = lambda x: self.__get_true_label(name, x, i)\n",
    "#             op_label, num1_label, num2_label = [torch.stack(item) for item in list(zip(*map(get_true, e)))]\n",
    "#             true_op_label = self.__expand_tensor(true_op_label, self.__pad_op(op_label))\n",
    "#             true_num1_label.append(self.__pad_num(num1_label))\n",
    "#             true_num2_label.append(self.__pad_num(num2_label))\n",
    "# #         return true_op_label, torch.stack(true_num1_label), torch.stack(true_num2_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b93a3b",
   "metadata": {},
   "source": [
    "Getting the true labels for operations and numbers. Since our model will generate equations in any arbitrary order, we choose to store a tuple representation of the formula, which can be looked up later during loss calculation.\n",
    "\n",
    "The value stored in embeddings['true'] is batch size examples of (true_ops, true_num1, true_num2, layer_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49b2ea52",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'pickle/embeddings/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39marray(process_batch(embeddings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_idx\u001b[39m\u001b[38;5;124m'\u001b[39m], embeddings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_literals\u001b[39m\u001b[38;5;124m'\u001b[39m], exp[batch_num]), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m))\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m \u001b[43m{\u001b[49m\u001b[43mname\u001b[49m\u001b[43m:\u001b[49m\u001b[43mget_true_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSET_NAMES\u001b[49m\u001b[43m}\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 58\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39marray(process_batch(embeddings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_idx\u001b[39m\u001b[38;5;124m'\u001b[39m], embeddings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_literals\u001b[39m\u001b[38;5;124m'\u001b[39m], exp[batch_num]), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m))\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m {name:\u001b[43mget_true_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m SET_NAMES}\n",
      "Cell \u001b[1;32mIn[7], line 52\u001b[0m, in \u001b[0;36mget_true_labels\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     50\u001b[0m exp \u001b[38;5;241m=\u001b[39m non_homogeneous_split(get_exp(name)\u001b[38;5;241m.\u001b[39mtolist(), num_per_batch)\n\u001b[0;32m     51\u001b[0m directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFINAL_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124membeddings/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 52\u001b[0m files \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m files\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m f: \u001b[38;5;28mint\u001b[39m(re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, f)))\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_num, f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(files):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'pickle/embeddings/train'"
     ]
    }
   ],
   "source": [
    "num_per_batch = 8\n",
    "\n",
    "def get_exp(name):\n",
    "    reorder = lambda x: (x[1], x[0], x[2])\n",
    "    convert_to_arr = lambda d: [[reorder(tuple(x.split())),idx] for idx, arr in enumerate(d.split(' ; ')) for x in eval(arr) if x is not None]\n",
    "    return data[name]['incremental'].map(convert_to_arr)\n",
    "\n",
    "def non_homogeneous_split(arr, num_per_batch):\n",
    "    return [arr[idx:idx+num_per_batch] for idx in range(0,len(arr),num_per_batch)]\n",
    "\n",
    "def process_num(num, literals, idx, prob, prev):\n",
    "    if num in const2val:\n",
    "        temp = np.where((literals[idx==prob]==num))[0]\n",
    "        if len(temp) > 0:\n",
    "            return temp[0]\n",
    "        else: # The constant predictor failed to predict the correct constants for this specific problem\n",
    "            return None\n",
    "    elif 'x' in num:\n",
    "        eq_idx = int(num[1:])-1\n",
    "        return (prev[0][eq_idx], prev[1][eq_idx])\n",
    "    else:\n",
    "        return np.where((literals[idx==prob]==str(float(num))))[0][0]\n",
    "\n",
    "def process_exp(num_idx, literals, exp, p):\n",
    "    op_labels = None\n",
    "    num1_labels = []\n",
    "    num2_labels = []\n",
    "    layer_idx = []\n",
    "    for (op, num1, num2), layer in exp:\n",
    "        num1_labels.append(process_num(num1, literals, num_idx, p, (num1_labels, num2_labels)))\n",
    "        num2_labels.append(process_num(num2, literals, num_idx, p, (num1_labels, num2_labels)))\n",
    "        \n",
    "        temp = torch.zeros((1,6))\n",
    "        temp[0,op2id[op]] = 1\n",
    "        if op_labels is None:\n",
    "            op_labels = temp\n",
    "        else:\n",
    "            op_labels = torch.cat((op_labels,temp),dim=0)\n",
    "            \n",
    "        layer_idx.append(layer)\n",
    "    return op_labels, np.array(num1_labels, dtype=object), np.array(num2_labels, dtype=object), np.array(layer_idx)\n",
    "\n",
    "def process_batch(num_idx, literals, expressions):\n",
    "    results = []\n",
    "    for p,exp in enumerate(expressions):\n",
    "        results.append(process_exp(num_idx, literals, exp, p))\n",
    "    return results\n",
    "    \n",
    "def get_true_labels(name):\n",
    "    exp = non_homogeneous_split(get_exp(name).tolist(), num_per_batch)\n",
    "    for batch_num, f in enumerate(files):\n",
    "        print(np.array(process_batch(embeddings['num_idx'], embeddings['num_literals'], exp[batch_num]), dtype=object))\n",
    "        break\n",
    "            \n",
    "{name:get_true_labels(name) for name in SET_NAMES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd485ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand(6,768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4659ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
