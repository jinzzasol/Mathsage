{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb351cc0",
   "metadata": {},
   "source": [
    "# MathQA Constant Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663cf3d7",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70b11732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "================================================================================\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('D')}\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('AQAAANCMnd8BFdERjHoAwE/Cl+sBAAAAan+7O/HXGUqbHMC20qgFNAQAAAACAAAAAAAQZgAAAAEAACAAAAC8w/AUVoGAsqbSQ4BP00dpBuGDWNmlRDCh1ZtQ7JQdAQAAAAAOgAAAAAIAACAAAAAvgHApRUBuDQJb8EDv4lNKq7azDvkAMeQH0Lhlr+X0eWAAAABwNY/l5gPC9bcRZJSjpAala2n1ymOhAo8/TXNDiROtOe7at4ABGEtaXXnF7hDoxWJlGXMxJTKukH9ihVP+QY8gNobGVSScwqd1bkNzcz5x5Wb4qizsH517NFzu0P086yVAAAAA4u8Y1cDAwvbg0oghzLLIAsLGq12LQ4Gp4pAyNRX4Hu7CZH4H8ZJ9L9QhMg1bd71RNypAmMtw1NLXb0bDqRD5uw==')}\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('module'), WindowsPath('/matplotlib_inline.backend_inline')}\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('/usr/local/cuda/lib64')}\n",
      "DEBUG: Possible options found for libcudart.so: set()\n",
      "CUDA SETUP: PyTorch settings found: CUDA_VERSION=121, Highest Compute Capability: 8.6.\n",
      "CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n",
      "CUDA SETUP: Loading binary D:\\anaconda\\envs\\torch\\Lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda121.so...\n",
      "argument of type 'WindowsPath' is not iterable\n",
      "CUDA SETUP: Problem: The main issue seems to be that the main CUDA runtime library was not detected.\n",
      "CUDA SETUP: Solution 1: To solve the issue the libcudart.so location needs to be added to the LD_LIBRARY_PATH variable\n",
      "CUDA SETUP: Solution 1a): Find the cuda runtime library via: find / -name libcudart.so 2>/dev/null\n",
      "CUDA SETUP: Solution 1b): Once the library is found add it to the LD_LIBRARY_PATH: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:FOUND_PATH_FROM_1a\n",
      "CUDA SETUP: Solution 1c): For a permanent solution add the export from 1b into your .bashrc file, located at ~/.bashrc\n",
      "CUDA SETUP: Solution 2: If no library was found in step 1a) you need to install CUDA.\n",
      "CUDA SETUP: Solution 2a): Download CUDA install script: wget https://github.com/TimDettmers/bitsandbytes/blob/main/cuda_install.sh\n",
      "CUDA SETUP: Solution 2b): Install desired CUDA version to desired location. The syntax is bash cuda_install.sh CUDA_VERSION PATH_TO_INSTALL_INTO.\n",
      "CUDA SETUP: Solution 2b): For example, \"bash cuda_install.sh 113 ~/local/\" will download CUDA 11.3 and install into the folder ~/local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\torch\\Lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:166: UserWarning: Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      "\n",
      "  warn(msg)\n",
      "D:\\anaconda\\envs\\torch\\Lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:166: UserWarning: D:\\anaconda\\envs\\torch did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.trainer because of the following error (look up to see its traceback):\n\n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1130\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch\\Lib\\site-packages\\transformers\\trainer.py:198\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_peft_available():\n\u001b[1;32m--> 198\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftModel\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_accelerate_available():\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch\\Lib\\site-packages\\peft\\__init__.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.5.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     AutoPeftModel,\n\u001b[0;32m     24\u001b[0m     AutoPeftModelForCausalLM,\n\u001b[0;32m     25\u001b[0m     AutoPeftModelForSequenceClassification,\n\u001b[0;32m     26\u001b[0m     AutoPeftModelForSeq2SeqLM,\n\u001b[0;32m     27\u001b[0m     AutoPeftModelForTokenClassification,\n\u001b[0;32m     28\u001b[0m     AutoPeftModelForQuestionAnswering,\n\u001b[0;32m     29\u001b[0m     AutoPeftModelForFeatureExtraction,\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmapping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     32\u001b[0m     MODEL_TYPE_TO_PEFT_MODEL_MAPPING,\n\u001b[0;32m     33\u001b[0m     PEFT_TYPE_TO_CONFIG_MAPPING,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     inject_adapter_in_model,\n\u001b[0;32m     37\u001b[0m )\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch\\Lib\\site-packages\\peft\\auto.py:31\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftConfig\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmapping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MODEL_TYPE_TO_PEFT_MODEL_MAPPING\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpeft_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     PeftModel,\n\u001b[0;32m     34\u001b[0m     PeftModelForCausalLM,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m     PeftModelForTokenClassification,\n\u001b[0;32m     40\u001b[0m )\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch\\Lib\\site-packages\\peft\\mapping.py:23\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftConfig\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpeft_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     PeftModel,\n\u001b[0;32m     25\u001b[0m     PeftModelForCausalLM,\n\u001b[0;32m     26\u001b[0m     PeftModelForFeatureExtraction,\n\u001b[0;32m     27\u001b[0m     PeftModelForQuestionAnswering,\n\u001b[0;32m     28\u001b[0m     PeftModelForSeq2SeqLM,\n\u001b[0;32m     29\u001b[0m     PeftModelForSequenceClassification,\n\u001b[0;32m     30\u001b[0m     PeftModelForTokenClassification,\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     AdaLoraConfig,\n\u001b[0;32m     34\u001b[0m     AdaLoraModel,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m     PromptTuningConfig,\n\u001b[0;32m     43\u001b[0m )\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch\\Lib\\site-packages\\peft\\peft_model.py:38\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftConfig\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     39\u001b[0m     AdaLoraModel,\n\u001b[0;32m     40\u001b[0m     AdaptionPromptModel,\n\u001b[0;32m     41\u001b[0m     IA3Model,\n\u001b[0;32m     42\u001b[0m     LoraModel,\n\u001b[0;32m     43\u001b[0m     PrefixEncoder,\n\u001b[0;32m     44\u001b[0m     PromptEmbedding,\n\u001b[0;32m     45\u001b[0m     PromptEncoder,\n\u001b[0;32m     46\u001b[0m )\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     48\u001b[0m     SAFETENSORS_WEIGHTS_NAME,\n\u001b[0;32m     49\u001b[0m     TRANSFORMERS_MODELS_TO_PREFIX_TUNING_POSTPROCESS_MAPPING,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     62\u001b[0m     shift_tokens_right,\n\u001b[0;32m     63\u001b[0m )\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch\\Lib\\site-packages\\peft\\tuners\\__init__.py:21\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madaption_prompt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AdaptionPromptConfig, AdaptionPromptModel\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlora\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoraConfig, LoraModel\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mia3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IA3Config, IA3Model\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch\\Lib\\site-packages\\peft\\tuners\\lora.py:45\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_bnb_available():\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbnb\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLoraConfig\u001b[39;00m(PeftConfig):\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch\\Lib\\site-packages\\bitsandbytes\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cuda_setup, utils, research\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     MatmulLtState,\n\u001b[0;32m      9\u001b[0m     bmm_cublas,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     matmul_4bit\n\u001b[0;32m     14\u001b[0m )\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch\\Lib\\site-packages\\bitsandbytes\\research\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     switchback_bnb,\n\u001b[0;32m      4\u001b[0m     matmul_fp8_global,\n\u001b[0;32m      5\u001b[0m     matmul_fp8_mixed,\n\u001b[0;32m      6\u001b[0m )\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch\\Lib\\site-packages\\bitsandbytes\\research\\nn\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearFP8Mixed, LinearFP8Global\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch\\Lib\\site-packages\\bitsandbytes\\research\\nn\\modules.py:8\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbnb\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GlobalOptimManager\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OutlierTracer, find_outlier_dims\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch\\Lib\\site-packages\\bitsandbytes\\optim\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m COMPILED_WITH_CUDA\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madagrad\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adagrad, Adagrad8bit, Adagrad32bit\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch\\Lib\\site-packages\\bitsandbytes\\cextension.py:20\u001b[0m\n\u001b[0;32m     19\u001b[0m     CUDASetup\u001b[38;5;241m.\u001b[39mget_instance()\u001b[38;5;241m.\u001b[39mprint_log_stack()\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124m    CUDA Setup failed despite GPU being available. Please run the following command to get more information:\u001b[39m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[38;5;124m    python -m bitsandbytes\u001b[39m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;124m    Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124m    to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124m    and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues\u001b[39m\u001b[38;5;124m'''\u001b[39m)\n\u001b[0;32m     28\u001b[0m lib\u001b[38;5;241m.\u001b[39mcadam32bit_grad_fp32 \u001b[38;5;66;03m# runs on an error if the library could not be found -> COMPILED_WITH_CUDA=False\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModel, TrainingArguments, Trainer, AutoModelForSequenceClassification\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m f1_score, accuracy_score\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1120\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[0;32m   1119\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1120\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1121\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1132\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1132\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1135\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.trainer because of the following error (look up to see its traceback):\n\n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, TrainingArguments, Trainer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from datasets import Dataset\n",
    "import warnings\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7585821d",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b29be",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_MODE = True # Set this to false to switch this into load and evaluate mode\n",
    "DATA_PATH = './dataset/'\n",
    "SET_NAMES = ['train', 'validation', 'test']\n",
    "MODEL_TYPE = 'microsoft/deberta-v3-large' # A more optimized version of roberta obtaining 95% of its performance\n",
    "MODEL_PATH = f'{MODEL_TYPE.split(\"/\")[-1]}-op_classifier-mathqa'\n",
    "MAX_LENGTH = 392\n",
    "NUM_MASK = '<num>'\n",
    "WORKING_DIR = 'TEMP/'\n",
    "FINAL_DIR = 'pickle/'\n",
    "\n",
    "class Op(Enum):\n",
    "    ADD = '+'\n",
    "    SUB = '-'\n",
    "    MULT = '*'\n",
    "    DIV = '/'\n",
    "    POW = '^'\n",
    "    \n",
    "class Const(Enum):\n",
    "    CONST_NEG_1 = 'const_neg_1' # I added this\n",
    "    CONST_0_25 = 'const_0_25'\n",
    "    CONST_0_2778 = 'const_0_2778'\n",
    "    CONST_0_33 = 'const_0_33'\n",
    "    CONST_0_3937 = 'const_0_3937'\n",
    "    CONST_1 = 'const_1'\n",
    "    CONST_1_6 = 'const_1_6'\n",
    "    CONST_2 = 'const_2'\n",
    "    CONST_3 = 'const_3'\n",
    "    CONST_PI = 'const_pi'\n",
    "    CONST_3_6 = 'const_3_6'\n",
    "    CONST_4 = 'const_4'\n",
    "    CONST_5 = 'const_5'\n",
    "    CONST_6 = 'const_6'\n",
    "    CONST_10 = 'const_10'\n",
    "    CONST_12 = 'const_12'\n",
    "    CONST_26 = 'const_26'\n",
    "    CONST_52 = 'const_52'\n",
    "    CONST_60 = 'const_60'\n",
    "    CONST_100 = 'const_100'\n",
    "    CONST_180 = 'const_180'\n",
    "    CONST_360 = 'const_360'\n",
    "    CONST_1000 = 'const_1000'\n",
    "    CONST_3600 = 'const_3600'\n",
    "\n",
    "values = [-1, 0.25, 0.2778, 0.33, 0.3937, 1, 1.6, 2, 3, math.pi, 3.6, 4, 5, 6, 10, 12, 26, 52, 60, 100, 180, 360, 1000, 3600]\n",
    "const2val = {k:v for k,v in zip(Const._value2member_map_.keys(), values)}    \n",
    "\n",
    "op2id = {k:v for k,v in zip(Op._value2member_map_.keys(), range(len(Op._value2member_map_)))}\n",
    "const2id = {k:v for k,v in zip(Const._value2member_map_.keys(), range(len(Const._value2member_map_)))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f72619",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bf445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {name:pd.read_csv(f'{DATA_PATH}{name}.csv') for name in SET_NAMES}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afd0a06",
   "metadata": {},
   "source": [
    "This function converts all of the constants used in a problem to a single one hot encoded vector used for multi class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65a490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_const(data):\n",
    "    labels = []\n",
    "    for num_set in data.nums:\n",
    "        num_set = eval(num_set)\n",
    "        idx = [const2id[num] for num in num_set if num in const2id]\n",
    "        onehot = np.zeros(len(const2id))\n",
    "        onehot[idx] = 1\n",
    "        labels.append(onehot)\n",
    "    return np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05dcf63",
   "metadata": {},
   "source": [
    "Getting only the necessary columns from the data (text/label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff23af09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {name:Dataset.from_dict({'text':data[name]['problem'], 'labels':onehot_const(data[name])}) for name in SET_NAMES}\n",
    "data['train'].set_format('torch')\n",
    "data['validation'].set_format('torch')\n",
    "data['test'].set_format('torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d34c4ed",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a32b9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_TYPE)\n",
    "\n",
    "def tokenization(items):\n",
    "    return tokenizer(items['text'], padding='max_length', max_length=MAX_LENGTH, truncation=True)\n",
    "\n",
    "encoded = {k:v.map(tokenization, batched=True, remove_columns=['text']) for k,v in data.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d143dfdd",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491fad7e",
   "metadata": {},
   "source": [
    "Training a model to predict which constants are used given a problem description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70974d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 4\n",
    "grad_acc = 4\n",
    "model_path = MODEL_PATH\n",
    "if TRAINING_MODE:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_TYPE, \n",
    "                                                               problem_type = 'multi_label_classification', \n",
    "                                                               num_labels = len(const2id))\n",
    "else:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path, \n",
    "                                                               problem_type = 'multi_label_classification', \n",
    "                                                               num_labels = len(const2id))\n",
    "    \n",
    "def get_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        'micro-f1': f1_score(y_true=y_true, y_pred=y_pred, average='micro'), \n",
    "        'macro-f1': f1_score(y_true=y_true, y_pred=y_pred, average='macro'),\n",
    "        'weighted-f1': f1_score(y_true=y_true, y_pred=y_pred, average='weighted'),\n",
    "        'accuracy': accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    }\n",
    "\n",
    "def compute_metrics_helper(p, label, thresh=0.5):\n",
    "    # Converting all values in the vector to be between 0 and 1\n",
    "    # The reason why softmax is not used is because we are doing multi label classification, meaning the total sum may be above 1\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    prob = sigmoid(torch.Tensor(p))\n",
    "    \n",
    "    # Converting items above the threshold to integers\n",
    "    y_pred = np.zeros(prob.shape)\n",
    "    y_pred[np.where(prob >= thresh)] = 1\n",
    "    \n",
    "    # Computing the metrics (f1, accuracy)\n",
    "    return get_metrics(label, y_pred)\n",
    "\n",
    "def compute_metrics(p):\n",
    "    return compute_metrics_helper(p.predictions, p.label_ids)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir = f'{WORKING_DIR}{model_path}',\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=500,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    learning_rate = 5e-6, # DeBERTa requires a lower learning rate\n",
    "    per_device_train_batch_size = batch,\n",
    "    per_device_eval_batch_size = batch,\n",
    "    gradient_accumulation_steps=grad_acc,\n",
    "    weight_decay=.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs = 5,\n",
    "    metric_for_best_model=\"accuracy\",  \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset = encoded['train'],\n",
    "    eval_dataset = encoded['validation'],\n",
    "    compute_metrics = compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b10872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TRAINING_MODE:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        trainer.train()\n",
    "        trainer.save_model(model_path)\n",
    "else:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        predictions = {name:trainer.predict(encoded[name]) for name in SET_NAMES}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5718799",
   "metadata": {},
   "source": [
    "## Analysis and Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e89336",
   "metadata": {},
   "source": [
    "As we can see, f1 and accuracy scores lie within the 80-85% accuracy range (except for macro f1, but we do not care about that as much for this specific problem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a46595f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \n",
      "{'micro-f1': 0.9210672595886603, 'macro-f1': 0.49350996493174204, 'weighted-f1': 0.9136586570272305, 'accuracy': 0.8795498215756244}\n",
      "\n",
      "VALIDATION: \n",
      "{'micro-f1': 0.8561643835616438, 'macro-f1': 0.4654305745971823, 'weighted-f1': 0.8468692698818778, 'accuracy': 0.8129151291512915}\n",
      "\n",
      "TEST: \n",
      "{'micro-f1': 0.8450920245398772, 'macro-f1': 0.4386897976899995, 'weighted-f1': 0.83637342170732, 'accuracy': 0.7975528364849833}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not TRAINING_MODE:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        for name in SET_NAMES:\n",
    "            print(f\"{name.upper()}: \")\n",
    "            print(compute_metrics_helper(predictions[name].predictions, predictions[name].label_ids))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef665b65",
   "metadata": {},
   "source": [
    "This is an acceptable accuracy, however, ideally this should be higher, especially if this is intended to be used on a downstream task. For our specific task, simply finding the constants that are useful for the problem, we care much more about recall than precision. Below we show some analysis by looking at the percentage of problems with missed constants and experimenting with the threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42b35bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_without_missed_const(p, label, thresh=0.5):\n",
    "    # Converting all values in the vector to be between 0 and 1\n",
    "    # The reason why softmax is not used is because we are doing multi label classification, meaning the total sum may be above 1\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    prob = sigmoid(torch.Tensor(p))\n",
    "    \n",
    "    # Converting items above the threshold to integers\n",
    "    y_pred = np.zeros(prob.shape)\n",
    "    y_pred[np.where(prob >= thresh)] = 1\n",
    "    \n",
    "    y_true = label\n",
    "    \n",
    "    # if the true set is a subset of the predicted set then it did not miss any constants in the problem\n",
    "    # returns avg # constants per problem, percent without any missed\n",
    "    return np.mean(np.sum(y_pred, axis=1)), np.sum([set(np.where(true==1)[0]) <= set(np.where(pred==1)[0]) for true, pred in zip(y_true, y_pred)])/len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182d5922",
   "metadata": {},
   "source": [
    "Shown below is the percentage of problems without any missed constants along with the average number of constants predicted given different thresholds. Using a threshold of .005 on the validation set still results in over a 98% coverage, but reduces the average number of constants from 24 to just under 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e728cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THRESH: 0.5\n",
      "Percent without any missed: 0.8557195571955719\n",
      "Average number of constants per problem: 1.033579335793358\n",
      "\n",
      "THRESH: 0.05\n",
      "Percent without any missed: 0.9254612546125461\n",
      "Average number of constants per problem: 1.8154981549815499\n",
      "\n",
      "THRESH: 0.005\n",
      "Percent without any missed: 0.9826568265682657\n",
      "Average number of constants per problem: 5.815129151291513\n",
      "\n",
      "THRESH: 0.001\n",
      "Percent without any missed: 0.9981549815498155\n",
      "Average number of constants per problem: 12.17490774907749\n",
      "\n",
      "THRESH: 0\n",
      "Percent without any missed: 1.0\n",
      "Average number of constants per problem: 24.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0.5, 0.05, 0.005, 0.001, 0]\n",
    "for thresh in thresholds:\n",
    "    print(f'THRESH: {thresh}')\n",
    "    avg_per_prob, percent_no_missed = percent_without_missed_const(predictions['validation'].predictions, predictions['validation'].label_ids, thresh)\n",
    "    print(f\"Percent without any missed: {percent_no_missed}\")\n",
    "    print(f\"Average number of constants per problem: {avg_per_prob}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4848c27",
   "metadata": {},
   "source": [
    "To show that this generalizes, showing the test set using a .005 threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0debf886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THRESH: 0.005\n",
      "Percent without any missed: 0.9805339265850945\n",
      "Average number of constants per problem: 5.800889877641824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thresholds = [.005]\n",
    "for thresh in thresholds:\n",
    "    print(f'THRESH: {thresh}')\n",
    "    avg_per_prob, percent_no_missed = percent_without_missed_const(predictions['test'].predictions, predictions['test'].label_ids, thresh)\n",
    "    print(f\"Percent without any missed: {percent_no_missed}\")\n",
    "    print(f\"Average number of constants per problem: {avg_per_prob}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54606404",
   "metadata": {},
   "source": [
    "## Storing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa1b008",
   "metadata": {},
   "source": [
    "Lastly, the the predicted values along with a mapping are saved to disk for use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c7fad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(p, thresh=0.005):\n",
    "    # Converting all values in the vector to be between 0 and 1\n",
    "    # The reason why softmax is not used is because we are doing multi label classification, meaning the total sum may be above 1\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    prob = sigmoid(torch.Tensor(p))\n",
    "    \n",
    "    # Converting items above the threshold to integers\n",
    "    y_pred = np.zeros(prob.shape)\n",
    "    y_pred[np.where(prob >= thresh)] = 1\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "y_pred = {name:get_pred(predictions[name].predictions) for name in SET_NAMES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd7d6763",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'pred': y_pred, 'map':const2id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "088af01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(FINAL_DIR):\n",
    "    os.makedirs(FINAL_DIR)\n",
    "    \n",
    "with open(f'{FINAL_DIR}constants.pickle', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a060f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
