{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c89aba5",
   "metadata": {},
   "source": [
    "# MathQA Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c79566",
   "metadata": {},
   "source": [
    "Notes/Todo:\n",
    "- Make sure to set params back to normal (see pic)\n",
    "- Use one global optimizer\n",
    "- Create class for whole model\n",
    "- Loss should be concatenated at each layer and returned at end\n",
    "- Best course of action would be to get layer 2 working with teacher forcing and see if that can be trained before putting all together\n",
    "- Keep running list of all true embeddings updated every layer\n",
    "- Are duplicate equations allowed on seperate layers? (dont think so but probably should double check)\n",
    "- implement code to remove item from batch once it has finished"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cd6cad",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71dadcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pickle\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "if get_ipython().__class__.__name__ == 'ZMQInteractiveShell':\n",
    "    from tqdm.notebook import tqdm\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "import unittest\n",
    "\n",
    "# remove\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99aa0f0",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf2941c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 6\n",
    "MAX_LAYERS = 8\n",
    "MAX_TOKENS = 392\n",
    "EMBEDDING_SIZE = 768\n",
    "\n",
    "DATA_PATH = './dataset/'\n",
    "SET_NAMES = ['train', 'validation', 'test']\n",
    "ENCODER_MODEL = 'distilroberta-base' # A more optimized version of roberta obtaining 95% of its performance\n",
    "DEVICE = 'cuda:0'\n",
    "NUM_MASK = '<num>'\n",
    "WORKING_DIR = 'TEMP/'\n",
    "\n",
    "OBJ_DIR = 'pickle/'\n",
    "\n",
    "\n",
    "class Op(Enum):\n",
    "    ADD = '+'\n",
    "    SUB = '-'\n",
    "    MULT = '*'\n",
    "    DIV = '/'\n",
    "    POW = '^'\n",
    "    \n",
    "class Const(Enum):\n",
    "    CONST_NEG_1 = 'const_neg_1' # I added this\n",
    "    CONST_0_25 = 'const_0_25'\n",
    "    CONST_0_2778 = 'const_0_2778'\n",
    "    CONST_0_33 = 'const_0_33'\n",
    "    CONST_0_3937 = 'const_0_3937'\n",
    "    CONST_1 = 'const_1'\n",
    "    CONST_1_6 = 'const_1_6'\n",
    "    CONST_2 = 'const_2'\n",
    "    CONST_3 = 'const_3'\n",
    "    CONST_PI = 'const_pi'\n",
    "    CONST_3_6 = 'const_3_6'\n",
    "    CONST_4 = 'const_4'\n",
    "    CONST_5 = 'const_5'\n",
    "    CONST_6 = 'const_6'\n",
    "    CONST_10 = 'const_10'\n",
    "    CONST_12 = 'const_12'\n",
    "    CONST_26 = 'const_26'\n",
    "    CONST_52 = 'const_52'\n",
    "    CONST_60 = 'const_60'\n",
    "    CONST_100 = 'const_100'\n",
    "    CONST_180 = 'const_180'\n",
    "    CONST_360 = 'const_360'\n",
    "    CONST_1000 = 'const_1000'\n",
    "    CONST_3600 = 'const_3600'\n",
    "\n",
    "values = [-1, 0.25, 0.2778, 0.33, 0.3937, 1, 1.6, 2, 3, math.pi, 3.6, 4, 5, 6, 10, 12, 26, 52, 60, 100, 180, 360, 1000, 3600]\n",
    "const2val = {k:v for k,v in zip(Const._value2member_map_.keys(), values)}    \n",
    "\n",
    "op2id = {k:v for k,v in zip(Op._value2member_map_.keys(), range(len(Op._value2member_map_)))}\n",
    "op2id['None'] = 5\n",
    "id2op = {v:k for k,v in op2id.items()}\n",
    "const2id = {k:v for k,v in zip(Const._value2member_map_.keys(), range(len(Const._value2member_map_)))}\n",
    "id2const = np.array(list(const2id.keys()))\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "class Util():\n",
    "    def load_obj(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            o = pickle.load(f)\n",
    "        return o\n",
    "    \n",
    "    def save_obj(self, path, o):\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(o, f)\n",
    "            \n",
    "    def load_data(self):\n",
    "        return {name:pd.read_csv(f'{DATA_PATH}{name}.csv') for name in SET_NAMES}\n",
    "    \n",
    "    def set_seed(self, seed):\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "util = Util()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22c3c62",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c8df74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess:\n",
    "    \n",
    "    def __init__(self, data, K, embedding_size, max_tokens, model_name, tokenizer_name):\n",
    "        # Randomly initializing embeddings\n",
    "        self.op = torch.randn(len(op2id),embedding_size)\n",
    "        self.query = torch.randn(K,embedding_size)\n",
    "        const = torch.randn(len(const2id),embedding_size)\n",
    "        \n",
    "        self.num, self.text = self.__get_nums_and_mask(data)\n",
    "        self.const = self.__get_const(const)\n",
    "        self.combined = self.__combine(self.num, self.const)\n",
    "        self.labels = {name:self.__get_labels(data,name) for name in SET_NAMES}\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder, self.tokenizer = self.__setup_model(model_name, tokenizer_name)\n",
    "        self.tokenized = {name:self.__tokenize_data(self.tokenizer, self.text[name], max_tokens) for name in SET_NAMES}\n",
    "        \n",
    "    # -----------------------------------------------------------\n",
    "    # util\n",
    "    # -----------------------------------------------------------\n",
    "    def __expand_tensor(self, curr, new):\n",
    "        if curr is None:\n",
    "            curr = new\n",
    "        else:\n",
    "            curr =  torch.cat((curr,new), dim=0)\n",
    "        return curr\n",
    "    \n",
    "    def __flatten(self, arr):\n",
    "        idx = np.concatenate([[i]*len(x) for i,x in enumerate(arr)])\n",
    "        flattened = np.concatenate(arr) \n",
    "        return idx, flattened\n",
    "    \n",
    "    # -----------------------------------------------------------\n",
    "    # tokenization\n",
    "    # -----------------------------------------------------------\n",
    "    def __setup_model(self, model_name, tokenizer_name):\n",
    "        model = AutoModel.from_pretrained(model_name, output_hidden_states=True)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        tokenizer.add_special_tokens({'additional_special_tokens':[NUM_MASK]})\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "        return model, tokenizer\n",
    "    \n",
    "    def __tokenize_data(self, tokenizer, text, max_tokens):\n",
    "        tokenization = lambda x: tokenizer(x, padding='max_length', max_length=max_tokens, truncation=True)\n",
    "\n",
    "        tokenized = list(map(tokenization, text))\n",
    "        input_ids = torch.stack([torch.tensor(x['input_ids']) for x in tokenized])\n",
    "        attention_mask = torch.stack([torch.tensor(x['attention_mask']) for x in tokenized])\n",
    "\n",
    "        return {'input_ids':input_ids.long(), 'attention_mask':attention_mask.int()}\n",
    "    \n",
    "    # -----------------------------------------------------------\n",
    "    # literals\n",
    "    # -----------------------------------------------------------\n",
    "    # Gets the numbers listed in a problem\n",
    "    # Once found, numbers are masked using a number mask\n",
    "    def __get_nums_and_mask(self, data):\n",
    "        nums = {name:[] for name in SET_NAMES}\n",
    "        problems = {name:[] for name in SET_NAMES}\n",
    "        num_idx = {name:[] for name in SET_NAMES}\n",
    "        for name in SET_NAMES:\n",
    "            for i,problem in enumerate(data[name].problem):\n",
    "                num = re.compile('([+-]?((\\d+(\\.\\d*)?)|(\\.\\d+)))') # normal num\n",
    "                big = re.compile(r'(-?\\d{1,3}(,\\d{3})+(\\.\\d*)?)') # num with comma\n",
    "\n",
    "                big_results = re.finditer(big, problem)\n",
    "                problem = re.sub(big, NUM_MASK, problem)        \n",
    "                num_results = re.finditer(num, problem)\n",
    "                problem = re.sub(num, NUM_MASK, problem)\n",
    "\n",
    "                # Getting the combined numbers in order of occurence\n",
    "                combined = [x for x in num_results]\n",
    "                combined.extend([x for x in big_results])\n",
    "                combined = sorted(combined, key=lambda x: x.start(0))\n",
    "\n",
    "                combined = [float(x.group(0).replace(',','')) for x in combined]\n",
    "\n",
    "                nums[name].append(np.array(combined))\n",
    "                problems[name].append(problem)\n",
    "            num_idx[name], nums[name] = self.__flatten(np.array(nums[name], dtype=object))\n",
    "            problems[name] = np.array(problems[name])\n",
    "        return {name:{'idx':torch.tensor(num_idx[name]), 'literals':nums[name]} for name in SET_NAMES}, problems\n",
    "    \n",
    "    def __get_const(self, embed):\n",
    "        const = {}\n",
    "        for name in SET_NAMES:\n",
    "            const_pred = util.load_obj(f'{OBJ_DIR}constants.pickle')['pred'][name]\n",
    "            const_idx, const_id = np.where(const_pred==1)\n",
    "            literals = id2const[const_id]\n",
    "            const[name] = {'idx':torch.tensor(const_idx), 'literals':literals, 'embed_idx':const_id, 'embed':embed}\n",
    "        return const\n",
    "    \n",
    "    def __combine(self, num, const):\n",
    "        combined = {}\n",
    "        for name in SET_NAMES:\n",
    "            combined[name] = {'idx':torch.cat((num[name]['idx'],const[name]['idx'])), \n",
    "                              'literals':np.concatenate((num[name]['literals'],const[name]['literals']))}\n",
    "        return combined\n",
    "    \n",
    "    # -----------------------------------------------------------\n",
    "    # labels\n",
    "    # -----------------------------------------------------------\n",
    "    def __get_exp(self, data, name):\n",
    "        reorder = lambda x: [x[1], x[0], x[2]]\n",
    "        convert_to_arr = lambda d: [[reorder(x.split()), idx] for idx, arr in enumerate(d.split(' ; ')) for x in eval(arr) if x is not None]\n",
    "        return data[name]['incremental'].map(convert_to_arr)\n",
    "\n",
    "    def __process_num(self, num, idx, literals, pnum, prev_eq):\n",
    "        if num in const2val:\n",
    "            temp = np.where((literals[idx==pnum]==num))[0]\n",
    "            if len(temp) > 0:\n",
    "                return temp[0]\n",
    "            else: # The constant predictor failed to predict the correct constants for this specific problem\n",
    "                return None\n",
    "        elif 'x' in num:\n",
    "            return prev_eq[int(num[1:])-1]\n",
    "        else:\n",
    "            return np.where((literals[idx==pnum]==str(float(num))))[0][0]\n",
    "        \n",
    "    def __process_exp(self, idx, literals, exp, pnum):\n",
    "        op_labels = None\n",
    "        prev_eq = []\n",
    "        num1_labels = []\n",
    "        num2_labels = []\n",
    "        layer_idx = []\n",
    "        for (op, num1, num2), layer in exp:\n",
    "            num1 = self.__process_num(num1, idx, literals, pnum, prev_eq)\n",
    "            num2 = self.__process_num(num2, idx, literals, pnum, prev_eq)\n",
    "            op = op2id[op]\n",
    "\n",
    "            layer_idx.append(layer)\n",
    "            num1_labels.append(num1)\n",
    "            num2_labels.append(num2)\n",
    "            prev_eq.append((op,num1,num2))\n",
    "\n",
    "            temp = torch.zeros(len(op2id))\n",
    "            temp[op] = 1\n",
    "            op_labels = self.__expand_tensor(op_labels,temp[None,:])\n",
    "            \n",
    "        return op_labels, np.array(num1_labels, dtype=object), np.array(num2_labels, dtype=object), np.array(layer_idx)\n",
    "    \n",
    "    def __get_labels(self, data, name):\n",
    "        results = []\n",
    "        for i,e in enumerate(self.__get_exp(data, name)):\n",
    "            results.append(self.__process_exp(self.combined[name]['idx'], self.combined[name]['literals'], e, i))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f8a06fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathQA(Dataset):\n",
    "    def __init__(self, config, name):\n",
    "        self.input_ids = config.tokenized[name]['input_ids']\n",
    "        self.attention_mask = config.tokenized[name]['attention_mask']\n",
    "        self.const_embed = config.const[name]['embed']\n",
    "        self.embed_idx = torch.tensor(config.const[name]['embed_idx']).int()\n",
    "        self.idx = config.combined[name]['idx'].int()\n",
    "        self.const_idx = config.const[name]['idx'].int()\n",
    "        self.true_labels = config.labels[name]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        if i.step: # using step is not defined\n",
    "            raise NotImplementedError\n",
    "            \n",
    "        input_ids = self.input_ids[i]\n",
    "        attention_mask = self.attention_mask[i]\n",
    "        true_labels = self.true_labels[i]\n",
    "        \n",
    "        if isinstance(i, slice):\n",
    "            const_embed = self.const_embed[self.embed_idx[(self.const_idx>=i.start)&(self.const_idx<i.stop)]]\n",
    "            idx = self.idx[(self.idx>=i.start)&(self.idx<i.stop)]\n",
    "        else:\n",
    "            const_embed = self.const_embed[self.embed_idx[self.const_idx==i]]\n",
    "            idx = self.idx[self.idx==i]\n",
    "        return input_ids, attention_mask, const_embed, idx, true_labels\n",
    "    \n",
    "class DataLoader:\n",
    "    def __init__(self, dataset, batch_size, shuffle):\n",
    "        self.curr = 0\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.slices = [slice(x,x+batch_size) for x in range(0,len(dataset),batch_size)]\n",
    "        self.num_batches = len(self.slices)\n",
    "        \n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.slices)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.num_batches\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):        \n",
    "        if self.curr < self.num_batches:\n",
    "            input_ids, attention_mask, const_embed, idx, true_labels = self.dataset[self.slices[self.curr]]\n",
    "            self.curr += 1\n",
    "            return input_ids, attention_mask, const_embed, idx%self.batch_size, true_labels\n",
    "        raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7bf9706",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.device = config.device\n",
    "        self.mask_id = config.tokenizer.encode(NUM_MASK, add_special_tokens=False)[0]\n",
    "        self.encoder = config.encoder.to(config.device)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, const_embed):\n",
    "        input_ids = input_ids.to(self.device)\n",
    "        attention_mask = attention_mask.to(self.device)\n",
    "        const_embed = const_embed.to(self.device)\n",
    "        \n",
    "        # Getting the hidden output\n",
    "        x = self.encoder(input_ids, attention_mask).last_hidden_state\n",
    "        \n",
    "        # Combining constants and numbers\n",
    "        embed = torch.cat((x[input_ids==self.mask_id],const_embed), dim=0)\n",
    "        \n",
    "        return x, embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "127f946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, config): \n",
    "        super(Decoder, self).__init__()\n",
    "        self.device = config.device\n",
    "        self.embedding_size = config.embedding_size\n",
    "        self.num_tokens = config.num_tokens\n",
    "        self.K = config.K\n",
    "        self.op_embed = config.op\n",
    "        \n",
    "        # standard transformer decoder\n",
    "        transformer_decoder_layer = torch.nn.TransformerDecoderLayer(self.embedding_size, nhead=config.nhead, batch_first=True)\n",
    "        self.transformer_decoder = torch.nn.TransformerDecoder(transformer_decoder_layer, num_layers=config.nlayer)\n",
    "        \n",
    "        # softmax for the operations\n",
    "        self.op_softmax = torch.nn.Softmax(dim=2)\n",
    "        \n",
    "        # softmax for the numbers\n",
    "        self.num_softmax = torch.nn.Softmax(dim=0)\n",
    "\n",
    "        # decreasing dimensionality to match embedding size: <op, num, num, num*num> = 3072 -> 768\n",
    "        self.exp_encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.embedding_size*4, self.embedding_size*2),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(self.embedding_size*2, self.embedding_size*2),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(self.embedding_size*2, self.embedding_size),\n",
    "        )\n",
    "        \n",
    "        # converting back into new <op, num, num> for loss calculation\n",
    "        self.op_decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.embedding_size, int(self.embedding_size*1.5)),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(int(self.embedding_size*1.5), int(self.embedding_size*1.5)),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(int(self.embedding_size*1.5), self.embedding_size),\n",
    "        )\n",
    "        self.num1_decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.embedding_size, int(self.embedding_size*1.5)),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(int(self.embedding_size*1.5), int(self.embedding_size*1.5)),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(int(self.embedding_size*1.5), self.embedding_size),\n",
    "        )\n",
    "        self.num2_decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.embedding_size, int(self.embedding_size*1.5)),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(int(self.embedding_size*1.5), int(self.embedding_size*1.5)),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(int(self.embedding_size*1.5), self.embedding_size),\n",
    "        )\n",
    "        \n",
    "    def __apply_to_nums(self, f, num, idx, batch_size):\n",
    "        new_nums = torch.zeros(batch_size, self.K, num.shape[0]).to(self.device)\n",
    "        for x in range(batch_size):\n",
    "            new_nums[x,:,idx==x] = f(num[idx==x]).T\n",
    "        return new_nums  \n",
    "    \n",
    "    # query: [batch_size, K, 768]\n",
    "    # prob_embed: [batch_size, num_tokens, 768]\n",
    "    # num_embed: [num_nums, 768]\n",
    "    # op_embed: [num_ops, 768]\n",
    "    def forward(self, query, prob_embed, num_embed, idx): \n",
    "        query = query.to(self.device)\n",
    "        prob_embed = prob_embed.to(self.device)\n",
    "        num_embed = num_embed.to(self.device)\n",
    "        op_embed = self.op_embed.to(self.device)\n",
    "        idx = idx.to(self.device)\n",
    "        batch_size = query.shape[0]\n",
    "        num_ops = op_embed.shape[0]\n",
    "        num_nums = num_embed.shape[0]\n",
    "\n",
    "        # ----------------------------\n",
    "        # Step 1 - transformer decoder\n",
    "        # ----------------------------\n",
    "        query = self.transformer_decoder(query, prob_embed) # [batch_size, K, 768] -> [batch_size, K, 768]\n",
    "        \n",
    "        # -------------------------------------------------------------------------------\n",
    "        # Step 2 - decoding the output into three embeddings of size 768 (op, num1, num2)\n",
    "        # -------------------------------------------------------------------------------\n",
    "#         query = self.exp_decoder(query) # [batch_size, K, 768] -> [batch_size, K, 768*3]\n",
    "#         op,num1,num2 = torch.split(query, self.embedding_size, dim=2)\n",
    "        op = self.op_decoder(query)\n",
    "        num1 = self.num1_decoder(query)\n",
    "        num2 = self.num2_decoder(query)\n",
    "        \n",
    "        # ----------------------------------------------------\n",
    "        # Step 3 - creating embedding for the found expression  \n",
    "        # ----------------------------------------------------\n",
    "        query = self.exp_encoder(torch.cat((op,num1,num2,num1*num2), dim=2)) # [batch_size, K, 3072] -> [batch_size, K, 768]\n",
    "        \n",
    "        # ------------------------------------------------------------------------------\n",
    "        # Step 4 - Taking a dot product between the predicted and stored true embeddings\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # making sure params have correct dimension\n",
    "        num_embed = num_embed[:,None,:].expand(-1,K,-1) # [num_nums, 768] -> [num_nums, K, 768]\n",
    "        op_embed = op_embed[None,None,:,:].repeat(batch_size,self.K,1,1) # [num_ops, 768] -> [batch_size, K, num_ops, 768]\n",
    "\n",
    "        # dot product - calculating the similarity between each op/num prediction and stored embeddings\n",
    "        num1 = (num1[idx]*num_embed).sum(dim=2) # [number_of_nums, K]\n",
    "        num2 = (num2[idx]*num_embed).sum(dim=2) # [number_of_nums, K]        \n",
    "        op = op[:,:,None,:].expand(-1,-1,num_ops,-1) # [batch_size, K, 768] -> # [batch_size, K, num_ops, 768]\n",
    "        op = (op*op_embed).sum(dim=3) # [batch_size, K, num_ops, 768] -> [batch_size, K, num_ops]\n",
    "        \n",
    "        # -----------------------------------------------------------------------------------------\n",
    "        # Step 5 - Finding the softmax for the similarity between the predicted and true embeddings\n",
    "        # -----------------------------------------------------------------------------------------\n",
    "        op = self.op_softmax(op) # [batch_size, K, num_ops] (ie op[1,2] would be the operator prediction probabilities for problem2, query3)\n",
    "        num1 = self.__apply_to_nums(self.num_softmax, num1, idx, batch_size) # [batch_size,K,num_nums]\n",
    "        num2 = self.__apply_to_nums(self.num_softmax, num2, idx, batch_size) # [batch_size,K,num_nums]\n",
    "        \n",
    "        return query, op, num1, num2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8b31e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    def __init__(self, config):\n",
    "        self.K = config.K\n",
    "        self.embedding_size = config.embedding_size\n",
    "        self.device = config.device\n",
    "        \n",
    "    # --------------------------------\n",
    "    # loss/accuracy calculation\n",
    "    # --------------------------------\n",
    "    def __lmatch(self, true_op, true_num1, true_num2, op, num1, num2):\n",
    "        true_op = torch.clone(true_op)\n",
    "        true_op[:,:,op2id['None']] = 0 # setting all none operators to zero so ignored during calculation\n",
    "\n",
    "        # rows: true exp, cols: pred exp (ie 0,1 would be the cost for true exp 0 with pred exp 1)\n",
    "        # [8,K*K]\n",
    "        op_mat = (true_op.repeat_interleave(K,dim=1)*op.repeat(1,K,1)).sum(dim=-1)\n",
    "        num1_mat = (true_num1.repeat_interleave(K,dim=1)*num1.repeat(1,K,1)).sum(dim=-1)\n",
    "        num2_mat = (true_num2.repeat_interleave(K,dim=1)*num2.repeat(1,K,1)).sum(dim=-1)\n",
    "\n",
    "        return -(op_mat+num1_mat+num2_mat).reshape(op_mat.shape[0],K,K)\n",
    "    \n",
    "    # consider trying to write this in pytorch if have time\n",
    "    def __hungarian_algorithm(self, true_op, true_num1, true_num2, op, num1, num2, batch_size):\n",
    "        m = self.__lmatch(true_op, true_num1, true_num2, op, num1, num2)\n",
    "        permutations = torch.stack(tuple([torch.tensor(linear_sum_assignment(m.detach().cpu().numpy()[x])[1]) for x in range(batch_size)]))\n",
    "        batch_idx = torch.arange(batch_size).unsqueeze(-1)\n",
    "        return op[batch_idx, permutations], num1[batch_idx, permutations], num2[batch_idx, permutations]\n",
    "    \n",
    "    # expects the optimal permutation from the hungarian algorithm\n",
    "    def __final_loss(self, true_op, true_num1, true_num2, op, num1, num2):        \n",
    "        log_op = torch.log((true_op*op).sum(-1))\n",
    "        \n",
    "        log_num1 = ((true_num1*num1).sum(-1))\n",
    "        log_num1[log_num1.nonzero(as_tuple=True)] = torch.log(log_num1[log_num1.nonzero(as_tuple=True)])\n",
    "        \n",
    "        log_num2 = ((true_num2*num2).sum(-1))\n",
    "        log_num2[log_num2.nonzero(as_tuple=True)] = torch.log(log_num2[log_num2.nonzero(as_tuple=True)])\n",
    " \n",
    "        return (-log_op-log_num1-log_num2).sum(-1).mean()\n",
    "\n",
    "    # expects the optimal permutation from the hungarian algorithm\n",
    "    # gets the number of correct examples for a batch\n",
    "    def __correct(self, true_op, true_num1, true_num2, op, num1, num2):\n",
    "        invalid = true_op.argmax(-1)==op2id['None']\n",
    "        op_correct = true_op.argmax(-1)==op.argmax(-1)\n",
    "        num1_correct = num1.argmax(-1)==true_num1.argmax(-1)\n",
    "        num2_correct = num2.argmax(-1)==true_num2.argmax(-1)\n",
    "        num1_correct[invalid]=True\n",
    "        num2_correct[invalid]=True\n",
    "        \n",
    "        correct = ((op_correct&num1_correct&num2_correct).sum(1)==self.K).sum()\n",
    "        num_ops = true_op.shape[0]*true_op.shape[1]\n",
    "        op_correct = op_correct.sum()\n",
    "        num_nums = len(num1_correct[~invalid])\n",
    "        num1_correct = num1_correct[~invalid].sum()\n",
    "        num2_correct = num2_correct[~invalid].sum()\n",
    "        return correct, op_correct, num_ops, num1_correct, num2_correct, num_nums\n",
    "    \n",
    "    # --------------------------------\n",
    "    # true label construction\n",
    "    # --------------------------------   \n",
    "    def __expand_tensor(self, curr, new):\n",
    "        if curr is None:\n",
    "            curr = new\n",
    "        else:\n",
    "            curr =  torch.cat((curr,new), dim=0)\n",
    "        return curr\n",
    "\n",
    "    def __prepare_labels(self, curr_layer, found_nums_idx, pnum, true_labels, num_nums):\n",
    "        true_op, true_num1, true_num2, layer_idx = true_labels[pnum]\n",
    "\n",
    "        # Creating num1 labels [batch_size, K, num_nums]\n",
    "        num1_indices = [found_nums_idx[pnum][x] for x in true_num1[layer_idx==curr_layer] if x in found_nums_idx[pnum]]          \n",
    "        num1_labels = torch.zeros(len(num1_indices), num_nums)\n",
    "        num1_labels[torch.arange(len(num1_indices)),num1_indices]=1\n",
    "        num1_labels = torch.cat((num1_labels, torch.zeros(num_nums)[None,:].repeat(self.K-len(num1_indices),1)), dim=0) \n",
    "\n",
    "        # Creating num2 labels [batch_size, K, num_nums]\n",
    "        num2_indices = [found_nums_idx[pnum][x] for x in true_num2[layer_idx==curr_layer] if x in found_nums_idx[pnum]]\n",
    "        num2_labels = torch.zeros(len(num2_indices), num_nums)\n",
    "        num2_labels[torch.arange(len(num2_indices)),num2_indices]=1\n",
    "        num2_labels = torch.cat((num2_labels, torch.zeros(num_nums)[None,:].repeat(self.K-len(num2_indices),1)), dim=0)\n",
    "        \n",
    "        # Creating op labels [batch_size, K, num_ops]\n",
    "        op_labels = true_op[layer_idx==curr_layer]\n",
    "        pad = torch.zeros(len(op2id))\n",
    "        pad[op2id['None']] = 1\n",
    "        op_labels = torch.cat((op_labels, pad[None,:].repeat(K-len(op_labels),1)), dim=0)\n",
    "\n",
    "        return op_labels.to(self.device), num1_labels.to(self.device), num2_labels.to(self.device)\n",
    "\n",
    "    def prepare_all_labels(self, curr_layer, found_nums_idx, true_labels, num_nums, batch_size):\n",
    "        true_op = None\n",
    "        true_num1 = None\n",
    "        true_num2 = None\n",
    "        # Aggregating labels\n",
    "        for pnum in range(batch_size):\n",
    "            op_labels, num1_labels, num2_labels = self.__prepare_labels(curr_layer, found_nums_idx, pnum, true_labels, num_nums)\n",
    "            true_op = self.__expand_tensor(true_op, op_labels[None,:,:])\n",
    "            true_num1 = self.__expand_tensor(true_num1, num1_labels[None,:,:])\n",
    "            true_num2 = self.__expand_tensor(true_num2, num2_labels[None,:,:])\n",
    "\n",
    "        # Randomizing equation order to help with generalization\n",
    "        batch_idx = torch.arange(batch_size).unsqueeze(-1)\n",
    "        perm = torch.rand(batch_size,K).argsort(dim=1)\n",
    "        true_op = true_op[batch_idx,perm,:]\n",
    "        true_num1 = true_num1[batch_idx,perm,:]\n",
    "        true_num2 = true_num2[batch_idx,perm,:]\n",
    "\n",
    "        return true_op, true_num1, true_num2\n",
    "    \n",
    "    # --------------------------------\n",
    "    # update for next layer\n",
    "    # --------------------------------       \n",
    "    # Given the predictions, update the running number dicts and get a new idx/embeddings list\n",
    "    def prepare_next(self, query, op, num1, num2, found_nums_list, found_nums_idx, idx, num_embed, batch_size, decoder=None):\n",
    "        new_ops = op.argmax(-1).flatten()\n",
    "        new_num1 = found_nums_list[num1.argmax(-1).cpu().flatten()]\n",
    "        new_num2 = found_nums_list[num2.argmax(-1).cpu().flatten()]\n",
    "        indices_added = []\n",
    "        new_idx = []\n",
    "        found_nums_list = deepcopy(found_nums_list)\n",
    "        found_nums_idx = deepcopy(found_nums_idx)\n",
    "\n",
    "        found_nums_list = list(found_nums_list)\n",
    "\n",
    "        # updating the number lists/embeddings/indices\n",
    "        j = 0\n",
    "        for i, new_op, new_num1, new_num2 in zip(torch.arange(batch_size).repeat_interleave(K), new_ops, new_num1, new_num2):\n",
    "            #eq = (new_op.item(), found_nums_list[new_num1], found_nums_list[new_num2])\n",
    "            eq = (new_op.item(), new_num1, new_num2)\n",
    "            i = i.item()\n",
    "            if eq not in found_nums_idx[i] and eq[0]!=op2id['None']:\n",
    "                new_idx.append(i)\n",
    "                indices_added.append(j)\n",
    "                found_nums_list.append(eq)\n",
    "                found_nums_idx[i][eq] = len(found_nums_list)-1\n",
    "            j += 1\n",
    "\n",
    "        found_nums_list = np.array(found_nums_list, dtype=object)\n",
    "        new_idx = torch.tensor(new_idx)\n",
    "\n",
    "        # Pass the decoder if in training mode so true embeddings can be calculated\n",
    "        if decoder is not None:\n",
    "            temp = [(o,found_nums_idx[pnum][x1],found_nums_idx[pnum][x2]) for pnum in range(batch_size) for o,x1,x2 in found_nums_list[-len(new_idx):][new_idx==pnum]]\n",
    "            temp = list(map(list,zip(*temp)))\n",
    "            o = decoder.op_embed[temp[0]].to(self.device)\n",
    "            x1 = num_embed[temp[1]]\n",
    "            x2 = num_embed[temp[2]]\n",
    "            new_embed = torch.cat((o,x1,x2,x1*x2), dim=-1)\n",
    "            new_embed = decoder.exp_encoder(new_embed)\n",
    "        else:\n",
    "            new_embed = query.reshape(K*batch_size,self.embedding_size)[indices_added]\n",
    "\n",
    "        # Preparing the newly added nums to be concatenated with the problem embedding\n",
    "        pad = torch.zeros(self.embedding_size)[None,:].to(self.device)\n",
    "        pad_embed = lambda x: torch.cat((x, pad.repeat(self.K-len(x),1)), dim=0)\n",
    "        to_cat = torch.stack([pad_embed(new_embed[new_idx==x]) for x in range(batch_size)])\n",
    "        \n",
    "        if decoder is not None:\n",
    "            print(found_nums_list)\n",
    "\n",
    "        return found_nums_list, found_nums_idx, torch.cat((idx,new_idx)).int(), torch.cat((num_embed,new_embed), dim=0), to_cat\n",
    "    \n",
    "    # --------------------------------\n",
    "    # main function\n",
    "    # --------------------------------  \n",
    "    def calculate(self, true_op, true_num1, true_num2, op, num1, num2, batch_size):    \n",
    "#         print('--------------------------------------------')\n",
    "#         print(true_op)\n",
    "#         print(true_num1)\n",
    "#         print(true_num2)\n",
    "#         print('--------------------------------------------')\n",
    "        op, num1, num2 = self.__hungarian_algorithm(true_op, true_num1, true_num2, op, num1, num2, batch_size) # getting optimal permutation\n",
    "        \n",
    "        loss = self.__final_loss(true_op, true_num1, true_num2, op, num1, num2)\n",
    "        correct, op_correct, num_ops, num1_correct, num2_correct, num_nums = self.__correct(true_op, true_num1, true_num2, op, num1, num2)\n",
    "        \n",
    "        return loss, correct, op_correct, num_ops, num1_correct, num2_correct, num_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a8eba6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['const_100 - 5', 'const_100 + 31.1', None, None, None, None] ; ['x2 * const_100', None, None, None, None, None] ; ['x3 / x1', None, None, None, None, None] ; ['x4 - const_100', None, None, None, None, None]\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['test']['incremental'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aad7cc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5.0', '31.1', '14.0', '1000.0', '4.0', '28.0', '26.0', '24.0',\n",
       "       'const_10', 'const_100', 'const_1', 'const_2', 'const_3',\n",
       "       'const_4', 'const_10', 'const_100', 'const_1', 'const_2',\n",
       "       'const_3', 'const_10', 'const_100', 'const_1000', 'const_neg_1',\n",
       "       'const_0_25', 'const_1', 'const_2', 'const_3', 'const_4',\n",
       "       'const_6', 'const_10', 'const_12'], dtype='<U32')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.combined['test']['literals'][config.combined['test']['idx']<4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c3e7e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array(data['validation']['incremental'].map(lambda x: x.split(' ; ')).map(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e89b195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1616"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(temp<=3).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37298484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d7c76b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstLayer(torch.nn.Module):\n",
    "    def __init__(self, config, layer):\n",
    "        super(FirstLayer, self).__init__()\n",
    "        self.device = config.device\n",
    "        self.encoder = Encoder(config).to(self.device)\n",
    "        self.decoder = Decoder(config).to(self.device)\n",
    "        self.loss = Loss(config)\n",
    "        self.query = config.query\n",
    "        self.layer = layer\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, const_embed, idx, true_labels):\n",
    "        batch_size = input_ids.shape[0]\n",
    "        \n",
    "        # encoder\n",
    "        prob_embed, num_embed = self.encoder(input_ids, attention_mask, const_embed)\n",
    "        \n",
    "        # creating initial params\n",
    "        query = self.query[None,:,:].repeat(batch_size,1,1)\n",
    "        convert_to_dict = lambda x: dict(zip(np.arange(len(x)),x))\n",
    "        temp = np.arange(len(idx))\n",
    "        found_nums_idx = [convert_to_dict(temp[idx==x]) for x in range(batch_size)]\n",
    "        found_nums_list = np.zeros(len(idx)).astype(int)\n",
    "        for i,x in enumerate(torch.bincount(idx)):\n",
    "            found_nums_list[idx==i] = np.arange(x)\n",
    "        found_nums_list = np.array(found_nums_list, dtype=object)\n",
    "                \n",
    "        # decoder        \n",
    "        query, op, num1, num2 = self.decoder(query, prob_embed, num_embed, idx)\n",
    "        \n",
    "        # loss\n",
    "        true_op, true_num1, true_num2 = self.loss.prepare_all_labels(self.layer, found_nums_idx, true_labels, num1.shape[-1], batch_size)\n",
    "        loss, correct, _, _, _, _, _ = self.loss.calculate(true_op, true_num1, true_num2, op, num1, num2, batch_size)\n",
    "        \n",
    "        # preparing for the next layer (if train mode, use the true values for teacher forcing)\n",
    "        if self.training:\n",
    "            found_nums_list, found_nums_idx, idx, num_embed, to_cat = self.loss.prepare_next(query, true_op, true_num1, \n",
    "                                                                                             true_num2, found_nums_list, \n",
    "                                                                                             found_nums_idx, idx, num_embed, \n",
    "                                                                                             batch_size, self.decoder)\n",
    "        else:\n",
    "            found_nums_list, found_nums_idx, idx, num_embed, to_cat = self.loss.prepare_next(query, op, num1, \n",
    "                                                                                             num2, found_nums_list, \n",
    "                                                                                             found_nums_idx, idx, num_embed, \n",
    "                                                                                             batch_size)\n",
    "        \n",
    "        return query, loss, correct, found_nums_list, found_nums_idx, idx, num_embed, torch.cat((prob_embed, to_cat), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc571c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(torch.nn.Module):\n",
    "    def __init__(self, config, layer):\n",
    "        super(Layer, self).__init__()\n",
    "        self.device = config.device\n",
    "        self.decoder = Decoder(config).to(self.device)\n",
    "        self.loss = Loss(config)\n",
    "        self.layer = layer\n",
    "        \n",
    "    def forward(self, query, found_nums_list, found_nums_idx, idx, num_embed, prob_embed, true_labels):\n",
    "        batch_size = query.shape[0]\n",
    "        \n",
    "        # forward pass\n",
    "        query, op, num1, num2 = self.decoder(query, prob_embed, num_embed, idx)\n",
    "        \n",
    "        # loss\n",
    "        true_op, true_num1, true_num2 = self.loss.prepare_all_labels(self.layer, found_nums_idx, true_labels, num1.shape[-1], batch_size)\n",
    "        \n",
    "        loss, correct, _, _, _, _, _ = self.loss.calculate(true_op, true_num1, true_num2, op, num1, num2, batch_size)\n",
    "        \n",
    "        # preparing for the next layer (if train mode, use the true values for teacher forcing)\n",
    "        if self.training:\n",
    "            found_nums_list, found_nums_idx, idx, num_embed, to_cat = self.loss.prepare_next(query, true_op, true_num1, \n",
    "                                                                                             true_num2, found_nums_list, \n",
    "                                                                                             found_nums_idx, idx, num_embed, \n",
    "                                                                                             batch_size, self.decoder)\n",
    "        else:\n",
    "            found_nums_list, found_nums_idx, idx, num_embed, to_cat = self.loss.prepare_next(query, op, num1, \n",
    "                                                                                             num2, found_nums_list, \n",
    "                                                                                             found_nums_idx, idx, num_embed, \n",
    "                                                                                             batch_size)\n",
    "        \n",
    "        return query, loss, correct, found_nums_list, found_nums_idx, idx, num_embed, torch.cat((prob_embed, to_cat), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6880819",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullModel(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(FullModel, self).__init__()\n",
    "        self.device = config.device\n",
    "        self.batch_size = config.batch_size\n",
    "        self.K = config.K\n",
    "        self.max_layers = config.max_layers\n",
    "        self.firstlayer = FirstLayer(config, 0).to(self.device)\n",
    "        self.layers = torch.nn.ModuleList([Layer(config, i+1).to(self.device) for i in range(config.batch_size-1)])\n",
    "        \n",
    "        # problem encoder - [batch_size,embedding_size,num_tokens+K] -> [batch_size,embedding_size,num_tokens]\n",
    "        # used for mixing in information about newly found expressions\n",
    "        self.prob_encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(config.num_tokens+self.K, config.num_tokens+int(self.K/2)),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(config.num_tokens+int(self.K/2), config.num_tokens+int(self.K/2)),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(config.num_tokens+int(self.K/2), config.num_tokens),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, const_embed, idx, true_labels):\n",
    "        total_loss = None\n",
    "        total_correct = torch.zeros(self.max_layers).int().to(self.device)\n",
    "        \n",
    "        query, loss, correct, found_nums_list, found_nums_idx, idx, num_embed, prob_embed = self.firstlayer(input_ids, attention_mask, const_embed, idx, true_labels)\n",
    "        prob_embed = self.prob_encoder(prob_embed.permute(0,2,1)).permute(0,2,1)\n",
    "        total_loss = loss\n",
    "        total_correct[0] += correct\n",
    "        \n",
    "        query, loss, correct, found_nums_list, found_nums_idx, idx, num_embed, prob_embed = self.layers[0](query, found_nums_list, found_nums_idx, idx, num_embed, prob_embed, true_labels)\n",
    "        prob_embed = self.prob_encoder(prob_embed.permute(0,2,1)).permute(0,2,1)\n",
    "        total_loss += loss\n",
    "        total_correct[1] += correct\n",
    "        \n",
    "        return found_nums_list, total_loss, total_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0bb12c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     data = util.load_data()\n",
    "#     config = Config(data, reload=False)\n",
    "#     train_dataloader = DataLoader(MathQA(config, 'train'), batch_size=config.batch_size, shuffle=False)\n",
    "#     input_ids, attention_mask, const_embed, idx, true_labels = next(iter(train_dataloader))\n",
    "#     util.set_seed(config.seed)\n",
    "#     model = FullModel(config)\n",
    "#     model.to(config.device)\n",
    "#     found_nums_list, total_loss, total_correct = model(input_ids, attention_mask, const_embed, idx, true_labels)\n",
    "# finally:\n",
    "#     #del model\n",
    "#     torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dafdc2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, config):\n",
    "        self.device = config.device\n",
    "        self.model = FullModel(config).to(self.device)\n",
    "        self.grad_norm_clip = config.grad_norm_clip\n",
    "        self.batch_size = config.batch_size\n",
    "        self.max_layers = config.max_layers\n",
    "        \n",
    "        self.opt = config.opt(self.model.parameters(), lr=config.lr)\n",
    "        \n",
    "    def __backpropagate(self, loss):\n",
    "        self.opt.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.grad_norm_clip)\n",
    "        self.opt.step()\n",
    "        \n",
    "    def train(self, dataloader, epoch, num_batches=None, path=None):\n",
    "        total_loss = 0\n",
    "        total_batches = num_batches if num_batches else len(dataloader)\n",
    "        total_correct = torch.zeros(self.max_layers).int()\n",
    "        total_examples = 0\n",
    "        self.model.train(True) # setting to train mode\n",
    "        with tqdm(dataloader, total=total_batches) as progress_bar:\n",
    "            for item in progress_bar:\n",
    "                progress_bar.set_description(f'Epoch {epoch}')\n",
    "                input_ids, attention_mask, const_embed, idx, true_labels = item\n",
    "                \n",
    "                # forward pass\n",
    "                found_nums_list, loss, correct = self.model(input_ids, attention_mask, const_embed, idx, true_labels)\n",
    "                \n",
    "                # backpropagating the loss\n",
    "                self.__backpropagate(loss)\n",
    "                \n",
    "                total_loss += loss.detach().item()\n",
    "                total_correct += correct.detach().cpu()\n",
    "                total_examples += self.batch_size\n",
    "                \n",
    "                progress_bar.set_postfix(loss=loss.detach().item())                \n",
    "                progress_bar.update(1)\n",
    "                \n",
    "                if num_batches:\n",
    "                    num_batches -= 1\n",
    "                if num_batches == 0:\n",
    "                    progress_bar.close()\n",
    "                    break\n",
    "        return total_loss/total_batches, total_correct/total_examples\n",
    "    \n",
    "    def val(self, dataloader, num_batches=None):\n",
    "        total_loss = 0\n",
    "        total_batches = num_batches if num_batches else len(dataloader)\n",
    "        total_correct = torch.zeros(self.max_layers).int()\n",
    "        total_examples = 0\n",
    "        self.model.eval() # setting to eval mode\n",
    "        with torch.no_grad():\n",
    "            with tqdm(dataloader, total=total_batches) as progress_bar:\n",
    "                for item in progress_bar:\n",
    "                    progress_bar.set_description(f'Validation')\n",
    "                    input_ids, attention_mask, const_embed, idx, true_labels = item\n",
    "\n",
    "                    # forward pass\n",
    "                    query, loss, correct = self.model(input_ids, attention_mask, const_embed, idx, true_labels)\n",
    "\n",
    "                    total_loss += loss.detach().item()\n",
    "                    total_correct += correct.detach().cpu()\n",
    "                    total_examples += self.batch_size\n",
    "           \n",
    "                    progress_bar.update(1)\n",
    "\n",
    "                    if num_batches:\n",
    "                        num_batches -= 1\n",
    "                    if num_batches == 0:\n",
    "                        progress_bar.close()\n",
    "                        break\n",
    "        return total_loss/total_batches, total_correct/total_examples\n",
    "            \n",
    "    def fit(self, epochs, num_batches=None):\n",
    "        for epoch in range(epochs):\n",
    "            train_dataloader = DataLoader(MathQA(config, 'test'), batch_size=config.batch_size, shuffle=False)\n",
    "            val_dataloader = DataLoader(MathQA(config, 'test'), batch_size=config.batch_size, shuffle=False)\n",
    "            train_loss, train_acc = self.train(train_dataloader, epoch+1, num_batches)\n",
    "            val_loss, val_acc = self.val(val_dataloader, num_batches)\n",
    "            \n",
    "            train_metrics = [train_loss]\n",
    "            train_metrics.extend([acc for acc in train_acc.numpy()])\n",
    "            val_metrics = [val_loss]\n",
    "            val_metrics.extend([acc for acc in val_acc.numpy()])\n",
    "            index = ['Loss']\n",
    "            index.extend([f'Layer {x+1} Accuracy' for x in range(len(train_acc))])\n",
    "            \n",
    "            df = pd.DataFrame({'Train':train_metrics, 'Validation':val_metrics}, index = index)\n",
    "            \n",
    "            display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27deffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \n",
    "    def __init__(self, data, reload=False):\n",
    "        self.device = torch.device('cuda:0')\n",
    "        self.model_name = r'D:\\jupyter_notebooks\\Mathsage\\Connor\\models\\distilroberta-base-encoder-mathqa'\n",
    "        self.tokenizer_name = 'distilroberta-base'\n",
    "        self.seed = 3\n",
    "        self.batch_size = 4\n",
    "        \n",
    "        # model params\n",
    "        self.K = 6\n",
    "        self.max_layers = 8\n",
    "        self.nhead = 6\n",
    "        self.nlayer = 6\n",
    "        self.embedding_size = 768\n",
    "        self.num_tokens = 392\n",
    "        \n",
    "        # training params\n",
    "        self.lr = 1e-5\n",
    "        self.opt = torch.optim.AdamW\n",
    "        self.grad_norm_clip = 1.0\n",
    "        \n",
    "        # Loading preprocessed data\n",
    "        if reload:\n",
    "            p = Preprocess(data, self.K, self.embedding_size, self.num_tokens, self.model_name, self.tokenizer_name)\n",
    "            util.save_obj(f'{OBJ_DIR}preprocess.pickle', p)\n",
    "        else:\n",
    "            p = util.load_obj(f'{OBJ_DIR}preprocess.pickle')\n",
    "                \n",
    "        self.num = p.num\n",
    "        self.const = p.const\n",
    "        self.combined = p.combined\n",
    "        self.query = p.query\n",
    "        self.op = p.op\n",
    "        self.text = p.text\n",
    "        self.labels = p.labels\n",
    "        self.encoder = p.encoder\n",
    "        self.tokenizer = p.tokenizer\n",
    "        self.tokenized = p.tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4586c061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config.labels['train'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12007fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['test']['incremental'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb9e89c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dfcce28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e3afefa46bf41208781b79b308612fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 2 0 0 1 2 3 3 4 5 6 7 8 1 2 3 4 5 6 2 3 4 5 6 7 8 9 10 (0, 3, 1)\n",
      " (1, 3, 0) (3, 0, 8) (0, 0, 1) (2, 2, 0)]\n",
      "[0 1 0 1 2 0 0 1 2 3 3 4 5 6 7 8 1 2 3 4 5 6 2 3 4 5 6 7 8 9 10 (0, 3, 1)\n",
      " (1, 3, 0) (3, 0, 8) (0, 0, 1) (2, 2, 0) (2, (0, 3, 1), 3)\n",
      " (2, 1, (3, 0, 8)) (0, (3, 0, 8), 3) (0, (0, 0, 1), 1) (0, (2, 2, 0), 4)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c930ac0a9ebb46baae425e2936268f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loss</th>\n",
       "      <td>37.479973</td>\n",
       "      <td>14.423472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 1 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 2 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 3 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 4 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 5 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 6 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 7 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 8 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Train  Validation\n",
       "Loss              37.479973   14.423472\n",
       "Layer 1 Accuracy   0.000000    0.000000\n",
       "Layer 2 Accuracy   0.000000    0.000000\n",
       "Layer 3 Accuracy   0.000000    0.000000\n",
       "Layer 4 Accuracy   0.000000    0.000000\n",
       "Layer 5 Accuracy   0.000000    0.000000\n",
       "Layer 6 Accuracy   0.000000    0.000000\n",
       "Layer 7 Accuracy   0.000000    0.000000\n",
       "Layer 8 Accuracy   0.000000    0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d32f0ff641e44a1a9da6988c4d25bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 2 0 0 1 2 3 3 4 5 6 7 8 1 2 3 4 5 6 2 3 4 5 6 7 8 9 10 (0, 3, 1)\n",
      " (1, 3, 0) (3, 0, 8) (0, 0, 1) (2, 2, 0)]\n",
      "[0 1 0 1 2 0 0 1 2 3 3 4 5 6 7 8 1 2 3 4 5 6 2 3 4 5 6 7 8 9 10 (0, 3, 1)\n",
      " (1, 3, 0) (3, 0, 8) (0, 0, 1) (2, 2, 0) (2, (0, 3, 1), 3)\n",
      " (2, 1, (3, 0, 8)) (0, (3, 0, 8), 3) (0, (0, 0, 1), 1) (0, (2, 2, 0), 4)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc594f546d9412984625a3d7641ec8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loss</th>\n",
       "      <td>17.614445</td>\n",
       "      <td>13.864141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 1 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 2 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 3 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 4 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 5 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 6 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 7 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 8 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Train  Validation\n",
       "Loss              17.614445   13.864141\n",
       "Layer 1 Accuracy   0.000000    0.000000\n",
       "Layer 2 Accuracy   0.000000    0.000000\n",
       "Layer 3 Accuracy   0.000000    0.000000\n",
       "Layer 4 Accuracy   0.000000    0.000000\n",
       "Layer 5 Accuracy   0.000000    0.000000\n",
       "Layer 6 Accuracy   0.000000    0.000000\n",
       "Layer 7 Accuracy   0.000000    0.000000\n",
       "Layer 8 Accuracy   0.000000    0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db54f69a11c04db38623dbea407770fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 2 0 0 1 2 3 3 4 5 6 7 8 1 2 3 4 5 6 2 3 4 5 6 7 8 9 10 (0, 3, 1)\n",
      " (1, 3, 0) (3, 0, 8) (0, 0, 1) (2, 2, 0)]\n",
      "[0 1 0 1 2 0 0 1 2 3 3 4 5 6 7 8 1 2 3 4 5 6 2 3 4 5 6 7 8 9 10 (0, 3, 1)\n",
      " (1, 3, 0) (3, 0, 8) (0, 0, 1) (2, 2, 0) (2, (0, 3, 1), 3)\n",
      " (2, 1, (3, 0, 8)) (0, (3, 0, 8), 3) (0, (0, 0, 1), 1) (0, (2, 2, 0), 4)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cfd2c7c472c4b2c8815fa56e65f1ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loss</th>\n",
       "      <td>15.486795</td>\n",
       "      <td>12.273218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 1 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 2 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 3 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 4 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 5 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 6 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 7 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 8 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Train  Validation\n",
       "Loss              15.486795   12.273218\n",
       "Layer 1 Accuracy   0.000000    0.000000\n",
       "Layer 2 Accuracy   0.000000    0.000000\n",
       "Layer 3 Accuracy   0.000000    0.000000\n",
       "Layer 4 Accuracy   0.000000    0.000000\n",
       "Layer 5 Accuracy   0.000000    0.000000\n",
       "Layer 6 Accuracy   0.000000    0.000000\n",
       "Layer 7 Accuracy   0.000000    0.000000\n",
       "Layer 8 Accuracy   0.000000    0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea501bcb6a1b4bdb8e8b6505fcc9255f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 2 0 0 1 2 3 3 4 5 6 7 8 1 2 3 4 5 6 2 3 4 5 6 7 8 9 10 (1, 3, 0)\n",
      " (0, 3, 1) (3, 0, 8) (0, 0, 1) (2, 2, 0)]\n",
      "[0 1 0 1 2 0 0 1 2 3 3 4 5 6 7 8 1 2 3 4 5 6 2 3 4 5 6 7 8 9 10 (1, 3, 0)\n",
      " (0, 3, 1) (3, 0, 8) (0, 0, 1) (2, 2, 0) (2, (0, 3, 1), 3)\n",
      " (0, (3, 0, 8), 3) (2, 1, (3, 0, 8)) (0, (0, 0, 1), 1) (0, (2, 2, 0), 4)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76e4c39da9e4e9489af733315c65c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loss</th>\n",
       "      <td>13.388052</td>\n",
       "      <td>10.754713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 1 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 2 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 3 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 4 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 5 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 6 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 7 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 8 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Train  Validation\n",
       "Loss              13.388052   10.754713\n",
       "Layer 1 Accuracy   0.000000    0.000000\n",
       "Layer 2 Accuracy   0.000000    0.000000\n",
       "Layer 3 Accuracy   0.000000    0.000000\n",
       "Layer 4 Accuracy   0.000000    0.000000\n",
       "Layer 5 Accuracy   0.000000    0.000000\n",
       "Layer 6 Accuracy   0.000000    0.000000\n",
       "Layer 7 Accuracy   0.000000    0.000000\n",
       "Layer 8 Accuracy   0.000000    0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e01b156d004ffe91b39c527dafb941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 2 0 0 1 2 3 3 4 5 6 7 8 1 2 3 4 5 6 2 3 4 5 6 7 8 9 10 (1, 3, 0)\n",
      " (0, 3, 1) (3, 0, 8) (0, 0, 1) (2, 2, 0)]\n",
      "[0 1 0 1 2 0 0 1 2 3 3 4 5 6 7 8 1 2 3 4 5 6 2 3 4 5 6 7 8 9 10 (1, 3, 0)\n",
      " (0, 3, 1) (3, 0, 8) (0, 0, 1) (2, 2, 0) (2, (0, 3, 1), 3)\n",
      " (0, (3, 0, 8), 3) (2, 1, (3, 0, 8)) (0, (0, 0, 1), 1) (0, (2, 2, 0), 4)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f5b290d6194ae792b09e4e85c71106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loss</th>\n",
       "      <td>12.492888</td>\n",
       "      <td>10.181341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 1 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 2 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 3 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 4 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 5 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 6 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 7 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 8 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Train  Validation\n",
       "Loss              12.492888   10.181341\n",
       "Layer 1 Accuracy   0.000000    0.000000\n",
       "Layer 2 Accuracy   0.000000    0.000000\n",
       "Layer 3 Accuracy   0.000000    0.000000\n",
       "Layer 4 Accuracy   0.000000    0.000000\n",
       "Layer 5 Accuracy   0.000000    0.000000\n",
       "Layer 6 Accuracy   0.000000    0.000000\n",
       "Layer 7 Accuracy   0.000000    0.000000\n",
       "Layer 8 Accuracy   0.000000    0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e90ce0c8ea4cf4a2774ebc5bbc55c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 2 0 0 1 2 3 3 4 5 6 7 8 1 2 3 4 5 6 2 3 4 5 6 7 8 9 10 (1, 3, 0)\n",
      " (0, 3, 1) (3, 0, 8) (0, 0, 1) (2, 2, 0)]\n",
      "[0 1 0 1 2 0 0 1 2 3 3 4 5 6 7 8 1 2 3 4 5 6 2 3 4 5 6 7 8 9 10 (1, 3, 0)\n",
      " (0, 3, 1) (3, 0, 8) (0, 0, 1) (2, 2, 0) (2, (0, 3, 1), 3)\n",
      " (2, 1, (3, 0, 8)) (0, (3, 0, 8), 3) (0, (0, 0, 1), 1) (0, (2, 2, 0), 4)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97a516eccb04f11b1ccd826f083b664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loss</th>\n",
       "      <td>12.22501</td>\n",
       "      <td>9.416731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 1 Accuracy</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 2 Accuracy</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 3 Accuracy</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 4 Accuracy</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 5 Accuracy</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 6 Accuracy</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 7 Accuracy</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 8 Accuracy</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Train  Validation\n",
       "Loss              12.22501    9.416731\n",
       "Layer 1 Accuracy   0.00000    0.000000\n",
       "Layer 2 Accuracy   0.00000    0.000000\n",
       "Layer 3 Accuracy   0.00000    0.000000\n",
       "Layer 4 Accuracy   0.00000    0.000000\n",
       "Layer 5 Accuracy   0.00000    0.000000\n",
       "Layer 6 Accuracy   0.00000    0.000000\n",
       "Layer 7 Accuracy   0.00000    0.000000\n",
       "Layer 8 Accuracy   0.00000    0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "565a291346404a69955d60e41603486d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 2 0 0 1 2 3 3 4 5 6 7 8 1 2 3 4 5 6 2 3 4 5 6 7 8 9 10 (0, 3, 1)\n",
      " (1, 3, 0) (3, 0, 8) (0, 0, 1) (2, 2, 0)]\n",
      "[0 1 0 1 2 0 0 1 2 3 3 4 5 6 7 8 1 2 3 4 5 6 2 3 4 5 6 7 8 9 10 (0, 3, 1)\n",
      " (1, 3, 0) (3, 0, 8) (0, 0, 1) (2, 2, 0) (2, (0, 3, 1), 3)\n",
      " (0, (3, 0, 8), 3) (2, 1, (3, 0, 8)) (0, (0, 0, 1), 1) (0, (2, 2, 0), 4)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4050a3e377ab41f7b9dcf4043f9c84bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loss</th>\n",
       "      <td>11.082148</td>\n",
       "      <td>9.079498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 1 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 2 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 3 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 4 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 5 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 6 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 7 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 8 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Train  Validation\n",
       "Loss              11.082148    9.079498\n",
       "Layer 1 Accuracy   0.000000    0.000000\n",
       "Layer 2 Accuracy   0.000000    0.000000\n",
       "Layer 3 Accuracy   0.000000    0.000000\n",
       "Layer 4 Accuracy   0.000000    0.000000\n",
       "Layer 5 Accuracy   0.000000    0.000000\n",
       "Layer 6 Accuracy   0.000000    0.000000\n",
       "Layer 7 Accuracy   0.000000    0.000000\n",
       "Layer 8 Accuracy   0.000000    0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99106a1d189c4f0c9cf8955340ab7641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 2 0 0 1 2 3 3 4 5 6 7 8 1 2 3 4 5 6 2 3 4 5 6 7 8 9 10 (1, 3, 0)\n",
      " (0, 3, 1) (3, 0, 8) (0, 0, 1) (2, 2, 0)]\n",
      "[0 1 0 1 2 0 0 1 2 3 3 4 5 6 7 8 1 2 3 4 5 6 2 3 4 5 6 7 8 9 10 (1, 3, 0)\n",
      " (0, 3, 1) (3, 0, 8) (0, 0, 1) (2, 2, 0) (2, (0, 3, 1), 3)\n",
      " (2, 1, (3, 0, 8)) (0, (3, 0, 8), 3) (0, (0, 0, 1), 1) (0, (2, 2, 0), 4)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d996c70ff444f37b43d8145aa39a165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loss</th>\n",
       "      <td>10.555177</td>\n",
       "      <td>8.65107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 1 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 2 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 3 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 4 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 5 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 6 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 7 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 8 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Train  Validation\n",
       "Loss              10.555177     8.65107\n",
       "Layer 1 Accuracy   0.000000     0.00000\n",
       "Layer 2 Accuracy   0.000000     0.00000\n",
       "Layer 3 Accuracy   0.000000     0.00000\n",
       "Layer 4 Accuracy   0.000000     0.00000\n",
       "Layer 5 Accuracy   0.000000     0.00000\n",
       "Layer 6 Accuracy   0.000000     0.00000\n",
       "Layer 7 Accuracy   0.000000     0.00000\n",
       "Layer 8 Accuracy   0.000000     0.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd119f29f2e493699bc7ff5cbe61ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 2 0 0 1 2 3 3 4 5 6 7 8 1 2 3 4 5 6 2 3 4 5 6 7 8 9 10 (1, 3, 0)\n",
      " (0, 3, 1) (3, 0, 8) (0, 0, 1) (2, 2, 0)]\n",
      "[0 1 0 1 2 0 0 1 2 3 3 4 5 6 7 8 1 2 3 4 5 6 2 3 4 5 6 7 8 9 10 (1, 3, 0)\n",
      " (0, 3, 1) (3, 0, 8) (0, 0, 1) (2, 2, 0) (2, (0, 3, 1), 3)\n",
      " (0, (3, 0, 8), 3) (2, 1, (3, 0, 8)) (0, (0, 0, 1), 1) (0, (2, 2, 0), 4)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd641148966c4967968d711b9a753ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loss</th>\n",
       "      <td>9.779472</td>\n",
       "      <td>8.317472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 1 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 2 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 3 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 4 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 5 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 6 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 7 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 8 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Train  Validation\n",
       "Loss              9.779472    8.317472\n",
       "Layer 1 Accuracy  0.000000    0.000000\n",
       "Layer 2 Accuracy  0.000000    0.000000\n",
       "Layer 3 Accuracy  0.000000    0.000000\n",
       "Layer 4 Accuracy  0.000000    0.000000\n",
       "Layer 5 Accuracy  0.000000    0.000000\n",
       "Layer 6 Accuracy  0.000000    0.000000\n",
       "Layer 7 Accuracy  0.000000    0.000000\n",
       "Layer 8 Accuracy  0.000000    0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4e5825f728472d92c7923d9b4b80a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 2 0 0 1 2 3 3 4 5 6 7 8 1 2 3 4 5 6 2 3 4 5 6 7 8 9 10 (0, 3, 1)\n",
      " (1, 3, 0) (3, 0, 8) (0, 0, 1) (2, 2, 0)]\n",
      "[0 1 0 1 2 0 0 1 2 3 3 4 5 6 7 8 1 2 3 4 5 6 2 3 4 5 6 7 8 9 10 (0, 3, 1)\n",
      " (1, 3, 0) (3, 0, 8) (0, 0, 1) (2, 2, 0) (2, (0, 3, 1), 3)\n",
      " (0, (3, 0, 8), 3) (2, 1, (3, 0, 8)) (0, (0, 0, 1), 1) (0, (2, 2, 0), 4)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b229edd6d14f9c84c5d343de7a03c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loss</th>\n",
       "      <td>10.034519</td>\n",
       "      <td>8.055159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 1 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 2 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 3 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 4 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 5 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 6 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 7 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer 8 Accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Train  Validation\n",
       "Loss              10.034519    8.055159\n",
       "Layer 1 Accuracy   0.000000    0.250000\n",
       "Layer 2 Accuracy   0.000000    0.000000\n",
       "Layer 3 Accuracy   0.000000    0.000000\n",
       "Layer 4 Accuracy   0.000000    0.000000\n",
       "Layer 5 Accuracy   0.000000    0.000000\n",
       "Layer 6 Accuracy   0.000000    0.000000\n",
       "Layer 7 Accuracy   0.000000    0.000000\n",
       "Layer 8 Accuracy   0.000000    0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    data = util.load_data()\n",
    "    config = Config(data, reload=False)\n",
    "    util.set_seed(config.seed)\n",
    "    trainer = Trainer(config)\n",
    "    trainer.fit(epochs = 10, num_batches=1)\n",
    "finally:\n",
    "    #del model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a11c992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5.0', '31.1', '14.0', '1000.0', '4.0', '28.0', '26.0', '24.0',\n",
       "       'const_10', 'const_100', 'const_1', 'const_2', 'const_3',\n",
       "       'const_4', 'const_10', 'const_100', 'const_1', 'const_2',\n",
       "       'const_3', 'const_10', 'const_100', 'const_1000', 'const_neg_1',\n",
       "       'const_0_25', 'const_1', 'const_2', 'const_3', 'const_4',\n",
       "       'const_6', 'const_10', 'const_12'], dtype='<U32')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.combined['test']['literals'][config.combined['test']['idx']<4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7daf7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.]]),\n",
       " array([3, 3, (0, 3, 1), (2, (0, 3, 1), 3),\n",
       "        (3, (2, (0, 3, 1), 3), (1, 3, 0))], dtype=object),\n",
       " array([0, 1, 3, (1, 3, 0), 3], dtype=object),\n",
       " array([0, 0, 1, 2, 3]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.labels['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e48c410e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.]]),\n",
       " array([0, 1, (3, 0, 8), (2, 1, (3, 0, 8)), (0, (3, 0, 8), 3), 1,\n",
       "        (2, 1, (4, (0, (3, 0, 8), 3), 2)),\n",
       "        (1, (2, 1, (4, (0, (3, 0, 8), 3), 2)), 1)], dtype=object),\n",
       " array([8, (3, 0, 8), 3, 2, 2, (4, (0, (3, 0, 8), 3), 2), 1,\n",
       "        (2, (2, 1, (3, 0, 8)), 2)], dtype=object),\n",
       " array([0, 1, 1, 2, 2, 3, 4, 5]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.labels['test'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d43fac5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.]]),\n",
       " array([0, (0, 0, 1), (0, 0, 1)], dtype=object),\n",
       " array([1, 1, (0, (0, 0, 1), 1)], dtype=object),\n",
       " array([0, 1, 2]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.labels['test'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62f542f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0.]]),\n",
       " array([2, (2, 2, 0), (0, (2, 2, 0), 4), (0, (2, 2, 0), 4)], dtype=object),\n",
       " array([0, 4, 4, (0, (0, (2, 2, 0), 4), 4)], dtype=object),\n",
       " array([0, 1, 2, 3]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.labels['test'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ba4206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
