{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1047759",
   "metadata": {},
   "source": [
    "# MathQA Operator Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5182770c",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2632faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, TrainingArguments, Trainer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from datasets import Dataset\n",
    "import warnings\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3631fc21",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82b358f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_MODE = False # Set this to false to switch this into load and evaluate mode\n",
    "DATA_PATH = './dataset/'\n",
    "SET_NAMES = ['train', 'validation', 'test']\n",
    "MODEL_TYPE = 'distilroberta-base' # A more optimized version of roberta obtaining 95% of its performance\n",
    "MAX_LENGTH = 392\n",
    "NUM_MASK = '<num>'\n",
    "WORKING_DIR = 'TEMP/'\n",
    "FINAL_DIR = 'pickle/'\n",
    "\n",
    "class Op(Enum):\n",
    "    ADD = '+'\n",
    "    SUB = '-'\n",
    "    MULT = '*'\n",
    "    DIV = '/'\n",
    "    POW = '^'\n",
    "    \n",
    "class Const(Enum):\n",
    "    CONST_NEG_1 = 'const_neg_1' # I added this\n",
    "    CONST_0_25 = 'const_0_25'\n",
    "    CONST_0_2778 = 'const_0_2778'\n",
    "    CONST_0_33 = 'const_0_33'\n",
    "    CONST_0_3937 = 'const_0_3937'\n",
    "    CONST_1 = 'const_1'\n",
    "    CONST_1_6 = 'const_1_6'\n",
    "    CONST_2 = 'const_2'\n",
    "    CONST_3 = 'const_3'\n",
    "    CONST_PI = 'const_pi'\n",
    "    CONST_3_6 = 'const_3_6'\n",
    "    CONST_4 = 'const_4'\n",
    "    CONST_5 = 'const_5'\n",
    "    CONST_6 = 'const_6'\n",
    "    CONST_10 = 'const_10'\n",
    "    CONST_12 = 'const_12'\n",
    "    CONST_26 = 'const_26'\n",
    "    CONST_52 = 'const_52'\n",
    "    CONST_60 = 'const_60'\n",
    "    CONST_100 = 'const_100'\n",
    "    CONST_180 = 'const_180'\n",
    "    CONST_360 = 'const_360'\n",
    "    CONST_1000 = 'const_1000'\n",
    "    CONST_3600 = 'const_3600'\n",
    "\n",
    "values = [-1, 0.25, 0.2778, 0.33, 0.3937, 1, 1.6, 2, 3, math.pi, 3.6, 4, 5, 6, 10, 12, 26, 52, 60, 100, 180, 360, 1000, 3600]\n",
    "const2val = {k:v for k,v in zip(Const._value2member_map_.keys(), values)}    \n",
    "\n",
    "op2id = {k:v for k,v in zip(Op._value2member_map_.keys(), range(len(Op._value2member_map_)))}\n",
    "const2id = {k:v for k,v in zip(Const._value2member_map_.keys(), range(len(Const._value2member_map_)))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1fe709",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20608f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {name:pd.read_csv(f'{DATA_PATH}{name}.csv') for name in SET_NAMES}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49da40c3",
   "metadata": {},
   "source": [
    "This function converts all of the operators used in a problem to a single one hot encoded vector used for multi class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ae38732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_op(data):\n",
    "    labels = []\n",
    "    for op_set in data.ops:\n",
    "        op_set = eval(op_set)\n",
    "        idx = [op2id[op] for op in op_set]\n",
    "        onehot = np.zeros(len(op2id))\n",
    "        onehot[idx] = 1\n",
    "        labels.append(onehot)\n",
    "    return np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ed725",
   "metadata": {},
   "source": [
    "Getting only the necessary columns from the data (text/label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "334ed246",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {name:Dataset.from_dict({'text':data[name]['problem'], 'labels':onehot_op(data[name])}) for name in SET_NAMES}\n",
    "data['train'].set_format('torch')\n",
    "data['validation'].set_format('torch')\n",
    "data['test'].set_format('torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdf26fb",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25325da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f35163de84964c8eacc7c0ea77103f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18215 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c0bca58f644317b2c8eb3b4b75849c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2710 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a09134b38b44a98ba64094b73e6b99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1798 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_TYPE)\n",
    "\n",
    "def tokenization(items):\n",
    "    return tokenizer(items['text'], padding='max_length', max_length=MAX_LENGTH, truncation=True)\n",
    "\n",
    "encoded = {k:v.map(tokenization, batched=True, remove_columns=['text']) for k,v in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "846bd58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 8\n",
    "model_path = f'models/{MODEL_TYPE}-op_classifier-mathqa'\n",
    "if TRAINING_MODE:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_TYPE, \n",
    "                                                               problem_type = 'multi_label_classification', \n",
    "                                                               num_labels = len(op2id))\n",
    "else:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path, \n",
    "                                                               problem_type = 'multi_label_classification', \n",
    "                                                               num_labels = len(op2id))\n",
    "    \n",
    "def get_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        'micro-f1': f1_score(y_true=y_true, y_pred=y_pred, average='micro'), \n",
    "        'macro-f1': f1_score(y_true=y_true, y_pred=y_pred, average='macro'),\n",
    "        'weighted-f1': f1_score(y_true=y_true, y_pred=y_pred, average='weighted'),\n",
    "        'accuracy': accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    }\n",
    "\n",
    "def compute_metrics_helper(p, label, thresh=0.5):\n",
    "    # Converting all values in the vector to be between 0 and 1\n",
    "    # The reason why softmax is not used is because we are doing multi label classification, meaning the total sum may be above 1\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    prob = sigmoid(torch.Tensor(p))\n",
    "    \n",
    "    # Converting items above the threshold to integers\n",
    "    y_pred = np.zeros(prob.shape)\n",
    "    y_pred[np.where(prob >= thresh)] = 1\n",
    "    \n",
    "    # Computing the metrics (f1, accuracy)\n",
    "    return get_metrics(label, y_pred)\n",
    "\n",
    "def compute_metrics(p):\n",
    "    return compute_metrics_helper(p.predictions, p.label_ids)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir = f'{WORKING_DIR}{model_path}',\n",
    "    evaluation_strategy = 'epoch',\n",
    "    per_device_train_batch_size = batch,\n",
    "    per_device_eval_batch_size = batch,\n",
    "    num_train_epochs = 5,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset = encoded['train'],\n",
    "    eval_dataset = encoded['validation'],\n",
    "    compute_metrics = compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1718a232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TRAINING_MODE:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        trainer.train()\n",
    "        trainer.save_model(model_path)\n",
    "else:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        predictions = {name:trainer.predict(encoded[name]) for name in SET_NAMES}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf131a4a",
   "metadata": {},
   "source": [
    "## Analysis and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83906ac4",
   "metadata": {},
   "source": [
    "As we can see, f1 scores are above 90% and accuracy lies in the mid 80s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efd4a05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: \n",
      "{'micro-f1': 0.9878143473894543, 'macro-f1': 0.9834399883952448, 'weighted-f1': 0.9878178142459981, 'accuracy': 0.9497666758166347}\n",
      "\n",
      "VALIDATION: \n",
      "{'micro-f1': 0.946394786630229, 'macro-f1': 0.9329214387304215, 'weighted-f1': 0.9464146740484812, 'accuracy': 0.8361623616236162}\n",
      "\n",
      "TEST: \n",
      "{'micro-f1': 0.9498525073746312, 'macro-f1': 0.9313226983129687, 'weighted-f1': 0.9498498023679985, 'accuracy': 0.842602892102336}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not TRAINING_MODE:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        for name in SET_NAMES:\n",
    "            print(f\"{name.upper()}: \")\n",
    "            print(compute_metrics_helper(predictions[name].predictions, predictions[name].label_ids))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44189b33",
   "metadata": {},
   "source": [
    "Similar to with the constants, we are much more concerened with recall than precision, so we test that below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49c64524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_without_missed_const(p, label, thresh=0.5):\n",
    "    # Converting all values in the vector to be between 0 and 1\n",
    "    # The reason why softmax is not used is because we are doing multi label classification, meaning the total sum may be above 1\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    prob = sigmoid(torch.Tensor(p))\n",
    "    \n",
    "    # Converting items above the threshold to integers\n",
    "    y_pred = np.zeros(prob.shape)\n",
    "    y_pred[np.where(prob >= thresh)] = 1\n",
    "    \n",
    "    y_true = label\n",
    "    \n",
    "    # if the true set is a subset of the predicted set then it did not miss any constants in the problem\n",
    "    # returns avg # constants per problem, percent without any missed\n",
    "    return np.mean(np.sum(y_pred, axis=1)), np.sum([set(np.where(true==1)[0]) <= set(np.where(pred==1)[0]) for true, pred in zip(y_true, y_pred)])/len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae96c85",
   "metadata": {},
   "source": [
    "Shown below is the percentage of problems without any missed operators along with the average number of operators predicted given different thresholds. Using a threshold of .003 on the validation set still results in over a 98% coverage, but reduces the average number of constants from 5 to 3.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35d3a8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THRESH: 0.5\n",
      "Percent without any missed: 0.9062730627306274\n",
      "Average number of constants per problem: 2.6538745387453875\n",
      "\n",
      "THRESH: 0.05\n",
      "Percent without any missed: 0.9450184501845018\n",
      "Average number of constants per problem: 2.802952029520295\n",
      "\n",
      "THRESH: 0.003\n",
      "Percent without any missed: 0.9826568265682657\n",
      "Average number of constants per problem: 3.3808118081180814\n",
      "\n",
      "THRESH: 0.001\n",
      "Percent without any missed: 0.992619926199262\n",
      "Average number of constants per problem: 4.352767527675277\n",
      "\n",
      "THRESH: 0\n",
      "Percent without any missed: 1.0\n",
      "Average number of constants per problem: 5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0.5, 0.05, 0.003, 0.001, 0]\n",
    "for thresh in thresholds:\n",
    "    print(f'THRESH: {thresh}')\n",
    "    avg_per_prob, percent_no_missed = percent_without_missed_const(predictions['validation'].predictions, predictions['validation'].label_ids, thresh)\n",
    "    print(f\"Percent without any missed: {percent_no_missed}\")\n",
    "    print(f\"Average number of operators per problem: {avg_per_prob}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d295ba25",
   "metadata": {},
   "source": [
    "Showing that this generalizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f411c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THRESH: 0.003\n",
      "Percent without any missed: 0.9816462736373749\n",
      "Average number of constants per problem: 3.360956618464961\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thresholds = [.003]\n",
    "for thresh in thresholds:\n",
    "    print(f'THRESH: {thresh}')\n",
    "    avg_per_prob, percent_no_missed = percent_without_missed_const(predictions['test'].predictions, predictions['test'].label_ids, thresh)\n",
    "    print(f\"Percent without any missed: {percent_no_missed}\")\n",
    "    print(f\"Average number of constants per problem: {avg_per_prob}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f282d581",
   "metadata": {},
   "source": [
    "## Storing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1a88f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(p, thresh=0.005):\n",
    "    # Converting all values in the vector to be between 0 and 1\n",
    "    # The reason why softmax is not used is because we are doing multi label classification, meaning the total sum may be above 1\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    prob = sigmoid(torch.Tensor(p))\n",
    "    \n",
    "    # Converting items above the threshold to integers\n",
    "    y_pred = np.zeros(prob.shape)\n",
    "    y_pred[np.where(prob >= thresh)] = 1\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "y_pred = {name:get_pred(predictions[name].predictions) for name in SET_NAMES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bfc3e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'pred': y_pred, 'map':op2id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "569230ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(FINAL_DIR):\n",
    "    os.makedirs(FINAL_DIR)\n",
    "    \n",
    "with open(f'{FINAL_DIR}ops.pickle', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d57736",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
