{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c89aba5",
   "metadata": {},
   "source": [
    "# MathQA Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cd6cad",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71dadcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pickle\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "if get_ipython().__class__.__name__ == 'ZMQInteractiveShell':\n",
    "    from tqdm.notebook import tqdm\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "import unittest\n",
    "\n",
    "# remove\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99aa0f0",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf2941c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 6\n",
    "MAX_LAYERS = 8\n",
    "MAX_TOKENS = 392\n",
    "EMBEDDING_SIZE = 768\n",
    "\n",
    "DATA_PATH = './dataset/'\n",
    "SET_NAMES = ['train', 'validation', 'test']\n",
    "ENCODER_MODEL = 'distilroberta-base' # A more optimized version of roberta obtaining 95% of its performance\n",
    "DEVICE = 'cuda:0'\n",
    "NUM_MASK = '<num>'\n",
    "WORKING_DIR = 'TEMP/'\n",
    "\n",
    "OBJ_DIR = 'pickle/'\n",
    "\n",
    "\n",
    "class Op(Enum):\n",
    "    ADD = '+'\n",
    "    SUB = '-'\n",
    "    MULT = '*'\n",
    "    DIV = '/'\n",
    "    POW = '^'\n",
    "    \n",
    "class Const(Enum):\n",
    "    CONST_NEG_1 = 'const_neg_1' # I added this\n",
    "    CONST_0_25 = 'const_0_25'\n",
    "    CONST_0_2778 = 'const_0_2778'\n",
    "    CONST_0_33 = 'const_0_33'\n",
    "    CONST_0_3937 = 'const_0_3937'\n",
    "    CONST_1 = 'const_1'\n",
    "    CONST_1_6 = 'const_1_6'\n",
    "    CONST_2 = 'const_2'\n",
    "    CONST_3 = 'const_3'\n",
    "    CONST_PI = 'const_pi'\n",
    "    CONST_3_6 = 'const_3_6'\n",
    "    CONST_4 = 'const_4'\n",
    "    CONST_5 = 'const_5'\n",
    "    CONST_6 = 'const_6'\n",
    "    CONST_10 = 'const_10'\n",
    "    CONST_12 = 'const_12'\n",
    "    CONST_26 = 'const_26'\n",
    "    CONST_52 = 'const_52'\n",
    "    CONST_60 = 'const_60'\n",
    "    CONST_100 = 'const_100'\n",
    "    CONST_180 = 'const_180'\n",
    "    CONST_360 = 'const_360'\n",
    "    CONST_1000 = 'const_1000'\n",
    "    CONST_3600 = 'const_3600'\n",
    "\n",
    "values = [-1, 0.25, 0.2778, 0.33, 0.3937, 1, 1.6, 2, 3, math.pi, 3.6, 4, 5, 6, 10, 12, 26, 52, 60, 100, 180, 360, 1000, 3600]\n",
    "const2val = {k:v for k,v in zip(Const._value2member_map_.keys(), values)}    \n",
    "\n",
    "op2id = {k:v for k,v in zip(Op._value2member_map_.keys(), range(len(Op._value2member_map_)))}\n",
    "op2id['None'] = 5\n",
    "id2op = {v:k for k,v in op2id.items()}\n",
    "const2id = {k:v for k,v in zip(Const._value2member_map_.keys(), range(len(Const._value2member_map_)))}\n",
    "id2const = np.array(list(const2id.keys()))\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "class Util():\n",
    "    def load_obj(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            o = pickle.load(f)\n",
    "        return o\n",
    "    \n",
    "    def save_obj(self, path, o):\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(o, f)\n",
    "            \n",
    "    def load_data(self):\n",
    "        return {name:pd.read_csv(f'{DATA_PATH}{name}.csv') for name in SET_NAMES}\n",
    "    \n",
    "    def set_seed(self, seed):\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "util = Util()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22c3c62",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c8df74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess:\n",
    "    \n",
    "    def __init__(self, data, K, embedding_size, max_tokens, model_name, tokenizer_name):\n",
    "        # Randomly initializing embeddings\n",
    "        self.op = torch.randn(len(op2id),embedding_size)\n",
    "        self.query = torch.randn(K,embedding_size)\n",
    "        const = torch.randn(len(const2id),embedding_size)\n",
    "        \n",
    "        self.num, self.text = self.__get_nums_and_mask(data)\n",
    "        self.const = self.__get_const(const)\n",
    "        self.combined = self.__combine(self.num, self.const)\n",
    "        self.labels = {name:self.__get_label(data,name) for name in SET_NAMES}\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder, self.tokenizer = self.__setup_model(model_name, tokenizer_name)\n",
    "        self.tokenized = {name:self.__tokenize_data(self.tokenizer, self.text[name], max_tokens) for name in SET_NAMES}\n",
    "        \n",
    "    # -----------------------------------------------------------\n",
    "    # util\n",
    "    # -----------------------------------------------------------\n",
    "    def __expand_tensor(self, curr, new):\n",
    "        if curr is None:\n",
    "            curr = new\n",
    "        else:\n",
    "            curr =  torch.cat((curr,new), dim=0)\n",
    "        return curr\n",
    "    \n",
    "    def __flatten(self, arr):\n",
    "        idx = np.concatenate([[i]*len(x) for i,x in enumerate(arr)])\n",
    "        flattened = np.concatenate(arr) \n",
    "        return idx, flattened\n",
    "    \n",
    "    # -----------------------------------------------------------\n",
    "    # tokenization\n",
    "    # -----------------------------------------------------------\n",
    "    def __setup_model(self, model_name, tokenizer_name):\n",
    "        model = AutoModel.from_pretrained(model_name, output_hidden_states=True)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        tokenizer.add_special_tokens({'additional_special_tokens':[NUM_MASK]})\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "        return model, tokenizer\n",
    "    \n",
    "    def __tokenize_data(self, tokenizer, text, max_tokens):\n",
    "        tokenization = lambda x: tokenizer(x, padding='max_length', max_length=max_tokens, truncation=True)\n",
    "\n",
    "        tokenized = list(map(tokenization, text))\n",
    "        input_ids = torch.stack([torch.tensor(x['input_ids']) for x in tokenized])\n",
    "        attention_mask = torch.stack([torch.tensor(x['attention_mask']) for x in tokenized])\n",
    "\n",
    "        return {'input_ids':input_ids.long(), 'attention_mask':attention_mask.int()}\n",
    "    \n",
    "    # -----------------------------------------------------------\n",
    "    # literals\n",
    "    # -----------------------------------------------------------\n",
    "    # Gets the numbers listed in a problem\n",
    "    # Once found, numbers are masked using a number mask\n",
    "    def __get_nums_and_mask(self, data):\n",
    "        nums = {name:[] for name in SET_NAMES}\n",
    "        problems = {name:[] for name in SET_NAMES}\n",
    "        num_idx = {name:[] for name in SET_NAMES}\n",
    "        for name in SET_NAMES:\n",
    "            for i,problem in enumerate(data[name].problem):\n",
    "                num = re.compile('([+-]?((\\d+(\\.\\d*)?)|(\\.\\d+)))') # normal num\n",
    "                big = re.compile(r'(-?\\d{1,3}(,\\d{3})+(\\.\\d*)?)') # num with comma\n",
    "\n",
    "                big_results = re.finditer(big, problem)\n",
    "                problem = re.sub(big, NUM_MASK, problem)        \n",
    "                num_results = re.finditer(num, problem)\n",
    "                problem = re.sub(num, NUM_MASK, problem)\n",
    "\n",
    "                # Getting the combined numbers in order of occurence\n",
    "                combined = [x for x in num_results]\n",
    "                combined.extend([x for x in big_results])\n",
    "                combined = sorted(combined, key=lambda x: x.start(0))\n",
    "\n",
    "                combined = [float(x.group(0).replace(',','')) for x in combined]\n",
    "\n",
    "                nums[name].append(np.array(combined))\n",
    "                problems[name].append(problem)\n",
    "            num_idx[name], nums[name] = self.__flatten(np.array(nums[name], dtype=object))\n",
    "            problems[name] = np.array(problems[name])\n",
    "        return {name:{'idx':torch.tensor(num_idx[name]), 'literals':nums[name]} for name in SET_NAMES}, problems\n",
    "    \n",
    "    def __get_const(self, embed):\n",
    "        const = {}\n",
    "        for name in SET_NAMES:\n",
    "            const_pred = util.load_obj(f'{OBJ_DIR}constants.pickle')['pred'][name]\n",
    "            const_idx, const_id = np.where(const_pred==1)\n",
    "            literals = id2const[const_id]\n",
    "            const[name] = {'idx':torch.tensor(const_idx), 'literals':literals, 'embed_idx':const_id, 'embed':embed}\n",
    "        return const\n",
    "    \n",
    "    def __combine(self, num, const):\n",
    "        combined = {}\n",
    "        for name in SET_NAMES:\n",
    "            combined[name] = {'idx':torch.cat((num[name]['idx'],const[name]['idx'])), \n",
    "                              'literals':np.concatenate((num[name]['literals'],const[name]['literals']))}\n",
    "        return combined\n",
    "    \n",
    "    # -----------------------------------------------------------\n",
    "    # labels\n",
    "    # -----------------------------------------------------------\n",
    "    def __get_init_exp(self, data, name):\n",
    "        reorder = lambda x: [x[1], x[0], x[2]]\n",
    "        convert_to_arr = lambda d: [reorder(x.split()) for idx, arr in enumerate(d.split(' ; ')) for x in eval(arr) if x is not None and idx == 0]\n",
    "        return data[name]['incremental'].map(convert_to_arr)\n",
    "\n",
    "    def __get_num_label(self, name, num, i):\n",
    "        idx = self.combined[name]['idx']\n",
    "        literals = self.combined[name]['literals'][idx==i]\n",
    "        label = torch.zeros(literals.shape)\n",
    "        if num in const2val:\n",
    "            location = np.where(literals==num)[0]\n",
    "            if len(location) == 0:\n",
    "                return torch.tensor(-1)\n",
    "            else:\n",
    "                location = location[0]\n",
    "        else:\n",
    "            location = np.where(literals==str(float(num)))[0][0]\n",
    "        return torch.tensor(location)\n",
    "\n",
    "    def __pad_op(self, op_label):\n",
    "        temp = torch.zeros(op_label.shape[1])\n",
    "        temp[op2id['None']] = 1\n",
    "        return torch.cat((op_label, temp[None,:].repeat(K-op_label.shape[0],1)), dim=0)[None,:,:]\n",
    "\n",
    "    def __pad_num(self, num_label):\n",
    "        return torch.cat((num_label, torch.tensor(-1).repeat(K-num_label.shape[0])), dim=0)\n",
    "\n",
    "    def __get_true_label(self, name, e, i):\n",
    "        op, num1, num2 = e\n",
    "        op_label = torch.zeros(len(op2id))\n",
    "        op_label[op2id[op]] = 1\n",
    "        num1_label = self.__get_num_label(name, num1, i)\n",
    "        num2_label = self.__get_num_label(name, num2, i)\n",
    "        return op_label, num1_label, num2_label\n",
    "\n",
    "    def __get_label(self, data, name):\n",
    "        exp = self.__get_init_exp(data, name)\n",
    "        idx = []\n",
    "        true_op_label = None\n",
    "        true_num1_label = []\n",
    "        true_num2_label = []\n",
    "        for i,e in enumerate(exp):\n",
    "            get_true = lambda x: self.__get_true_label(name, x, i)\n",
    "            op_label, num1_label, num2_label = [torch.stack(item) for item in list(zip(*map(get_true, e)))]\n",
    "            true_op_label = self.__expand_tensor(true_op_label, self.__pad_op(op_label))\n",
    "            true_num1_label.append(self.__pad_num(num1_label))\n",
    "            true_num2_label.append(self.__pad_num(num2_label))\n",
    "        return true_op_label, torch.stack(true_num1_label), torch.stack(true_num2_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f8a06fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathQA(Dataset):\n",
    "    def __init__(self, config, name):\n",
    "        self.input_ids = config.tokenized[name]['input_ids']\n",
    "        self.attention_mask = config.tokenized[name]['attention_mask']\n",
    "        self.const_embed = config.const[name]['embed']\n",
    "        self.embed_idx = torch.tensor(config.const[name]['embed_idx']).int()\n",
    "        self.idx = config.combined[name]['idx'].int()\n",
    "        self.const_idx = config.const[name]['idx'].int()\n",
    "        self.true_labels = config.labels[name]\n",
    "        self.literals = config.combined[name]['literals']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        if i.step: # using step is not defined\n",
    "            raise NotImplementedError\n",
    "            \n",
    "        input_ids = self.input_ids[i]\n",
    "        attention_mask = self.attention_mask[i]\n",
    "        true_op = self.true_labels[0][i]\n",
    "        true_num1 = self.true_labels[1][i]\n",
    "        true_num2 = self.true_labels[2][i]\n",
    "        \n",
    "        if isinstance(i, slice):\n",
    "            const_embed = self.const_embed[self.embed_idx[(self.const_idx>=i.start)&(self.const_idx<i.stop)]]\n",
    "            idx = self.idx[(self.idx>=i.start)&(self.idx<i.stop)]\n",
    "            literals = self.literals[(self.idx>=i.start)&(self.idx<i.stop)]\n",
    "        else:\n",
    "            const_embed = self.const_embed[self.embed_idx[self.const_idx==i]]\n",
    "            idx = self.idx[self.idx==i]\n",
    "            literals = self.literals[self.idx==i]\n",
    "        return input_ids, attention_mask, const_embed, idx, (true_op, true_num1, true_num2), literals\n",
    "    \n",
    "class DataLoader:\n",
    "    def __init__(self, dataset, batch_size, shuffle):\n",
    "        self.curr = 0\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.slices = [slice(x,x+batch_size) for x in range(0,len(dataset),batch_size)]\n",
    "        self.num_batches = len(self.slices)\n",
    "        \n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.slices)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.num_batches\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):        \n",
    "        if self.curr < self.num_batches:\n",
    "            input_ids, attention_mask, const_embed, idx, true_labels, literals = self.dataset[self.slices[self.curr]]\n",
    "            self.curr += 1\n",
    "            return input_ids, attention_mask, const_embed, idx%self.batch_size, true_labels, literals\n",
    "        raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7bf9706",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.device = config.device\n",
    "        self.mask_id = config.tokenizer.encode(NUM_MASK, add_special_tokens=False)[0]\n",
    "        self.encoder = config.encoder.to(config.device)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, const_embed):\n",
    "        input_ids = input_ids.to(self.device)\n",
    "        attention_mask = attention_mask.to(self.device)\n",
    "        const_embed = const_embed.to(self.device)\n",
    "        \n",
    "        # Getting the hidden output\n",
    "        x = self.encoder(input_ids, attention_mask).last_hidden_state\n",
    "        \n",
    "        # Combining constants and numbers\n",
    "        embed = torch.cat((x[input_ids==self.mask_id],const_embed), dim=0)\n",
    "        \n",
    "        return x, embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "127f946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, config): \n",
    "        super(Decoder, self).__init__()\n",
    "        self.device = config.device\n",
    "        self.embedding_size = config.embedding_size\n",
    "        self.num_tokens = config.num_tokens\n",
    "        self.K = config.K\n",
    "        self.op_embed = config.op\n",
    "        \n",
    "        # standard transformer decoder\n",
    "        transformer_decoder_layer = torch.nn.TransformerDecoderLayer(self.embedding_size, nhead=config.nhead, batch_first=True)\n",
    "        self.transformer_decoder = torch.nn.TransformerDecoder(transformer_decoder_layer, num_layers=config.nlayer)\n",
    "        \n",
    "        # softmax for the operations\n",
    "        self.op_softmax = torch.nn.Softmax(dim=2)\n",
    "        \n",
    "        # softmax for the numbers\n",
    "        self.num_softmax = torch.nn.Softmax(dim=0)\n",
    "\n",
    "        # decreasing dimensionality to match embedding size: <op, num, num, num*num> = 3072 -> 768\n",
    "#         self.exp_encoder = torch.nn.Sequential(\n",
    "#             torch.nn.Linear(self.embedding_size*4, self.embedding_size*2),\n",
    "#             torch.nn.SiLU(),\n",
    "#             torch.nn.Linear(self.embedding_size*2, self.embedding_size*2),\n",
    "#             torch.nn.SiLU(),\n",
    "#             torch.nn.Linear(self.embedding_size*2, self.embedding_size),\n",
    "#         )\n",
    "        \n",
    "        # converting back into new <op, num, num> for loss calculation\n",
    "        self.op_decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.embedding_size, int(self.embedding_size*1.5)),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(int(self.embedding_size*1.5), int(self.embedding_size*1.5)),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(int(self.embedding_size*1.5), self.embedding_size),\n",
    "        )\n",
    "        self.num1_decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.embedding_size, int(self.embedding_size*1.5)),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(int(self.embedding_size*1.5), int(self.embedding_size*1.5)),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(int(self.embedding_size*1.5), self.embedding_size),\n",
    "        )\n",
    "        self.num2_decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.embedding_size, int(self.embedding_size*1.5)),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(int(self.embedding_size*1.5), int(self.embedding_size*1.5)),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(int(self.embedding_size*1.5), self.embedding_size),\n",
    "        )\n",
    "        \n",
    "    def __apply_to_nums(self, f, num, idx, batch_size):\n",
    "        new_nums = torch.zeros(batch_size, self.K, num.shape[0]).to(self.device)\n",
    "        for x in range(batch_size):\n",
    "            new_nums[x,:,idx==x] = f(num[idx==x]).T\n",
    "        return new_nums  \n",
    "    \n",
    "    # query: [batch_size, K, 768]\n",
    "    # prob_embed: [batch_size, num_tokens, 768]\n",
    "    # num_embed: [num_nums, 768]\n",
    "    # op_embed: [num_ops, 768]\n",
    "    def forward(self, query, prob_embed, num_embed, idx): \n",
    "        query = query.to(self.device)\n",
    "        prob_embed = prob_embed.to(self.device)\n",
    "        num_embed = num_embed.to(self.device)\n",
    "        op_embed = self.op_embed.to(self.device)\n",
    "        idx = idx.to(self.device)\n",
    "        batch_size = query.shape[0]\n",
    "        num_ops = op_embed.shape[0]\n",
    "        num_nums = num_embed.shape[0]\n",
    "\n",
    "        # ----------------------------\n",
    "        # Step 1 - transformer decoder\n",
    "        # ----------------------------\n",
    "        query = self.transformer_decoder(query, prob_embed) # [batch_size, K, 768] -> [batch_size, K, 768]\n",
    "        \n",
    "        # -------------------------------------------------------------------------------\n",
    "        # Step 2 - decoding the output into three embeddings of size 768 (op, num1, num2)\n",
    "        # -------------------------------------------------------------------------------\n",
    "        op = self.op_decoder(query)\n",
    "        num1 = self.num1_decoder(query)\n",
    "        num2 = self.num2_decoder(query)\n",
    "        \n",
    "        # ----------------------------------------------------\n",
    "        # Step 3 - creating embedding for the found expression  \n",
    "        # ----------------------------------------------------\n",
    "        #query = self.exp_encoder(torch.cat((op,num1,num2,num1*num2), dim=2)) # [batch_size, K, 3072] -> [batch_size, K, 768]\n",
    "        \n",
    "        # ------------------------------------------------------------------------------\n",
    "        # Step 4 - Taking a dot product between the predicted and stored true embeddings\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # making sure params have correct dimension\n",
    "        num_embed = num_embed[:,None,:].expand(-1,K,-1) # [num_nums, 768] -> [num_nums, K, 768]\n",
    "        op_embed = op_embed[None,None,:,:].repeat(batch_size,self.K,1,1) # [num_ops, 768] -> [batch_size, K, num_ops, 768]\n",
    "\n",
    "        # dot product - calculating the similarity between each op/num prediction and stored embeddings\n",
    "        num1 = (num1[idx]*num_embed).sum(dim=2) # [number_of_nums, K]\n",
    "        num2 = (num2[idx]*num_embed).sum(dim=2) # [number_of_nums, K]        \n",
    "        op = op[:,:,None,:].expand(-1,-1,num_ops,-1) # [batch_size, K, 768] -> # [batch_size, K, num_ops, 768]\n",
    "        op = (op*op_embed).sum(dim=3) # [batch_size, K, num_ops, 768] -> [batch_size, K, num_ops]\n",
    "        \n",
    "        # -----------------------------------------------------------------------------------------\n",
    "        # Step 5 - Finding the softmax for the similarity between the predicted and true embeddings\n",
    "        # -----------------------------------------------------------------------------------------\n",
    "        op = self.op_softmax(op) # [batch_size, K, num_ops] (ie op[1,2] would be the operator prediction probabilities for problem2, query3)\n",
    "        num1 = self.__apply_to_nums(self.num_softmax, num1, idx, batch_size) # [batch_size,K,num_nums]\n",
    "        num2 = self.__apply_to_nums(self.num_softmax, num2, idx, batch_size) # [batch_size,K,num_nums]\n",
    "        \n",
    "        return query, op, num1, num2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8b31e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    def __init__(self, config):\n",
    "        self.K = config.K\n",
    "        self.device = config.device\n",
    "        \n",
    "    # --------------------------------\n",
    "    # loss/accuracy calculation\n",
    "    # --------------------------------\n",
    "    def __lmatch(self, true_op, true_num1, true_num2, op, num1, num2):\n",
    "        true_op = torch.clone(true_op)\n",
    "        true_op[:,:,op2id['None']] = 0 # setting all none operators to zero so ignored during calculation\n",
    "\n",
    "        # rows: true exp, cols: pred exp (ie 0,1 would be the cost for true exp 0 with pred exp 1)\n",
    "        # [8,K*K]\n",
    "        op_mat = (true_op.repeat_interleave(K,dim=1)*op.repeat(1,K,1)).sum(dim=-1)\n",
    "        num1_mat = (true_num1.repeat_interleave(K,dim=1)*num1.repeat(1,K,1)).sum(dim=-1)\n",
    "        num2_mat = (true_num2.repeat_interleave(K,dim=1)*num2.repeat(1,K,1)).sum(dim=-1)\n",
    "\n",
    "        return -(op_mat+num1_mat+num2_mat).reshape(op_mat.shape[0],K,K)\n",
    "    \n",
    "    # consider trying to write this in pytorch if have time\n",
    "    def __hungarian_algorithm(self, true_op, true_num1, true_num2, op, num1, num2, batch_size):\n",
    "        m = self.__lmatch(true_op, true_num1, true_num2, op, num1, num2)\n",
    "        permutations = torch.stack(tuple([torch.tensor(linear_sum_assignment(m.detach().cpu().numpy()[x])[1]) for x in range(batch_size)]))\n",
    "        batch_idx = torch.arange(batch_size).unsqueeze(-1)\n",
    "        return op[batch_idx, permutations], num1[batch_idx, permutations], num2[batch_idx, permutations]\n",
    "    \n",
    "    # expects the optimal permutation from the hungarian algorithm\n",
    "    def __final_loss(self, true_op, true_num1, true_num2, op, num1, num2):        \n",
    "        log_op = torch.log((true_op*op).sum(-1))\n",
    "        \n",
    "        log_num1 = ((true_num1*num1).sum(-1))\n",
    "        log_num1[log_num1.nonzero(as_tuple=True)] = torch.log(log_num1[log_num1.nonzero(as_tuple=True)])\n",
    "        \n",
    "        log_num2 = ((true_num2*num2).sum(-1))\n",
    "        log_num2[log_num2.nonzero(as_tuple=True)] = torch.log(log_num2[log_num2.nonzero(as_tuple=True)])\n",
    " \n",
    "        return (-log_op-log_num1-log_num2).sum(-1).mean()\n",
    "\n",
    "    # expects the optimal permutation from the hungarian algorithm\n",
    "    # gets the number of correct examples for a batch\n",
    "    def __correct(self, true_op, true_num1, true_num2, op, num1, num2):\n",
    "        invalid = true_op.argmax(-1)==op2id['None']\n",
    "        op_correct = true_op.argmax(-1)==op.argmax(-1)\n",
    "        num1_correct = num1.argmax(-1)==true_num1.argmax(-1)\n",
    "        num2_correct = num2.argmax(-1)==true_num2.argmax(-1)\n",
    "        num1_correct[invalid]=True\n",
    "        num2_correct[invalid]=True\n",
    "        \n",
    "        correct = ((op_correct&num1_correct&num2_correct).sum(1)==self.K).sum()\n",
    "        num_ops = true_op.shape[0]*true_op.shape[1]\n",
    "        op_correct = op_correct.sum()\n",
    "        num_nums = len(num1_correct[~invalid])\n",
    "        num1_correct = num1_correct[~invalid].sum()\n",
    "        num2_correct = num2_correct[~invalid].sum()\n",
    "        return correct, op_correct, num_ops, num1_correct, num2_correct, num_nums\n",
    "    \n",
    "    def prepare_labels(self, idx, true_labels, shape):\n",
    "        true_op, true_num1, true_num2 = true_labels\n",
    "        batch_size = true_op.shape[0]\n",
    "\n",
    "        temp = torch.zeros(shape)\n",
    "        unmasked = true_num1!=-1\n",
    "        true_idx = torch.cat([torch.where(idx==x)[0][true_num1[x][true_num1[x]!=-1]] for x in range(batch_size)])\n",
    "        temp[unmasked,true_idx]=1\n",
    "        true_num1 = temp\n",
    "\n",
    "        temp = torch.zeros(shape)\n",
    "        unmasked = true_num2!=-1\n",
    "        true_idx = torch.cat([torch.where(idx==x)[0][true_num2[x][true_num2[x]!=-1]] for x in range(batch_size)])\n",
    "        temp[unmasked,true_idx]=1\n",
    "        true_num2 = temp\n",
    "\n",
    "        # Randomizing equation order\n",
    "        batch_idx = torch.arange(batch_size).unsqueeze(-1)\n",
    "        perm = torch.rand(batch_size,self.K).argsort(dim=1)\n",
    "        true_op = true_op[batch_idx,perm,:]\n",
    "        true_num1 = true_num1[batch_idx,perm,:]\n",
    "        true_num2 = true_num2[batch_idx,perm,:]\n",
    "\n",
    "        return true_op.to(self.device), true_num1.to(self.device), true_num2.to(self.device)\n",
    "    \n",
    "    def calculate(self, idx, true_labels, op, num1, num2, batch_size):\n",
    "        true_op, true_num1, true_num2 = self.prepare_labels(idx, true_labels, num1.shape)\n",
    "        \n",
    "        op, num1, num2 = self.__hungarian_algorithm(true_op, true_num1, true_num2, op, num1, num2, batch_size) # getting optimal permutation\n",
    "        \n",
    "        loss = self.__final_loss(true_op, true_num1, true_num2, op, num1, num2)\n",
    "        correct, op_correct, num_ops, num1_correct, num2_correct, num_nums = self.__correct(true_op, true_num1, true_num2, op, num1, num2)\n",
    "        \n",
    "        return loss, correct, op_correct, num_ops, num1_correct, num2_correct, num_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d7c76b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstLayer(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(FirstLayer, self).__init__()\n",
    "        self.device = config.device\n",
    "        self.encoder = Encoder(config)\n",
    "        self.decoder = Decoder(config)\n",
    "        self.loss = Loss(config)\n",
    "        self.query = config.query\n",
    "        \n",
    "        self.opt = config.opt(self.parameters(), lr=config.lr)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, const_embed, idx, true_labels):\n",
    "        batch_size = input_ids.shape[0]\n",
    "        \n",
    "        # encoder\n",
    "        prob_embed, num_embed = self.encoder(input_ids, attention_mask, const_embed)\n",
    "                \n",
    "        # decoder\n",
    "        query = self.query[None,:,:].repeat(batch_size,1,1)\n",
    "        query, op, num1, num2 = self.decoder(query, prob_embed, num_embed, idx)\n",
    "        \n",
    "        # loss\n",
    "        loss, correct, op_correct, num_ops, num1_correct, num2_correct, num_nums = self.loss.calculate(idx, true_labels, op, num1, num2, batch_size)\n",
    "        \n",
    "        return query, loss, correct, op_correct, num_ops, num1_correct, num2_correct, num_nums, op, num1, num2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dafdc2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullModel(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(FullModel, self).__init__()\n",
    "        self.device = config.device\n",
    "        self.firstlayer = FirstLayer(config)\n",
    "        self.grad_norm_clip = config.grad_norm_clip\n",
    "        \n",
    "    def __backpropagate(self, loss, layer):\n",
    "        layer.opt.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(layer.parameters(), self.grad_norm_clip)\n",
    "        layer.opt.step()\n",
    "        \n",
    "    def train(self, dataloader, epoch, num_batches=None):\n",
    "        total_loss = 0\n",
    "        total_batches = num_batches if num_batches else len(dataloader)\n",
    "        total_correct = 0\n",
    "        total_examples = 0\n",
    "        total_op_correct = 0\n",
    "        total_num1_correct = 0\n",
    "        total_num2_correct = 0\n",
    "        total_nums = 0\n",
    "        total_ops = 0\n",
    "        with tqdm(dataloader, total=total_batches) as progress_bar:\n",
    "            for item in progress_bar:\n",
    "                progress_bar.set_description(f'Epoch {epoch}')\n",
    "                input_ids, attention_mask, const_embed, idx, true_labels, _ = item\n",
    "                \n",
    "                # forward pass\n",
    "                query, loss, correct, op_correct, num_ops, num1_correct, num2_correct, num_nums,_,_,_ = self.forward(input_ids, attention_mask, const_embed, idx, true_labels)\n",
    "                \n",
    "                # backpropagating the loss\n",
    "                self.__backpropagate(loss, self.firstlayer)\n",
    "                \n",
    "                total_loss += loss.detach().item()\n",
    "                total_correct += correct.detach().item()\n",
    "                total_examples += input_ids.shape[0]\n",
    "                total_op_correct += op_correct.detach().item()\n",
    "                total_num1_correct += num1_correct.detach().item()\n",
    "                total_num2_correct += num2_correct.detach().item()\n",
    "                total_ops += num_ops\n",
    "                total_nums += num_nums\n",
    "                \n",
    "                progress_bar.set_postfix(loss=loss.detach().item())                \n",
    "                progress_bar.update(1)\n",
    "                \n",
    "                if num_batches:\n",
    "                    num_batches -= 1\n",
    "                if num_batches == 0:\n",
    "                    progress_bar.close()\n",
    "                    break\n",
    "        return total_loss/total_batches, total_correct/total_examples, total_op_correct/total_ops, total_num1_correct/total_nums, total_num2_correct/total_nums\n",
    "    \n",
    "    def val(self, dataloader, num_batches=None):\n",
    "        total_loss = 0\n",
    "        total_batches = num_batches if num_batches else len(dataloader)\n",
    "        total_correct = 0\n",
    "        total_examples = 0\n",
    "        total_op_correct = 0\n",
    "        total_num1_correct = 0\n",
    "        total_num2_correct = 0\n",
    "        total_nums = 0\n",
    "        total_ops = 0\n",
    "        with torch.no_grad():\n",
    "            with tqdm(dataloader, total=total_batches) as progress_bar:\n",
    "                for item in progress_bar:\n",
    "                    progress_bar.set_description(f'Validation')\n",
    "                    input_ids, attention_mask, const_embed, idx, true_labels, _ = item\n",
    "\n",
    "                    # forward pass\n",
    "                    query, loss, correct, op_correct, num_ops, num1_correct, num2_correct, num_nums,_,_,_ = self.forward(input_ids, attention_mask, const_embed, idx, true_labels)\n",
    "\n",
    "                    total_loss += loss.detach().item()\n",
    "                    total_correct += correct.detach().item()\n",
    "                    total_examples += input_ids.shape[0]\n",
    "                    total_op_correct += op_correct.detach().item()\n",
    "                    total_num1_correct += num1_correct.detach().item()\n",
    "                    total_num2_correct += num2_correct.detach().item()\n",
    "                    total_ops += num_ops\n",
    "                    total_nums += num_nums\n",
    "           \n",
    "                    progress_bar.update(1)\n",
    "\n",
    "                    if num_batches:\n",
    "                        num_batches -= 1\n",
    "                    if num_batches == 0:\n",
    "                        progress_bar.close()\n",
    "                        break\n",
    "        return total_loss/total_batches, total_correct/total_examples, total_op_correct/total_ops, total_num1_correct/total_nums, total_num2_correct/total_nums\n",
    "            \n",
    "    def fit(self, epochs, num_batches=None):\n",
    "        for epoch in range(epochs):\n",
    "            best_loss = math.inf\n",
    "            \n",
    "            train_dataloader = DataLoader(MathQA(config, 'train'), batch_size=config.batch_size, shuffle=True)\n",
    "            val_dataloader = DataLoader(MathQA(config, 'validation'), batch_size=config.batch_size, shuffle=True)\n",
    "            train_loss, train_acc, train_op_acc, train_num1_acc, train_num2_acc = self.train(train_dataloader, epoch+1, num_batches)\n",
    "            val_loss, val_acc, val_op_acc, val_num1_acc, val_num2_acc = self.val(val_dataloader, num_batches)\n",
    "            \n",
    "            df = pd.DataFrame({'Train':[train_loss, train_acc, train_op_acc, train_num1_acc, train_num2_acc], \n",
    "                               'Validation':[val_loss, val_acc, val_op_acc, val_num1_acc, val_num2_acc]},\n",
    "                       index = ['Loss','Accuracy','Op Accuracy','Num1 Accuracy','Num2 Accuracy'])\n",
    "            \n",
    "            display(df)\n",
    "            \n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                model_path = 'D:\\jupyter_notebooks\\Mathsage\\Connor\\models\\mathsage_step1'\n",
    "                torch.save(self.state_dict(), model_path)\n",
    "            \n",
    "    def forward(self, input_ids, attention_mask, const_embed, idx, true_labels):\n",
    "        query, loss, correct, op_correct, num_ops, num1_correct, num2_correct, num_nums, op, num1, num2 = self.firstlayer(input_ids, attention_mask, const_embed, idx, true_labels)\n",
    "        return query, loss, correct, op_correct, num_ops, num1_correct, num2_correct, num_nums, op, num1, num2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31e00e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \n",
    "    def __init__(self, data, reload=False):\n",
    "        self.device = torch.device('cuda:0')\n",
    "        self.model_name = r'D:\\jupyter_notebooks\\Mathsage\\Connor\\models\\distilroberta-base-encoder-mathqa'\n",
    "        self.tokenizer_name = 'distilroberta-base'\n",
    "        self.seed = 3\n",
    "        self.batch_size = 8\n",
    "        \n",
    "        # model params\n",
    "        self.K = 6\n",
    "        self.max_layers = 8\n",
    "        self.nhead = 6\n",
    "        self.nlayer = 6\n",
    "        self.embedding_size = 768\n",
    "        self.num_tokens = 392\n",
    "        \n",
    "        # training params\n",
    "        self.lr = 2e-5\n",
    "        self.opt = torch.optim.AdamW\n",
    "        self.grad_norm_clip = 1.0\n",
    "        \n",
    "        # Loading preprocessed data\n",
    "        if reload:\n",
    "            p = Preprocess(data, self.K, self.embedding_size, self.num_tokens, self.model_name, self.tokenizer_name)\n",
    "            util.save_obj(f'{OBJ_DIR}preprocess.pickle', p)\n",
    "        else:\n",
    "            p = util.load_obj(f'{OBJ_DIR}preprocess.pickle')\n",
    "                \n",
    "        self.num = p.num\n",
    "        self.const = p.const\n",
    "        self.combined = p.combined\n",
    "        self.query = p.query\n",
    "        self.op = p.op\n",
    "        self.text = p.text\n",
    "        self.labels = p.labels\n",
    "        self.encoder = p.encoder\n",
    "        self.tokenizer = p.tokenizer\n",
    "        self.tokenized = p.tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dfcce28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# try:\n",
    "#     data = util.load_data()\n",
    "#     config = Config(data, reload=False)\n",
    "#     util.set_seed(config.seed)\n",
    "#     model = FullModel(config)\n",
    "#     model.to(config.device)\n",
    "#     model.fit(epochs = 5)\n",
    "# finally:\n",
    "#     #del model\n",
    "#     torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59c83266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3248ddbde8044ecb9408e40a64ce8bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0d0fb0f3b4498fae0a9c3144aeae21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/339 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941bf41ecb574b85a88701e53cd07f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loss</th>\n",
       "      <td>1.253186</td>\n",
       "      <td>4.139475</td>\n",
       "      <td>3.978741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.782322</td>\n",
       "      <td>0.662731</td>\n",
       "      <td>0.660178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Op Accuracy</th>\n",
       "      <td>0.963995</td>\n",
       "      <td>0.923555</td>\n",
       "      <td>0.922506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num1 Accuracy</th>\n",
       "      <td>0.959682</td>\n",
       "      <td>0.878148</td>\n",
       "      <td>0.887967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num2 Accuracy</th>\n",
       "      <td>0.951088</td>\n",
       "      <td>0.876333</td>\n",
       "      <td>0.873444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Train  Validation      Test\n",
       "Loss           1.253186    4.139475  3.978741\n",
       "Accuracy       0.782322    0.662731  0.660178\n",
       "Op Accuracy    0.963995    0.923555  0.922506\n",
       "Num1 Accuracy  0.959682    0.878148  0.887967\n",
       "Num2 Accuracy  0.951088    0.876333  0.873444"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    data = util.load_data()\n",
    "    config = Config(data, reload=False)\n",
    "    util.set_seed(config.seed)\n",
    "    model = FullModel(config)\n",
    "    model.to(config.device)\n",
    "    model.load_state_dict(torch.load('D:\\jupyter_notebooks\\Mathsage\\Connor\\models\\mathsage_step1'))\n",
    "    train_dataloader = DataLoader(MathQA(config, 'train'), batch_size=config.batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(MathQA(config, 'validation'), batch_size=config.batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(MathQA(config, 'test'), batch_size=config.batch_size, shuffle=True)\n",
    "    train_loss, train_acc, train_op_acc, train_num1_acc, train_num2_acc = model.val(train_dataloader)\n",
    "    val_loss, val_acc, val_op_acc, val_num1_acc, val_num2_acc = model.val(val_dataloader)\n",
    "    test_loss, test_acc, test_op_acc, test_num1_acc, test_num2_acc = model.val(test_dataloader)\n",
    "    df = pd.DataFrame({'Train':[train_loss, train_acc, train_op_acc, train_num1_acc, train_num2_acc], \n",
    "                        'Validation':[val_loss, val_acc, val_op_acc, val_num1_acc, val_num2_acc],\n",
    "                        'Test':[test_loss, test_acc, test_op_acc, test_num1_acc, test_num2_acc]},\n",
    "                       index = ['Loss','Accuracy','Op Accuracy','Num1 Accuracy','Num2 Accuracy'])  \n",
    "    display(df)\n",
    "finally:\n",
    "    #del model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96420d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(MathQA(config, 'validation'), batch_size=config.batch_size, shuffle=False)\n",
    "input_ids, attention_mask, const_embed, idx, true_labels, literals = next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a91221f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eq(op, num1, num2, literals):\n",
    "    valid = op.argmax(-1)!=op2id['None']\n",
    "    pred_op = op.argmax(-1)[valid]\n",
    "    pred_num1 = num1.argmax(-1)[valid]\n",
    "    pred_num2 = num2.argmax(-1)[valid]\n",
    "    eq_idx = np.concatenate([[i]*x for i,x in enumerate(valid.sum(axis=-1))])\n",
    "    eq = [f'{num1} {op} {num2}' for num1, op, num2 in zip(literals[pred_num1.cpu()], np.array(list(id2op.values()))[pred_op.cpu().numpy()], literals[pred_num2.cpu()])]\n",
    "    return eq, eq_idx\n",
    "\n",
    "def get_all_eq(name):\n",
    "    dataloader = DataLoader(MathQA(config, name), batch_size=config.batch_size, shuffle=False)\n",
    "    eq = []\n",
    "    eq_idx = []\n",
    "    with torch.no_grad():\n",
    "        for i,batch in enumerate(dataloader):\n",
    "            input_ids, attention_mask, const_embed, idx, true_labels, literals = batch\n",
    "            query, loss, correct, op_correct, num_ops, num1_correct, num2_correct, num_nums, op, num1, num2 = model(input_ids, attention_mask, const_embed, idx, true_labels)\n",
    "            x1, x2 = get_eq(op, num1, num2, literals)\n",
    "            eq.extend(x1)\n",
    "            eq_idx.extend(list((x2+config.batch_size*i).astype(int)))\n",
    "    return eq, eq_idx\n",
    "\n",
    "subexpressions = {name:get_all_eq(name) for name in SET_NAMES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "40b70f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.save_obj(f'{OBJ_DIR}subexp.pickle',subexpressions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4dac33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
